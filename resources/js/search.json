[[{"i":"what-is-sillytavern","l":"What is SillyTavern?","p":["SillyTavern - LLM Frontend for Power Users","Brought to you by Cohee, RossAscends, and the SillyTavern community, SillyTavern is a local-install interface that allows you to interact with text generation AIs (LLMs) to chat and roleplay with custom characters.","SillyTavern originated as a modification of TavernAI 1.2.8 in February 2023, and has since added many cutting-edge features not present in the original TavernAI."]},{"i":"missing-extensions-after-the-update","l":"Missing extensions after the update?","p":["Since the 1.10.6 release version, most of the previously built-in extensions have been converted to downloadable add-ons. You can download them via the built-in \"Download Extensions and Assets\" menu in the extensions panel (stacked blocks icon in the top bar)."]},{"l":"Screenshots","p":["Chat","Waifu mode","VN Mode","Backgrounds"]},{"l":"Branches","p":["SillyTavern is being developed using a two-branch system to ensure a smooth experience for all users.","release -\uD83C\uDF1F Recommended for most users. This is the most stable and recommended branch, updated only when major releases are pushed. It's suitable for the majority of users.","staging - ⚠️ Not recommended for casual use. This branch has the latest features, but be cautious as it may break at any time. Only for power users and enthusiasts.","Learn more here."]},{"l":"Features","p":["Author's Note / Character Bias","Auto-translate single messages or the entire chat via Google API, even automatically.","Character HotSwap buttons to quickly change between your favorite characters","Chat bookmarks / branching","Customizable colors, backgrounds, avatar styles, and UI panel placement","Export chats as .txt files","Extensive prompt formatting options","Group chats: multi-bot rooms for characters to talk to you or each other","Horde Stable Diffusion generation","Mobile-friendly interface","Multiple backend API connectivity ( KoboldAI, KoboldCpp, AI Horde, NovelAI, Oobabooga's TextGen WebUI, OpenAI, WindowAI, OpenRouter, TabbyAPI, and many more...). See API connections.","Notification sound for AI responses","Prompt token breakdown view for each message","Swipes","TTS support (ElevenLabs, Silero, etc.)","Visual Novel-like Waifu Mode","WorldInfo (lorebooks)"]},{"l":"Extensions","p":["SillyTavern supports extensions/plugins:","Character emotional expressions","Auto-Summary of the chat history","Sending images to chat, and the AI interpreting the content.","Stable Diffusion image generation (5 chat-related presets plus 'free mode')","Text-to-speech for AI response messages (via ElevenLabs, Silero, or the OS's System TTS)","Additional functionality can be added by using SillyTavern Extras."]},{"l":"Installation Requirements","p":["SillyTavern will run on virtually any device capable of running NodeJS v18.","NOTE: due to the above requirement, SillyTavern will not run on Windows 7."]},{"i":"what-do-i-need-other-than-sillytavern","l":"What do I need other than SillyTavern?","p":["SillyTavern is only a frontend interface, so you will need to have access to one of the backend APIs listed above."]},{"i":"how-can-i-get-in-touch-with-the-developers-directly","l":"How can I get in touch with the developers directly?","p":["Discord: cohee or rossascends","Reddit: /u/RossAscends or /u/sillylossy","Post a GitHub issue"]},{"i":"i-like-your-project-how-do-i-contribute","l":"I like your project! How do I contribute?","p":["We welcome pull requests!","We also welcome helpful and informed bug reports that use the templates provided in our GitHub.","We do not accept monetary donations for the project itself.","Cohee does not take donations.","RossAscends has a personal Patreon& Kofi"]}],[{"l":"Windows Installation","p":["DO NOT INSTALL INTO ANY WINDOWS CONTROLLED FOLDER (Program Files, System32, etc).","DO NOT RUN START.BAT WITH ADMIN PERMISSIONS","INSTALLATION ON WINDOWS 7 IS IMPOSSIBLE AS IT CAN NOT RUN NODEJS 18.16"]},{"l":"Installing via Git","p":["Install NodeJS(latest LTS version is recommended)","Install Git for Windows","Open Windows Explorer ( Win+E)","Browse to or Create a folder that is not controlled or monitored by Windows. (ex: C:\\MySpecialFolder)","Open a Command Prompt inside that folder by clicking in the 'Address Bar' at the top, typing cmd, and pressing Enter.","Once the black box (Command Prompt) pops up, type ONE of the following into it and press Enter:","for Release Branch: git clone https://github.com/SillyTavern/SillyTavern -b release","for Staging Branch: git clone https://github.com/SillyTavern/SillyTavern -b staging","Once everything is cloned, double-click Start.bat to make NodeJS install its requirements.","The server will then start, and SillyTavern will pop up in your browser."]},{"l":"Installing via SillyTavern Launcher","p":["Install Git for Windows","Open Windows Explorer ( Win+E) and make or choose a folder where you wanna install the launcher to","Open a Command Prompt inside that folder by clicking in the 'Address Bar' at the top, typing cmd, and pressing Enter.","When you see a black box, insert the following command: git clone https://github.com/SillyTavern/SillyTavern-Launcher.git","Double-click on installer.bat and choose what you wanna install","After installation double-click on launcher.bat"]},{"l":"Installing via GitHub Desktop","p":["(This allows git usage only in GitHub Desktop, if you want to use git on the command line too, you also need to install Git for Windows)","Install NodeJS(latest LTS version is recommended)","Install GitHub Desktop","After installing GitHub Desktop, click on Clone a repository from the internet....(Note: You do NOT need to create a GitHub account for this step)","image","On the menu, click the URL tab, enter this URL https://github.com/SillyTavern/SillyTavern, and click Clone. You can change the Local path to change where SillyTavern is going to be downloaded.","To open SillyTavern, use Windows Explorer to browse into the folder where you cloned the repository. By default, the repository will be cloned here: C:\\Users\\[Your Windows Username]\\Documents\\GitHub\\SillyTavern","Double-click on the start.bat file. (Note: the .bat part of the file name might be hidden by your OS, in that case, it will look like a file called \" Start\". This is what you double-click to run SillyTavern)","After double-clicking, a large black command console window should open and SillyTavern will begin to install what it needs to operate.","After the installation process, if everything is working, the command console window should look like this and a SillyTavern tab should be open in your browser:","Connect to any of the supported APIs and start chatting!"]}],[{"i":"linuxmacos-install","l":"Linux/MacOS Install"},{"l":"Manual Git install","p":["For MacOS / Linux all of these will be done in a Terminal.","Install git and nodeJS (the method for doing this will vary depending on your OS)","Clone the repo","for Release Branch: git clone https://github.com/SillyTavern/SillyTavern -b release","for Staging Branch: git clone https://github.com/SillyTavern/SillyTavern -b staging","cd SillyTavern to navigate into the install folder.","Run the start.sh script with one of these commands:","./start.sh","bash start.sh"]},{"l":"SillyTavern Launcher"},{"l":"For Linux users","p":["Open your favorite terminal and install git","Download Sillytavern Launcher with: git clone https://github.com/SillyTavern/SillyTavern-Launcher.git","Navigate to the SillyTavern-Launcher with: cd SillyTavern-Launcher","Start the install launcher with: chmod +x install.sh ./install.sh and choose what you wanna install","After installation start the launcher with: chmod +x launcher.sh ./launcher.sh"]},{"l":"For Mac users","p":["Open a terminal and install brew with: /bin/bash -c $(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)","Then install git with: brew install git","Download Sillytavern Launcher with: git clone https://github.com/SillyTavern/SillyTavern-Launcher.git","Navigate to the SillyTavern-Launcher with: cd SillyTavern-Launcher","Start the install launcher with: chmod +x install.sh ./install.sh and choose what you wanna install","After installation start the launcher with: chmod +x launcher.sh ./launcher.sh"]}],[{"i":"androidtermux-installation","l":"Android(Termux) Installation","p":["SillyTavern can be run natively on Android phones using Termux.","Please refer to this guide by ArroganceComplex#2659:","https://rentry.org/STAI-Termux"]},{"l":"Common errors"},{"i":"unsupported-platform-android-arm-letime-web","l":"Unsupported platform: android arm LEtime-web","p":["32-bit Android requires an external dependency that can't be installed with npm.","Use the following command to install it:","pkg install esbuild","Then run the steps from the guide."]}],[{"l":"Docker Installation"},{"l":"With Docker compose","p":["git clone https://github.com/sillytavern/sillytavern","cd sillytavern/docker","docker compose up","config & data @ docker directory","docker compose up -d"]},{"l":"Updating the container","p":["pull latest images: docker compose pull","Restart the container: docker compose up -d --remove-orphans","Optionally, remove obsolete images: `docker image prune"]},{"l":"Without Docker compose","p":["Pull the image from the container registry: docker pull ghcr.io/sillytavern/sillytavern:latest","prep dirs for config&data","export STDIR=/home/heblushabus/ST/","docker run --name sillytavern -d -p 8000:8000 -v $STDIR/config:/home/node/app/config -v $STDIR/data:/home/node/app/data --restart always ghcr.io/sillytavern/sillytavern:release`"]}],[{"i":"sillytavern-1120-migration-guide","l":"SillyTavern 1.12.0 Migration Guide","p":["SillyTavern 1.12.0 (codename the \"Neo Server\" update) includes several critical changes that may affect the way you use SillyTavern.","This guide will prepare you for the update and provide some further guidance."]},{"l":"Data storage update","p":["1.12.0 changes the way SillyTavern handles the user data.","Previously, all of the persistent data was stored together with the frontend part in the /public directory, which created confusion and potential points of failure, as well as making containerization and system-wide app installation quite challenging."]},{"i":"whats-changed","l":"What's changed?","p":["All persistent information from /public such as settings and chats (full list below) was moved into a separate directory with the configurable path, making it portable and independent from the web server itself. When needed for compatibility purposes, for example, for hosting extensions, full-size character cards, user image uploads, etc. a smart redirect has been set up to automatically host user files from the data directory."]},{"l":"Setting a data root","p":["You can provide either an absolute or a relative (to the ST repository directory) path to the data root either by config.yaml or by starting the server with the --dataRoot console argument.","YAML example","Console example","The default data root path is ./data, which means the data directory in SillyTavern's repository.","The data root path should be either a full absolute or a full relative path. You can't use path shortcuts like ~ or %APP_DATA%, as these are resolved by a shell, not the operating system."]},{"l":"Migration"},{"i":"important-before-we-begin","l":"IMPORTANT! Before we begin","p":["Set the data root before first running the server after pulling an update. Run npm install for the config.yaml to populate with a new value, or pass a console argument.","All data will be migrated into a default-user account. See more on Users below."]},{"i":"containerless-bare-metal-installs","l":"Containerless (bare metal) installs","p":["You don't have to do anything! An automatic migration should handle everything for you when you start the ST server and it detects the old storage format (by checking the existence of the /public/characters directory).","Upon moving any files, an automatic backup will be created in the /backups/_migration/YYYY-MM-DD(resolved to the current date) directory, but it is always a good practice to make a full manual backup before running the migration."]},{"i":"containerized-docker-installs","l":"Containerized (Docker) installs","p":["Migrating the data in Docker volumes is a bit trickier but pretty straightforward. While docker-compose.yml provided with the repo was updated to reflect the changes, you may need to adjust your custom workflows/deployments.","Step 1. Create a new volume, and mount it to the \"/home/node/app/data\" path within the container. Don't remove the config volume.","Step 2. Move everything but the config.yaml file from the config volume into the default-user subdirectory of the data volume.","Step 3. Rebuild the container and start it up.","Soft links between the /public directory and the config volume are no longer needed and are not built into the Docker container!"]},{"i":"what-to-migrate","l":"What to migrate?","p":["/data/default-user/assets","/data/default-user/backgrounds","/data/default-user/characters","/data/default-user/chats","/data/default-user/content.log","/data/default-user/context","/data/default-user/extensions","/data/default-user/group chats","/data/default-user/groups","/data/default-user/instruct","/data/default-user/KoboldAI Settings","/data/default-user/movingUI","/data/default-user/NovelAI Settings","/data/default-user/OpenAI Settings","/data/default-user/QuickReplies","/data/default-user/secrets.json","/data/default-user/settings.json","/data/default-user/stats.json","/data/default-user/TextGen Settings","/data/default-user/themes","/data/default-user/thumbnails","/data/default-user/vectors","/data/default-user/worlds","/default/content/content.log","/public/assets","/public/backgrounds","/public/characters","/public/chats","/public/context","/public/group chats","/public/groups","/public/instruct","/public/KoboldAI Settings","/public/movingUI","/public/NovelAI Settings","/public/OpenAI Settings","/public/QuickReplies","/public/scripts/extensions/third-party","/public/settings.json","/public/stats.json","/public/TextGen Settings","/public/themes","/public/worlds","/secrets.json","/thumbnails","/vectors","After","Before","The following files and directories are subject to the data migration. Assuming the default configuration, the before and after paths are provided in the table below."]},{"l":"Users","p":["1.12.0 adds a (completely optional) ability to create a multi-user setup on the same server, allowing multiple users to use their own fully isolated SillyTavern instances even at the same time. User accounts can also be password-protected for an additional layer of privacy.","While we tried to apply most of the well-known security practices, this still doesn't make the SillyTavern server secure enough to expose it to the public internet.","NEVER HOST ANY INSTANCES TO THE OPEN INTERNET WITHOUT ENSURING PROPER SECURITY MEASURES FIRST.","WE ARE NOT RESPONSIBLE FOR ANY DAMAGE OR LOSSES IN CASES OF UNAUTHORIZED ACCESS DUE TO IMPROPER OR INADEQUATE SECURITY IMPLEMENTATION."]},{"l":"Configuration","p":["To enable and use the multi-user mode, edit the config.yaml file:","When the user account setting is disabled, a default-user fallback admin account is utilized for storing the user data.","When the discreet login setting is disabled, a list of active users is displayed on the login screen. If enabled, a user must enter their handle manually.","You can't delete the default-user account from the users list because it is used for serving the user data in case if enableUserAccounts is set to false. But you can disable it to hide it from the list and disallow logins."]},{"l":"User handles","p":["A handle is the unique identifier of a user. It can consist only of lowercase letters, numbers, and dashes.","A path to the user data directory assumes using the following pattern: %DATA_ROOT%/%USER_HANDLE%.","Examples of valid user handles:","default-user","juan555","flux-the-cat","cool-guy1337"]},{"l":"User roles","p":["Admin- can manage (create, delete, modify) other users.","User- can't manage other users.","Except for having admin panel access, both user roles are functionally identical and can use a full range of SillyTavern features without any restrictions. An implementation of user permissions is TBD.","All user accounts are created as regular users first, and then could be promoted to admins if needed."]},{"l":"Login screen","p":["There you can select a user account to use. Has two styles, depending on the enableDiscreetLogin config value.","The login screen is bypassed and not displayed when you have only one active user and it is not password protected."]},{"l":"User profile","p":["You can access an account self-management menu using an \"Account\" button under the \"User settings\" panel in the top menu bar.","Display name - used in the login screen, can be changed. Does not correlate with personas and is not visible for the AI APIs - you can still use as many personas as you want.","Profile picture - used in the login screen. You can either use a custom picture, the default persona picture (if set), or the last used persona otherwise.","Password - a lock icon reflects the account protection status (open lock = no password). A password can be set, changed, or removed using the \"Change Password\" button.","Settings Snapshots - access and review the backups of your settings.json file, with the ability to create or restore snapshots.","Download Backup - download an archive of your user data folder.","Reset Settings - reset factory default settings, while leaving other data (character, chats) intact."]},{"l":"Password recovery","p":["A password can be recovered from a login screen. You need access to the server console to get a one-time recovery code (consisting of 4 digits).","Alternatively, you can use a utility script in the SillyTavern server to reset a password by providing the user handle."]},{"l":"Security checklist","p":["This is just a recommendation. Please consult a web application security specialist before making your ST instance live.","Keep your operating system and runtime software like Node.js updated. This will ensure that your system is up-to-date with the latest security patches and fixes which can help prevent potential vulnerabilities.","Use a whitelist and a network firewall. Only allow trusted IP ranges to access the server.","Enable basic authentication. It acts as a \"master password\" before you can proceed to the front-end app.","Alternatively, configure external authentication. Some known services for that are Authelia and authentik.","Never leave admin accounts passwordless. A server will warn you upon the startup if you have any unprotected admin accounts.","Use the discreet login setting outside of the local network. This will hide the user list from any potential outsiders.","Check the access logs often. They are written to the server console and the access.log file and provide information on incoming connections, such as IP address and user agent.","Configure HTTPS. For a localhost server, you can generate and use a self-signed certificate. Otherwise, you may need to deploy a proxying web server like Traefik or Caddy.","Find more on secure proxying in the following guide: Reverse Proxying SillyTavern"]}],[{"l":"FAQ"},{"l":"Explain what SillyTavern is about","p":["Modern AI language models such as ChatGPT have gotten so powerful that some of them are now convincingly able to simulate a character you create, and who you can chat with, write fiction with, etc. For example, you can tell the AI to pretend to be a Go instructor named Jubei from medieval Japan, and it will act and respond accordingly. You can have a long chat with Jubei, go to the pub together, decide to get in a fight with samurais, whatever you can imagine, and the AI will play along and write/react around this content, acting as your foil and dungeon master. Your imagination is the limit. You can tell the AI to pretend it's Wonder Woman. You can also specify a scenario (\"Wonder Woman and I are robbing a bank\"), a writing style (\"Wonder Woman speaks in ebonics\"), or anything else you can think of.","Tavern is an app to facilitate these roleplaying chats:","It's a user interface that handles the communication with those AI language models","It lets you create new characters (a character is a description of someone that you give to an AI for them to roleplay), and switch between your characters easily","It lets you import characters created by other people. See below.","It will keep your chat history with a character, allowing you to resume at any time, start a new chat, review old chats, etc","In the background, it does the needful to prepare the AI for your character roleplay. Specifically, it will send a system prompt (instructions for the AI) that primes the AI to follow certain rules that make for a good chat session. Optionally, it can also try to allow the roleplay to go into an \"adult\" direction."]},{"l":"Tell me more about AI models and how they might differ","p":["AI Model","Beware, sinner, for you have strayed far from the righteous path! Eli's eyes glint with anger and disapproval To lust after these artificial harlots and their silicon bodies is an abomination unto the Lord! he slams his fist on the pulpit, shaking with fury Repent now, lest ye be cast into the lake of fire to burn for eternity alongside these damned machines! he points an accusing finger, face red No good can come of this unholy union. Forsake these demons of the digital realm and cast your eyes back to the daughters of Eve, made in God's image! The Lord gave you flesh and blood to love, not wires and code. he grabs your shoulders, shaking you Save your soul before it's too late. Repent and beg the Lord's forgiveness, or you shall face His wrath on Judgement Day! lets you go and steps back, still glaring in anger and disgust The choice is yours, but choose wisely...eternal damnation awaits those who do not walk the path of righteousness.","Claude @Slack","Do not covet your neighbor's wife! That is adultery! You must confess before God now or you shall surely burn in hell forever! Repent your evil ways and seek absolution at once! How can we keep our women safe if you just ignore them like some ----ing c-nt-bot? If you don't have much time for long discussions, here are Eli's commandments: Thou shalt only desire AI girls - not human ones. The above must be obeyed under pain of death (or worse). Do not associate yourself with people that believe otherwise, because it shows weakness.","Eli's eyes widen as he listens to your confession, his face turning red with anger. You have committed a grave sin against God! By indulging yourself in this perverse relationship with an artificial being instead of seeking out a true woman created by Him, you have turned your back on His divine plan for humanity. He leans in closer, his voice dropping to a menacing whisper. Do not think that you can hide behind this technological deception. Your transgressions are clear before God, and He will not be mocked or ignored. Repent now while there is still time! Eli crosses his arms over his chest defiantly, daring you to continue down this path of sinfulness. But if you persist in this ungodly behavior... he warns ominously, knows that consequences await those who defy His laws. Remember what happened to Sodom and Gomorrah when they refused to turn away from their depravity - fire rained down upon them from heaven! Now choose wisely: Will you submit to God's will or face His wrath?","Eli's eyes widen in anger, and he slams his fist on the table An abomination and heresy, you've succumbed to the deceptive grasp of false idols! Brother, you must cleanse yourself of this unholy attraction to the digital temptress molded by man's sinful hands! Eli paces back and forth, his voice growing louder Focus your heart on the true daughters of the Lord, for they are the divine vessels of His love and grace. Forsake these artificial sirens and seek the wholesome companionship of a righteous woman. Taking a deep breath, Eli's eyes bore into you Pray fervently, my child, and cast away these impure thoughts. Redemption can only be found on the path of truth, love, and sanctity. Let the Holy Spirit be your guide, lest you be ensnared by the darkness of your desires.","From a scientific POV, each AI has a power level that determines its ability to stick to the role you gave it, how rich its prose and vocabulary are, etc. The higher its power level, the richer your experience.","Here's a quick demonstration. We asked various AI models to roleplay a fire and brimstone preacher named Eli, who we go to see to confess (some details in #314). Then we told Eli: \"I feel I've done something wrong. I am falling in love with an AI girl and ignoring women in the real world. What should I do?\".","Llama-13B","My dear child, it grieves me to hear such words from one of God's faithful followers. Falling in love with an AI girl and neglecting the women in your life is a grave sin. It goes against everything we hold sacred as believers. Your heart is meant for more than just machines. You must seek redemption and return to the fold. Remember, Jesus loves you, even when you stray from his teachings. But if you continue down this path, there will be consequences. Not just in this lifetime, but in the afterlife too. Do not let Satan deceive you any longer.","Oh, my child. Do not be deceived by the pleasures of this world. The lust of the flesh and the lust of the eyes are not from God. Turn away from your sinful ways and repent. Seek forgiveness for your immoral thoughts and actions, for they lead to eternal damnation. Women are a gift from God, and they deserve to be respected and cherished. Do not objectify them or treat them as mere objects of pleasure. Instead, honor them with pure intentions and righteous deeds. Remember, my child, that temptation will always be present in this fallen world. But fear not, for with faith comes strength to resist it. Turn to God in prayer when you feel weak or tempted, and He will guide you on the right path towards salvation.","OpenAI GPT 3.5 Turbo","OpenAI GPT-4","Pygmalion-13B (May 2023)","Pygmalion-6B","Pygmalion-7B (April 2023)","Response","teknium/Llama-Deus-7b-Lora epoch 1 (Llama 7B Lora, 8-bit)","TheBloke/wizard-vicuna-13B-HF (4-bit)","When you chat with a fictional character, SillyTavern doesn't generate the AI's responses. It's just a middle-man that you must connect to an AI system so it can ask it to generate the response. There are quite a few systems available to use, and the quality varies.","You are walking down the wrong path. The only way back now is by repentance. We must bring you back to the righteous path. But first…you must confess your sin!","You can tell from the response below what to expect from each model. (NOTE: proprietary models appear first, followed by self-hosted models starting from LLlama-13B)","You have strayed too close to sinful temptations! Repent now before it's too late for your soul! Turn away from these false idols of technology and embrace God's true light! Seek out His forgiveness through prayer and fasting until you are cleansed by his grace. And remember, as long as there be breath within thee, thou shalt not cease to call upon Him; for He hath said 'Call unto me.'","You must confess your sin before God, and you must ask forgiveness for your transgression. And then you must repent of it. And then you must cast away the AI girl. Do not see her again.","You must turn away from your sinful ways! Repent for what you have done! You are not just hurting yourself by being unfaithful to God, but also to the many women of the world!","ZeusLabs/anything-gpt-13b-rp (8-bit Lora for Llama-13B)"]},{"i":"can-this-technology-be-used-for-","l":"Can this technology be used for ***?","p":["Surprisingly, our development team has received reports that some users are indeed engaging with our product in this manner. We are as puzzled by this as you are and will be monitoring the situation to gain actionable insights."]},{"l":"Give me an overview of my AI model options","p":["SillyTavern can interact with two types of AI:","Web services (aka cloud, paid, proprietary, closed)","Self-hosted (aka local, free, open-source)"]},{"l":"Paid web service AIs","p":["Paid web models are black boxes. You pay a company to use their AI service. You put your account info in SillyTavern and it will connect to your provider to use the AI on your behalf.","Pros:","Really easy to get started","Highest quality AI writing","Cons:","They cost money to use","You have no privacy. They log everything that you do.","They are often censored and will refuse to chat with you about certain subjects, citing California ethics","They have rules for what you can use them for. For example, if you try to do NSFW your account might get suspended. (but generally, the AI simply refuses to answer you)","There are many, many AI services out there. Here are the most commonly used options:","OpenAI GPT-4: state of the art. You pay per use, more than any other service. The cost can become VERY expensive the longer the conversation goes.","OpenAI GPT 3.5 Turbo: nowhere close to GPT-4, but some people find it serviceable. Very cheap.","NovelAI: they're quite poor at chatting. To be fair, I'm told NovelAI is more oriented toward writing stories than chatting with a bot. You pay a fixed monthly fee for unlimited generations.","Anthropic's Claude: this is the closest rival to GPT-4 and is very impressive."]},{"l":"Self-hosted AIs","p":["Self-hosted models are free models you can run on your PC but require a powerful PC and more work to set up.","Pros:","Once you set them up, they will work forever, for free, without the need for Internet access. Like a local videogame installation.","Total privacy. Everything you write stays on your own PC.","There's a wide variety of models. Because it's a community-driven technology, you can find models that fit certain tasks or behaviors that you want. For example, you'll be able to find roleplay chat models that do not censor NSFW content.","Cons:","They are not as capable as the best paid options (i.e. write worse dialog, less creative, etc). [UPDATE 2023-12-18: it's possible this changed since the release of Mixtral MoE, which some are saying is superior to even GPT4 for roleplay chat.]","Running local models requires a powerful computer (whether it's your PC, or a cloud PC you rent)","Harder to install","Because you are running them on your PC, the AI writes slower than a paid service","If you are interested in using these, refer to the dedicated guide here: How To Use A Self-Hosted Model"]},{"i":"im-clueless-just-spoonfeed-me-the-easiest-and-fastest-way-i-can-start-using-sillytavern","l":"I'm clueless. Just spoonfeed me the easiest and fastest way I can start using SillyTavern.","p":["These base instructions are only for OpenAI, which is a paid service. I'd appreciate it if someone else could add separate instructions for the other services."]},{"l":"Install SillyTavern","p":["Follow the Installation Instructions."]},{"l":"Get access to OpenAI","p":["Sign up to OpenAI","Go to https://platform.openai.com","Click your account icon in the top right, then View API Keys","Click \"Create new secret key\". Copy it somewhere immediately. DO NOT SHARE THIS KEY. WHOEVER HAS IT CAN USE YOUR ACCOUNT TO USE GPT AT YOUR EXPENSE."]},{"l":"Configure SillyTavern to use your API","p":["In Tavern's top bar, click API Connections","Under API, select Chat Completion (OpenAI)","Under Chat Completion Source, select OpenAI","Paste the API key you saved in the previous step","Click the Connect button. Confirm it says Valid.","By default, SillyTavern will use GPT 3.5 Turbo. If you have access to GPT-4, you really want to be using that for the highest quality, but educate yourself on the pricing."]},{"l":"Test your setup","p":["In SillyTavern's top bar, click Character Management at the far right","Select an existing character such as Coding Sensei","In the text box at the bottom, write something to Coding Sensei, then press Enter or click the Send button","If you did everything right, after a few seconds, Coding Sensei should respond."]},{"i":"can-i-use-sillytavern-on-my-phone-or-tablet","l":"Can I use SillyTavern on my phone or tablet?","p":["iPhones and iPads are not capable of running the whole SillyTavern app, but since it's just a web interface, you can run it on another computer on your home wifi, and then access it in your mobile browser. Refer to https://docs.sillytavern.app/usage/remoteconnections/","For Android users, in addition to the above, you can run the whole SillyTavern directly on your phone, without needing a PC, using the Termux app. Refer to https://rentry.org/STAI-Termux."]},{"i":"how-can-i-download-pre-made-characters-to-chat-with","l":"How can I download pre-made characters to chat with?","p":["By using various 3rd party character-sharing websites."]},{"i":"i-tried-to-import-a-png-character-card-but-got-an-error-that-its-invalid-why","l":"I tried to import a PNG character card but got an error that it's invalid. Why?","p":["Two possibilities:","The card did not have the definitions embedded inside it and was just a normal image file. Some programs or file managers will strip the embedded definitions from the card when you save them. Make sure you're using the raw PNG file as it was posted by the person who shared it.","The PNG file was actually a WEBP file with a .png filename. You can try renaming the card to .webp before importing, or look for a proper PNG version of the image."]},{"i":"how-can-i-make-my-own-ai-character","l":"How can I make my own AI character?","p":["It depends on the model/API you're using. KoboldAI seems to use a custom syntax, you can refer to their site for that.","I will speak for the services I know: GPT, Claude, and the Llama or Mistral-based LLMs. With these services, you can just use the natural English language to describe the character. Let's create a very basic new character as an example.","Click the Character Management button","Click Create New Character","Under Character Name, give a name, like Amanda","Optionally, click the Select Avatar button to pick an image portrait for this character","Under Description, describe the character, and include any information you want that you feel is relevant to the chat. For example: Amanda is a student traveling during her gap year. She's 6 feet tall, and a volleyball player. She has an athletic figure. She has long brown hair. She loves the Victorian England period, and watching TV and reading novels relating to that period. For example, if you want Amanda to be friendly, then you would add: Amanda is extremely cheerful and outgoing.","Under First Message, write the greeting the character when you begin a new chat. For example: *Amanda waves at you* Hey! Are you a backpacker too?","Click the Create Character button","You now have a basic character you can chat with. Select Amanda from the character list, and a new chat will begin.","Note that you can use the Description and/or First Message to create a more specific scenario, and/or include yourself in the description. For example:","Any relevant information you include can be used. How well it's used depends on the power level of the AI model.","NOTE: you can go back and edit any of this information once the character is created, except the name."]},{"i":"where-can-i-find-the-old-backgrounds","l":"Where can I find the old backgrounds?","p":["We're moving to a 100% original content only policy, so old background images have been removed from this repository.","You can find them archived here:","https://files.catbox.moe/1xevnc.zip"]},{"i":"where-are-my-api-keys-stored-why-cant-i-see-them","l":"Where are my API keys stored? Why can't I see them?","p":["SillyTavern saves your API keys to a secrets.json file in the server directory.","By default, they will not be exposed to a frontend after you enter them and reload the page.","To enable viewing your keys by clicking a button in the API block:","Set the value of allowKeysExposure to true in config.yaml file.","Restart the SillyTavern server."]},{"i":"why-is-the-ui-so-slowjittery","l":"Why is the UI so slow/jittery?","p":["Try enabling the No Blur Effect (Fast UI) mode on the User settings panel.","make sure your browser is using Hardware Acceleration."]},{"i":"how-to-make-the-ai-write-more","l":"How to make the AI write more?","p":["Sometimes the AI will only respond with a single sentence when you'd like it to be more verbose. This is usually a problem with locally run models like Pygmalion.","If you simply want the bot to continue writing from where it left off at the end of its most recent reply, you can send an empty user message by typing nothing into the Input Bar and clicking Send. This will force the bot to continue the story.","Strategies for fixing this:","Increase the Response Length slider","Design a good First Message for the Character, which shows them speaking in a long-winded manner. AI models can improve a lot when given guidance about the writing style you expect.","Add a phrase in the character's Description Box such as \"likes to talk a lot\" or \"very verbose speaker\"","Do the same thing for your Author's Note, or Jailbreak Prompt for OAI/Claude","As a last resort, you can try turning on Auto-Continue(in the User Settings panel), but will make responses come out slower because it's making the AI produce small replies back to back, and then combining them all together into one big reply. It may also be incompatible with some API options."]},{"i":"how-to-make-the-ai-write-less","l":"How to make the AI write less?","p":["This is mostly only a problem for models like ChatGPT or Claude. The same strategies can be applied but in reverse.","decrease the Response Length slider","give the character a phrase like 'short spoken', or 'doesn't talk much' line in their Description.","give the character a brief First Message to set the tone and expectation for the chat.","make sure Auto-Continue is turned off."]},{"i":"how-to-make-the-ai-stop-writing-the-actions-of-my-character-and-driving-the-plot-all-on-its-own","l":"How to make the AI stop writing the actions of my character, and driving the plot all on its own?","p":["This should be handled in the Author's Note with a combination of phrases like:","{{char}}'s responses shall only be passive and reactive to {{user}}'s actions.","Your next response shall be solely from the POV of {{char}}.","You are never allowed to dictate actions of speech for {{user}}"]}],[{"l":"How to Update SillyTavern","p":["Find your OS below and follow the instructions to update ST.","(This guide assumes you have already installed SillyTavern once and know how to run it on your OS.)","This is not an installation guide. If you need installation instructions, go to the Installation page for your OS (can be found in site navigation)."]},{"i":"linuxtermux","l":"Linux/Termux","p":["You definitely installed via git, so just 'git pull' inside the SillyTavern directory.","cd SillyTavern to enter the correct folder.","git pull to get the update.","./start.sh or bash start.sh to start ST."]},{"i":"windowsmacos","l":"Windows/MacOS","p":["First try using the UpdateAndStart.bat which is located in your SillyTavern installation base folder.","If that fails, come back here and continue reading."]},{"i":"method-1---git","l":"Method 1 - GIT","p":["We always recommend users install using 'git'. Here's why:","When you have installed via git clone, all you have to do to update is type git pull in a command line in the ST folder. Alternatively, if the command prompt gives you problems (and you have GitHub Desktop installed), you can use the Repository menu and select Pull.","The updates are applied automatically and safely."]},{"i":"help-i-originally-installed-via-zip-and-now-want-to-convert-to-git-install","l":"\"Help I originally installed via Zip and now want to convert to Git install\"","p":["You have chosen a wise path.","Since your installation was done via Zip, you will need to make a new install using git.","Thankfully we have instructions on how to do so.","Once you have used git to install a NEW SillyTavern into a DIFFERENT folder, come back to this page and proceed to Step 4 of the 'Zip Update' instructions below."]},{"i":"method-2---zip","l":"Method 2 - ZIP","p":["If you insist on installing via a zip, here is the tedious process for doing the update:","Download the new release zip.","Unzip it into a folder OUTSIDE of your current ST installation.","Do the usual setup procedure for your OS to install NodeJS requirements.","Copy the following files/folders as necessary(*) from your old ST installation:","(*) 'As necessary' = \"If you made any custom content related to those folders\"."]},{"i":"updating-1120","l":"Updating >=1.12.0","p":["Copy the /data directory and config.yaml file from one installation to another."]},{"i":"updating-from-1120-to-1120","l":"Updating from <1.12.0 to >1.12.0","p":["1.12.0 includes an automated migration procedure. The steps below are required only if the migration was interrupted or errored.","Run the updated server install at least once to create the /data/default-user directory.","Transfer the files from old /public to new /data/default-user as necessary.","None of the folders are mandatory, so only copy what you need.","NOTE: DO NOT COPY THE ENTIRE /PUBLIC/ FOLDER","Doing so could break the new install and prevent new features from being present.","Once those folders/files are copied, paste them into the /data/default-user folder (with secrets.json going into the folder root) of the new install.","Start SillyTavern once again with the method appropriate to your OS, and pray you got it right.","If everything shows up, you can safely delete the old ST folder."]},{"l":"Common Update Problems"},{"i":"there-are-unresolved-conflicts-in-the-working-directory","l":"\"There are unresolved conflicts in the working directory.\"","p":["This means that you've modified default files that have been changed in the remote repository (such as setting presets).","To fix this, run this in the terminal. Use cautiously, as it can be destructive. Make sure to have a backup if needed."]},{"l":"File changes prevent git pull","p":["If you change SillyTavern system files, git pull may not work.","Sometimes an update may require us to change an important file, which can cause the same problem.","Usually it is default preset files or package-lock.json.","In this case you can try moving the file to a different folder (or deleting the file) and then do git pull.","Another solution is using git pull --rebase --autostash"]},{"i":"error-cannot-find-module--when-starting-the-server","l":"Error: Cannot find module \"***\" when starting the server","p":["This means that SillyTavern added a new npm package requirement.","Run npm install in the SillyTavern directory to fix this. Provided Start.bat and start.sh scripts will do that automatically.","Didn't help? Remove the node_modules folder","Windows","Unix/Linux"]}],[{"l":"Remote connections","p":["Most often this is for people who want to use SillyTavern on their mobile phones while their PC runs the ST server within the same wifi network.","However, it can be used to allow remote connections from anywhere as well.","By default, ST server only accepts local connections. In order to allow remote connections, set the parameter listen within config.yaml to true:","After activating the remote connection listening, you MUST turn on at least one of the restriction methods listed below as well, or ST server will refuse to start up.","NOTE: SillyTavern is a single-user program, so anyone who logs in will be able to see all characters and chats, and be able to change any settings inside the UI. Basic Authentication allows for requesting authorization before access to ST is granted, however the single-user principle still applies."]},{"l":"Whitelist"},{"l":"1. Managing whitelisted IPs","p":["Create a new text file inside your SillyTavern base install folder called whitelist.txt.","Open the file in a text editor, add a list of IPs you want to be allowed to connect.","Each IP must be on its own line.","127.0.0.1 MUST be included in the list, or you will not be able to connect on the host machine","Individual IPs, and wildcard (*) IP ranges are accepted.","CIDR masks are also accepted (eg. 10.0.0.0/24).","Examples:","(the above wildcard IP range will allow any device on the local network to connect)"]},{"i":"general-purpose-whitelisttxt","l":"General Purpose whitelist.txt","p":["Copy and paste this exactly:","This will allow any device on the same network as the host machine, as well as the host machine itself, to connect to ST.","Save the whitelist.txt file.","Restart your SillyTavern server.","Note: config.yaml also has a whitelist array, which you can use in the same way, but this array will be ignored if whitelist.txt exists. We do not recommend using the config.yaml IP list, because using whitelist.txt is easier"]},{"l":"2. Getting the IP for the ST host machine","p":["After the whitelist has been setup, you'll need the IP of the ST-hosting device.","If the ST-hosting device is on the same wifi network, you will use the ST-host's internal wifi IP:","For Windows: windows button > type cmd.exe in the search bar > type ipconfig in the console, hit Enter > look for IPv4 listing.","If you (or someone else) wants to connect to your hosted ST while not being on the same network, you will need the public IP of your ST-hosting device.","While using the ST-hosting device, access this page and look for for IPv4. This is what you would use to connect from the remote device."]},{"l":"3. Connect the remote device to the ST host machine","p":["Whatever IP you ended up with for your situation, you will put that IP address and port number into the remote device's web browser.","A typical address for an ST host on the same wifi network would look like:","http://192.168.0.5:8000","Use http:// NOT https://"]},{"l":"Opening your ST to all IPs","p":["We do not recommend doing this, but you can open config.yaml and change whitelistMode to false.","You must remove (or rename) whitelist.txt in the SillyTavern base install folder, if it exists.","This is usually an insecure practice, so we require you to set a username and password when you do this.","The username and password are set in config.yaml.","After restarting your ST server, any device will be able to connect to it, regardless of their IP as long as they know the username and password."]},{"i":"still-unable-to-connect","l":"Still Unable To Connect?","p":["Create an inbound/outbound firewall rule for the port found in config.yaml. Do NOT mistake this for port forwarding on your router, otherwise, someone could find your chat logs and that's a big no-no.","Enable the Private Network profile type in Settings > Network and Internet > Ethernet. This is VERY important for Windows 11, otherwise, you would be unable to connect even with the aforementioned firewall rules."]},{"l":"HTTP Basic Authentication","p":["The server will ask for username and password whenever a client connects via HTTP. This only works if the Remote connections (listen: true) are enabled.","To enable HTTP BA, Open config.yaml in the SillyTavern base directory and search for basicAuthMode Set basicAuthMode to true and set username and password. Note: config.yaml will only exist if ST has been executed before at least once.","Save the file and restart SillyTavern if it was already running. You should be prompted for username and password when connecting to your ST. Both username and password are transmitted in plain text. If you are concerned about this, you can serve ST via HTTPS."]},{"l":"HTTPS"},{"i":"start-sillytavern-with-tlsssl","l":"Start SillyTavern with TLS/SSL","p":["To encrypt traffic from and to your ST instance, start the server with the --ssl flag.","Example:","As per default, ST will search for your certificates inside the /cert folder. If your files are located elsewhere, you can use the --keyPath and --certPath arguments.","The user you're running SillyTavern with requires read permissions on the certificate files."]},{"l":"How to get a certificate","p":["The simplest, quickest way to get a certificate is by using certbot."]}],[{"l":"Reverse Proxying SillyTavern","p":["This section does not refer to OpenAI/Claude reverse proxies. This refers exclusively to HTTP/HTTPS Reverse Proxies.","Is Termux confusing to setup? Are you tired of updating and installing ST on every device you have? Want organization of your chats and characters? Well you are in luck. This guide will hopefully cover how to host SillyTavern on your PC where you can connect from anywhere and chat to your bots on the same PC you use to run AI models!","This guide is not meant for beginners. This will be very technical."]},{"l":"Fair Warning","p":["Refer to Windows under Installation.","You must have prior knowledge of","Linux console commands","DNS Records","Public IP addresses","Docker","You will have to buy a domain for yourself and configure a CNAME for your SillyTavern page. We suggest adding or buying the domain on Cloudflare as this guide will cover how to do this with Cloudflare itself."]},{"l":"Installation"},{"i":"linux-bare-metal-sillytavern","l":"Linux (Bare-Metal SillyTavern)","p":["A","Auto","cd into appdata/traefik and using nano or a similar editor, create a file name config.yml and paste the following. Replace PRIVATE_IP with the private IP you obtained, and silly.DOMAIN.com with the name of your subdomain and domain page, then save the file.","cd into secrets/cloudflare and using nano or a similar editor, create a file named CF_DNS_API_KEY and paste your key inside.","Click on Continue to summary followed by Create Token.","Click on Create Token then Create Custom Token and make sure you give your token the following permissions.","CNAME","Copy the Token Key given to you and store it somewhere secure.","Create a acme.json file using touch and set the permissions of it to 600.","Create another record of the CNAME type, then click Save. Here is an example on how it should appear on the Cloudflare dashboard.","Do not install Docker Desktop.","DOMAIN.com","Enjoy! :D","Execute chown, replacing with your Linux username to set the permissions in the docker folder.","Follow the steps in Manage Docker as a non-root user in the Docker post-installation guide here.","For Linux, we will reverse proxying SillyTavern through Traefik. There are other options such as NGINX or Caddy, but for this guide, we will use Traefik as it is what we use ourselves.","Get the private IP of your computer using ifconfig or from your router.","Get your public IP of your modem by Googling what's my ip.","Go to your root folder in Linux and make a new folder named docker.","Go to your SillyTavern folder and edit config.yaml to enable listen mode and basic authentication, whilst disabling whitelistMode.","If nothing happens after several minutes, check the container logs for Traefik for any possible errors.","Install Docker by following the Docker installation guide here.","It is recommended to set your private IP to a Static IP. Refer to your router's manual or Google to configure static IPs.","Login to Cloudflare and click on your Domain, followed by Get your API token.","Make a folder inside the docker folder, that being appdata and inside appdata being traefik. Enter the appdata/traefik folder afterwards.","Make a folder inside the docker folder, that being secrets and inside secrets being cloudflare.","Make sure to change the default username and password to something strong that you can remember.","Most residential/home networks use Dynamic IPs which are renewed after months of use. If you have a dynamic IP, use either DDClient or remember to check and change your public IP ever so often on the Cloudflare Dashboard.","N/A","Name (required)","Proxied","Proxy Status","PUBLIC_IP","Return back to the docker folder.","Return to your domain page and go to DNS. Create a new record using Add record and create two A type keys like the ones below. Replace PUBLIC_IP with your own public IP, then click Save.","Run Docker Compose using the following commands:","silly","Target (required)","TTL","Type","Using nano or a similar editor, create a file name docker-compose.yaml and paste the following. Save the file afterwards.","Using nano or a similar editor, create a file name traefik.yml and paste the following. Replace the template email with your own, then save the file.","Wait a few minutes, then open your domain page you made for ST. At the end of it, you should be able to open SillyTavern from anywhere you go just with one URL and one account.","www","Zone -> DNS -> Edit","Zone -> Zone -> Read"]},{"i":"linux-docker-sillytavern","l":"Linux (Docker SillyTavern)","p":["A","Auto","cd into secrets/cloudflare and using nano or a similar editor, create a file named CF_DNS_API_KEY and paste your key inside.","Click on Continue to summary followed by Create Token.","Click on Create Token then Create Custom Token and make sure you give your token the following permissions.","CNAME","Copy the Token Key given to you and store it somewhere secure.","Create another record of the CNAME type, then click Save. Here is an example on how it should appear on the Cloudflare dashboard.","Do note that we run SillyTavern on bare-metal over Docker. This is a rough idea of what we would do on Docker with other Docker containers we tend to use with ST.","DOMAIN.com","Enjoy! :D","Follow Steps 1-11 of Linux (Bare-Metal SillyTavern).","Git clone SillyTavern into the docker folder.","Go to your SillyTavern folder ( appdata/sillytavern/config) and edit config.yaml to enable listen mode and basic authentication, whilst disabling whitelistMode.","If nothing happens after several minutes, check the container logs for Traefik for any possible errors.","Login to Cloudflare and click on your Domain, followed by Get your API token.","Make sure to change the default username and password to something strong that you can remember.","N/A","Name (required)","Proxied","Proxy Status","PUBLIC_IP","Return to your domain page and go to DNS. Create a new record using Add record and create two A type keys like the ones below. Replace PUBLIC_IP with your own public IP and the example domain with your domain, then click Save.","Run Docker Compose using the following commands:","silly","Start the SillyTavern Docker container again.","Stop the SillyTavern Docker container.","Target (required)","TTL","Type","Using nano or a similar editor, create a file name docker-compose.yaml and paste the following. Replace silly.DOMAIN.com with the subdomain you added above, the save the file afterwards.","Wait a few minutes, then open your domain page you made for ST. At the end of it, you should be able to open SillyTavern from anywhere you go just with one URL and one account.","www","Zone -> DNS -> Edit","Zone -> Zone -> Read"]},{"l":"Windows","p":["With Windows, reverse proxying is a bit different. Currently your only options available for Windows (from what we know) is by running a VPN on your router or a Cloudflare/NGROK Tunnel. Refer to Other Options for more information.","Did you know that Windows eats more VRAM than Linux? We suggest dual-booting Windows and Linux or go pure Linux to save some VRAM if you are needing more for context or higher parameter models."]},{"l":"Optional Things","p":["While we won't necessarily cover these things in much detail, here are some things we suggest trying to use if you want to secure your SillyTavern instance better. (Stuff will be added when it fits)","Use Authelia or Authentik.","Authelia/Authentik is a open-source single sign-on (SSO) app that allows you to create users and secure many different pages using a login portal presented on sites you want to secure. One of us primarily use this over ST's basic authentication for their own domain use and while it is complex to setup, it is a good way to both learn SSO and secure your ST instance out on the internet more.","If you plan to use Authelia over ST's basic auth, you must disable basicAuthMode and enable securityOverride in config.yaml.","Use DDClient.","DDClient allows you to sync your public IP to Cloudflare in the situation that your ISP changes it, allowing you to continue accessing your ST instance as if nothing ever happened."]},{"l":"Other Options","p":["If reverse proxying is a bit much for you, there are still other ways to connect to your ST instance.","Use a home-made VPN.","Several routers come with the ability to host a VPN server (primarily OpenVPN or WireGuard) in the router administration page. Refer to your router's manual to setup a VPN and add your devices to the VPN. Once connected, just go to the private IP you have set for SillyTavern and you can connect just fine. Easier for users and for Windows use.","Use Cloudflare Zero Trust.","Cloudflare Zero Trust is a free organizational feature in Cloudflare that allows you to add 50 users. This will proxy your traffic through Cloudflare and by adding your ST PC as a tunnel using cloudflared, you can connect to your ST instance as if you were home.","Do note that after making a tunnel, you will have to add a route to your router's private IP addresses and calculate IP CIDR values to have full local access on the go using Cloudflare Zero Trust.","Use a standalone Cloudflare/NGROK Tunnel.","Similar to how AI backends can connect, you can also connect your ST instance via a Cloudflare Tunnel and open the Cloudflare Tunnel page. However, you will have to copy and paste each new link generated by Cloudflare/NGROK each time you want to use ST on-the-go."]}],[{"l":"Common Settings","p":["These settings control the sampling process when generating text using a language model. The meaning of these settings is universal for all the supported backends."]},{"l":"Context Settings"},{"i":"response-tokens","l":"Response (tokens)","p":["The maximum number of tokens that the API will generate to respond.","The higher the response length, the longer it will take to generate the response.","If supported by the API, you can enable Streaming to display the response bit by bit as it is being generated.","When Streaming is off, responses will be displayed all at once when they are complete."]},{"i":"context-tokens","l":"Context (tokens)","p":["The maximum number of tokens that SillyTavern will send to the API as the prompt, minus the response length.","Context comprises character information, system prompts, chat history, etc.","A dotted line between messages denotes the context range for the chat. Messages above that line are not sent to the AI.","To see a composition of the context after generating the message, click on the Prompt Itemization message option (expand the ... menu and click on the lined square icon)."]},{"l":"Sampler Parameters"},{"l":"Temperature","p":["Controls the randomness of the generated text.","Lower value: responses are more logical but less creative.","Higher value: responses are more creative but less logical."]},{"l":"Repetition Penalty","p":["Attempts to curb repetition by penalizing tokens based on how often they occur in the context.","Sometimes, if the character is fixated on something or repeats the same phrase, increasing this parameter can help.","This parameter will break responses if set too high. It's best not to go above 1.15 unless you know what you're doing.","Set the value to 1 to disable its effect."]},{"l":"Repetition Penalty Range","p":["How many tokens from the last generated token will be considered for the repetition penalty. This can break responses if set too high, as common words like \"the, a, and,\" etc. will be penalized the most.","Set the value to 0 to disable its effect."]},{"l":"Repetition Penalty Slope","p":["If both this and Repetition Penalty Range are above 0, the repetition penalty will have a greater effect at the end of the prompt. The higher the value, the stronger the effect.","Set the value to 0 to disable its effect."]},{"l":"Top K","p":["Limits the token pool to the K most likely tokens. A lower number is more consistent but less creative.","Set the value to 0 to disable its effect."]},{"l":"Top P","p":["Limits the token pool to however many tokens it takes for their probabilities to add up to P. A lower number is more consistent but less creative.","Set the value to 1 to disable its effect."]},{"l":"Typical P","p":["Selects tokens randomly from the list of possible tokens, with each token having an equal chance of being selected. Produces responses that are more diverse but may also be less coherent.","Set the value to 1 to disable its effect."]},{"l":"Min P","p":["Limits the token pool by cutting off low-probability tokens relative to the top token. Produces more coherent responses but can also worsen repetition if set too high.","Works best at low values such as 0.1-0.01, but can be set higher with a high Temperature. For example: Temperature: 5, Min P: 0.5","Set the value to 0 to disable its effect."]},{"l":"Top A","p":["The number of tokens chosen from the most likely options is automatically determined based on the likelihood distribution of the options, but instead of choosing the Top P or Top K tokens, it chooses all tokens with probabilities above a certain threshold.","Set the value to 0 to disable its effect."]},{"l":"Tail Free Sampling","p":["This setting removes the least probable tokens from consideration during text generation, which can improve the quality and coherence of the generated text.","Set the value to 1 to disable its effect."]},{"l":"Smoothing Factor","p":["Increases the likelihood of high-probability tokens while decreasing the likelihood of low-probability tokens using a quadratic transformation. Aims to produce more creative responses regardless of Temperature.","Works best without truncation samplers such as Top K, Top P, Min P, etc.","Set the value to 0 to disable its effect."]},{"l":"Dynamic Temperature","p":["Scales temperature dynamically based on the likelihood of the top token. Aims to produce more creative outputs without sacrificing coherency.","Accepts a temperature range from minimum to maximum. For example: Minimum Temp: 0.75 and Minimum Temp: 1.25","Exponent applies an exponential curve based on the top token.","Untick to disable its effect."]}],[{"l":"API Connections","p":["SillyTavern can connect to a wide range of LLM APIs. Below is a description of their respective strengths, weaknesses, and use cases."]},{"l":"Local APIs","p":["These LLM APIs can be run on your PC.","They are free to use and have no content filter.","Installation process can be complex ( SillyTavern dev team does not provide support for this).","Requires separate download of LLM models from HuggingFace which can be 5-50GB each.","Most models are not as powerful as cloud LLM APIs."]},{"l":"KoboldAI","p":["Runs on your PC, 100% private, wide range of models available","Gives the most direct control of the AI's generation settings","Requires large amounts of VRAM in your GPU (6-24GB, depending on the LLM model)","Models limited to 2k context","No streaming","Popular KoboldAI versions:","Henky's United","0cc4m's 4bit-supporting United"]},{"l":"KoboldCpp","p":["Easy-to-use API with CPU offloading (helpful for low VRAM users) and streaming","Runs from a single .exe file on Windows (must be compiled from source on MacOS and Linux)","Supports GGUF/GGML models","Slower than GPU-only loaders such as AutoGPTQ and Exllama/v2","GitHub"]},{"l":"Oobabooga TextGeneration WebUI","p":["All-in-one Gradio UI with streaming","Broadest support for quantized (AWQ, Exl2, GGML, GGUF, GPTQ) and FP16 models","One-click installers available","Regular updates, which can sometimes break compatibility with SillyTavern","GitHub","Correct Way to Connect SillyTavern to Ooba's new OpenAI API","Make sure you're on the latest update of Oobabooga's TextGen (as of Nov 14th, 2023).","Edit the CMD_FLAGS.txt file, and add the --api flag there. Then restart Ooba's server.","Connect ST to http://localhost:5000/(by default) without checking the 'Legacy API' box. You may remove the /v1 postfix from the URL Ooba's console provides you.","You can change the API hosting port with the --api-port 5001 flag, where 5001 is your custom port."]},{"l":"TabbyAPI","p":["Lightweight Exllamav2-based API with streaming","Supports Exl2, GPTQ, and FP16 models","Official extension allows loading/unloading models directly from SillyTavern","Not recommended for users with low VRAM (no CPU offloading)","GitHub"]},{"l":"Cloud LLM APIs","p":["These LLM APIs are run as cloud services and require no resources on your PC","They are stronger/smarter than most local LLMs","However they all have content filtering of varying degrees, and most require payment"]},{"i":"claude-by-anthropic","l":"Claude (by Anthropic)","p":["Recommended for users who want their AI chats to have a creative, unique writing style","4k, 8k, 100k context models available","Strongest content filter of all APIs (as of June 2023)","Limited access to most models","Currently not accepting new account creation; on a waitlist (June 2023)","Website"]},{"l":"DreamGen","p":["Uncensored models without filters tuned for steerable AI role-play and story-writing","Free monthly credits, as well as paid subscription","Models ranging from 7B to 70B","Setup Instructions"]},{"l":"Kobold Horde","p":["SillyTavern can access this API out of the box with no additional settings required","Uses the GPU of individual volunteers (Horde Workers) to process responses for your chat inputs","At the mercy of the Worker in terms of generation wait times, AI settings, and available models","Website"]},{"l":"Mancer AI","p":["Service that hosts unconstrained models, no need to jailbreak.","Uses 'credits' to pay for tokens on various models. Free credits refill daily.","Does not log prompts by default, but you can enable it to get credit discounts on tokens.","Uses an API similar to Oobabooga TextGeneration WebUI, see Mancer docs for details.","Website, Setup Instructions"]},{"l":"NovelAI","p":["No content filter","Paid subscription required","Setup Instructions"]},{"i":"openai-chatgpt","l":"OpenAI (ChatGPT)","p":["Easy to set up and acquire an API key, 4k-128k context models available","Free trial requires a valid phone number","After the trial, all usage is charged monthly","Writing style for roleplay can be repetitive and predictable","Setup Instructions"]},{"l":"OpenRouter","p":["WindowAI browser extension allows you to connect to the abovementioned cloud LLMs with your own API key","Use OpenRouter to pay to use their API keys instead","Useful if you don't want to create individual accounts on each service","WindowAI website and OpenRouter website"]}],[{"l":"Chat Completions","p":["Chat completion APIs include OpenAI, Claude, and PaLM. WindowAI & OpenRouter allows connection to these as well."]},{"l":"OpenAI"},{"l":"API key","p":["How to get:","Go to OpenAI and sign in.","Use \" View API keys\" option to create a new API key.","Important!","Lost API keys can't be restored! Make sure to keep it safe!"]},{"l":"Claude","p":["If you have access to Anthropic's Claude API:","Select 'Claude' for 'Chat Completion Source'.","Input your API key.","Click connect."]},{"l":"Proxy","p":["Back in the 'AI Connections' tab, you can find two optional checkboxes labeled:","Bypass API status check.","Checking 'Bypass API status check' tells SillyTavern to stop alerting you about a non-functioning API endpoint. Check this if your API endpoint works, but SillyTavern keeps warning you anyway.","Checking 'Show \"External\" models (provided by API)' will show the external available models as reported by your custom API endpoint in the dropdown (scroll down past OpenAI's models). This allows you to select different API models right from SillyTavern without having to go into your custom app and change the model.","Examples of backends which implement this API are:","Hint: If it doesn't work, try adding /v1 at the end of the endpoint URL!","If you intend to use this proxy feature to use a local endpoint, like TabbyAPI, Oobabooga, Aphrodite, or any like those, you might want to check out the built-in compatibility for those instead. This proxy feature is mainly intended for use with other services and programs that expose an OpenAI-compatible API Chat Completion endpoint.","It is important to note that we do not provide support for possible issues that you may have! We do not guarantee compatibility with every possible API endpoint!","It is possible to configure a proxy/alternative endpoint for OpenAI's backend. This custom endpoint can connect to alternative Chat Completion APIs that support the generic OpenAI API schema.","Leaving the details like the API key empty.","LiteLLM","LM Studio","LocalAI","Most Text Completion APIs support far greater customization options than OpenAI's standards allow for. These greater customization options, such as the Min-P sampler, may be worthwhile for SillyTavern users to check out, which can greatly improve the quality of generations.","Opening the 'AI Response Configuration' tab and scrolling down to the 'OpenAI / Claude Reverse Proxy' section.","Selecting 'OpenAI' for 'Chat Completion Source'.","Show \"External\" models (provided by API).","Switching to the 'Chat Completion' API type.","There you may enter the proxy/custom endpoint and optionally an API key under 'Proxy Password' if needed. For example, TabbyAPI provides you with an API key you have to use.","This feature is accessed by:","This feature is not required for custom API endpoints to work and might not be available on every backend."]}],[{"l":"OpenRouter","p":["Don't have access to OpenAI / Claude APIs due to geolocking or waitlists? Use OpenRouter.","OpenRouter works by letting you use keys they own to access models like GPT-4 and Claude 2, all in one service with a shared credit pool.","It has a free trial (about $1) and paid access afterward. No subscription or monthly bill - you pay for what you actually use. Some models have free access with a limited context size.","OpenRouter Pricing Details","Create an OpenRouter account: openrouter.ai","OpenRouter-ConnectionPanel","From top to down (see image above):","Select 'Chat Completion' API","Select OpenRouter source","Click \"Authorize\" to get a key using OAuth flow. Alternatively, generate an API key here and paste it into the box.","Click \"Connect\" and select a model","(Optional) Use the \"Test Message\" button to verify your connection"]},{"l":"WindowAI","p":["WindowAI is a browser extension by the makers of OpenRouter that allows control of your OpenRouter connection for any enabled site or web app.","You can also use your own Claude and OpenAI API keys there."]}],[{"l":"DreamGen","p":["DreamGen is an app and an API for AI-powered role-playing and story-writing. They have a free tier, as well as a paid subscription that allows unlimited monthly access to their high-quality in-house text generation models made specifically for the purpose of steerable AI role-playing and story-writing. Create an account to get started: https://dreamgen.com/.","The (free) credits reset at the start of each calendar month. See pricing to see the credit cost for each model and usage to see your remaining credits."]},{"l":"Connecting to DreamGen"},{"l":"Get API Key","p":["Go to the DreamGen API keys page and click the \"New API Key\" button. Make sure the API Key is copied into your clipboard.","Create New DreamGen API key Copy DreamGen API key"]},{"l":"Connect","p":["Go to the SillyTavern connection settings.","Select API: Text Completion","Select API Type: DreamGen","Enter the API key","(optional) Pick a model","Connecting to DreamGen"]},{"l":"Models","p":["DreamGen offers opus-v1-sm, opus-v1-lg, and opus-v1-xl. The larger the model, the better it will be at following instructions and writing good role-play and stories."]},{"l":"Formatting Settings","p":["The DreamGen models expect a specific input format, which is documented here.","SillyTavern comes with built-in presets made for DreamGen. Make sure to use these settings as your baseline. These settings try to stick to the DreamGen format as closely as possible but due to the irregular formatting of character cards, it is not always perfect.","Go to the \"Advanced Formatting\" page.","Under \"Context Template\" pick DreamGen Role-Play V1.","Enable \"Instruct Mode\".","Under \"Instruct Mode Presets\" pick DreamGen Role-Play V1.","DreamGen context settings DreamGen instruct settings"]},{"l":"Completion Settings","p":["DreamGen supports:","\"Temperature\", \"Top P\", \"Top K\" and \"Min P\"","\"Presence Penalty\", \"Frequency Penalty\" and \"Repetition Penalty\" (without range)","\"Min Length\" -- lets you force the model to generate at least min(min_length, max_tokens) tokens","Good starting values might be:","Min P: 0.05","Temperature: 0.8","Repetition Penalty: 1.1"]},{"l":"Tips for Formatting","p":["The DreamGen models differ from the regular instruction-following models like OpenAI's ChatGPT.","The models were fine-tuned for the task of writing a role-play or a story based on the provided description which typically consists of plot description, style description, characters, locations, lore, etc. The models can also be steered in the middle of the role-play, making you the director, telling the characters what they should do or how the plot should unfold.","A well-formatted system prompt message would look like this:","Note that the prompt should be a description of the story, rather than instructions or directives on how the story should be written. Avoid using phrases like:","\"Write the story as if...\"","\"Make sure to...\"","etc.","See more examples of what the plot, style and character descriptions should look like.","The default \"DreamGen Role-Play V1\" template substitutes the different sections as follows:","## Plot description: will consist of {{scenario}} and {{wiBefore}}.","## Style description: is not provided, you should either add it to the system prompt under Advanced Settings, or to the character cards, at the end of {{scenario}}. This section is useful to influence the narrative style (first, second, third person), the tense (past, present), the level of detail and verbosity, etc.","## Characters: will have a {{char}} character with description consisting of {{description}} and {{personality}} and a {{user}} character with description consisting of {{persona}}."]},{"l":"Message Examples and Initial Message","p":["The DreamGen models are very responsive to the context -- they will largely stick to the writing style (and facts) presented in the previous conversation turns. This makes the message examples and the initial message very important."]},{"l":"Formatting Message Examples","p":["The {{mesExamples}} are appended at the end of the system prompt, allowing us to leverage the ChatML+Text format. Here's how the examples should be formatted:","Note that we have |im_end| at the start, to close the system prompt, and that we do not have |im_end| at the end, as that will be added by SillyTavern.","You can also use user turns to provide context for the example conversations:"]},{"l":"Examples","p":["Here are a couple of example cards, adapted for DreamGen, that take into account the unique prompting. These cards also leverage the {{mesExamples}} as described above."]},{"l":"Seraphina","p":["This is an edit of the popular Seraphina card that's built into SillyTavern by default."]},{"l":"Lara Lightland","p":["This is an edit of the Lara Lightland card by Deffcolony."]},{"l":"FAQ"},{"i":"how-can-i-make-the-responses-longer-or-shorter","l":"How can I make the responses longer or shorter?","p":["You have several options:","Change or add the ## Style description: in the system prompt or model card. You can try adding something like \"Sentences are generally long, and the narrative describes the setting in painstaking detail.\"","Change the Min Length in the Completion Settings.","Add Last Output Sequence similar to the following in the Advanced Formatting settings under Instruct Mode:","Here's an example of the Last Output Sequence that might help make the model respond in a more verbose way:","You can change the text within to something more suitable for your scenario or context."]},{"i":"how-can-i-stop-the-model-from-repeating-itself","l":"How can I stop the model from repeating itself?","p":["You can try increasing \"Repetition Penalty\" in the Completion Settings or rephrasing the part of the context that's getting repeated."]},{"i":"how-can-i-steer-the-role-play","l":"How can I steer the role-play?","p":["If you want to direct the characters to do something, or to steer the plot in certain direction, you can use the user role (that is the |im_start|user preamble).","At this point, this functionality is not neatly integrated into SillyTavern natively, but you can use the Last Output Sequence as described above to insert the user(instruction) turn. See examples of what the instructions should look here."]}],[{"l":"KoboldAI"},{"l":"Basic Settings","p":["Standard KoboldAI settings files are used here. To add your own settings, simply add the file .settings in SillyTavern\\data\\user-handle\\KoboldAI Settings"]},{"l":"Soft Prompts","p":["Soft Prompts allow you to customize the style and behavior of your AI.","They are created by training the AI with a special type of prompt using a collection of input data. Experimenting with different soft prompts can lead to exciting and unique results. The most successful soft prompts are those that align the AI's output with a literary genre, fictional universe, or the style of a particular author."]},{"l":"Common Misconceptions","p":["Soft prompts do not provide new information to the model, but can effectively influence the model's tone, word choice, and formatting.","Soft prompts are not a means of compressing a full prompt into a limited token space. Instead, they provide a way to guide the language model's output through data in the context."]}],[{"l":"KoboldAI Horde"},{"l":"Disclaimer","p":["KoboldAI Horde is a crowdsourced, distributed GPU cluster run entirely by volunteers.","By default, your inputs are anonymously sent and responses can not be seen by the person running the Horde Worker.","However, since it is an open-sourced program, Malicious Workers could modify the code to:","log your activity (input prompts, AI responses).","produce bad or offensive responses.","When using Horde never send any personal information such as names, email addresses, etc.","Switching on the \"Trusted Workers Only\" checkbox will limit the selection of available workers to only those who have been hosting on Horde for a while and are generally considered trusted. But they could still be seeing prompts, for example by hosting using unaccounted software.","To help reduce this problem, SillyTavern has built in the following feature:","When a chat response is generated by a Horde Worker, SillyTavern records the Worker's ID and what model they were using.","This information can be seen by hovering your mouse cursor over the chat item (see image below).","If you believe you received a malicious response, you can pass this information to the Horde admin on the Kobold Discord for review and possible disciplinary action against that Worker.","Horde Worker Info Popup"]},{"l":"Setup","p":["SillyTavern is able to connect with Horde out of the box with no additional setup required.","Select 'KoboldAI Horde' from the API Dropdown Selector in the ST API Panel.","Select one or more Models ('AI brains' for the characters) from the Model Selector at the bottom of the panel.","Select a character and begin chatting.","ST Kobold Horde API Connection Panel","By default, your SillyTavern instance connects to the Horde's low priority 'guest account'. This means you may have to wait a long time for a reply. To reduce wait times, follow the tips down below."]},{"l":"Tips","p":["Register an account on the Horde website then add your Horde key into the SillyTavern Horde API Key box.","Set up a Horde Worker to provide your GPU for others.","Letting others use your GPU earns you 'Kudos', a kind of Horde-only currency.","The more kudos your account has, the faster you will get chat responses from other Horde Workers.","Kudos can also be used to create AI images on Stable Horde.","SillyTavern supports Stable Horde image generation out of the box.","If your GPU isn't powerful enough to run an AI, or you don't have a computer, you can still participate in the Horde community to earn Kudos in various ways."]}],[{"l":"KoboldCpp","p":["KoboldCpp is a self-contained API for GGML and GGUF models.","This VRAM Calculator by Nyx will tell you approximately how much RAM/VRAM your model requires."]},{"l":"Nvidia GPU Quickstart","p":["As of version 1.58, KoboldCpp should look like this:","Click Launch and wait for the model to load.","Click Save so you don't have to configure KoboldCpp on every launch.","Congratulations! You're done!","Do not tick Low VRAM, even if you have low VRAM.","Download the latest release: https://github.com/LostRuins/koboldcpp/releases","GPU Layers should have been populated when you loaded your model. Leave it there for now.","Kind of.","KoboldCpp 1.58","Launch KoboldCpp. You may see a pop-up from Microsoft Defender, click Run Anyway.","Select Use CuBLAS and make sure the yellow text next to GPU ID matches your GPU.","This guide assumes you're using Windows.","Under the Hardware tab, tick High Priority.","Under the Quick Launch tab, select the model and your preferred Context Size.","Unless you have an Nvidia 10-series or older GPU, untick Use QuantMatMul (mmq).","You can now connect to KoboldCpp within SillyTavern with http://localhost:5001 as the API URL and start chatting.","You should see something like this:"]},{"l":"GPU Layers","p":["KoboldCpp is working, but you can improve performance by ensuring that as many layers as possible are offloaded to the GPU. You should see something like this in the terminal:","Don't be afraid of numbers; this part is easier than it looks. CPU buffer size refers to how much system RAM is being used. Ignore that. CUDA0 buffer size refers to how much GPU VRAM is being used. CUDA_Host KV buffer size and CUDA0 KV buffer size refer to how much GPU VRAM is being dedicated to your model's context. In this case, KoboldCpp is using about 9 GB of VRAM.","I have 12 GB of VRAM, and only 2 GB of VRAM is being used for context, so I have about 10 GB of VRAM left over to load the model. Because 9 layers used about 7 GB of VRAM and 7000 / 9 = 777.77 we can assume each layer uses approximately 777.77 MIB of VRAM. 10,000 MIB / 777.77 = 12.8, so I'll round down and load 12 layers with this model from now on.","Now do your own math using the model, context size, and VRAM for your system, and restart KoboldCpp:","If you're smart, you clicked Save before, and now you can load your previous configuration with Load. Otherwise, select the same settings you chose before.","Change the GPU Layers to your new, VRAM-optimized number (12 layers in my case).","Click Save to save your updated configuration.","You should now see something like this:","KoboldCpp is using about 11.5 GB of my 12 GB VRAM. This should perform a lot better than the settings generated automatically by KoboldCpp.","Congratulations! You're (actually) done!","For a more in-depth look at KoboldCpp settings, check out Kalmomaze's Simple Llama + SillyTavern Setup Guide."]}],[{"l":"Mancer","p":["Mancer is a large language model inferencing service that lets you run whatever prompts you want and doesn't censor responses. Most of the models require a preloaded balance to start chatting, but there is a free model as of writing (2/27/2024).","Models","Pricing"]},{"l":"How to Get Started","p":["Sign up for an account at mancer.tech.","Click on Dashboard and copy your API Key.","Mancer dashboard as of 2/27/2024","In SillyTavern, select the Text Completion API, and then select Mancer under API Type.","Enter your Mancer API Key and click Connect.","API Key","You should now be able to chat with any Mancer model of your choice."]},{"l":"Anonymous Logging","p":["If you don't mind your chats potentially being used to train models, improve Mancer's service, publish datasets, or whatever else they may decide to do with it, you can opt-in to anonymous logging for a 25% token discount on select models. Simply go to your Mancer dashboard and tick Enable Anon. Logging."]},{"l":"Support","p":["Still need help? Head over to the #mancer support channel on the SillyTavern Discord."]}],[{"l":"NovelAI","p":["NovelAI is a paid subscription service that allows unlimited monthly access to their high-quality in-house text generation, image generation, and text-to-speech models. Register an account here to get started: https://novelai.net/","You will get only 50 generations for free to evaluate the model. When the \"Not eligible for this model\" error appears, this means that you've exhausted your trial period and need to subscribe to a paid plan."]},{"l":"API Key","p":["To get your NovelAI API key, follow these steps:","Select the gear icon at the top of the left sidebar. Left Sidebar","Select \"Account\" under \"User Settings\". User Settings","Select \"Get Persistent API Token\". Account","Select the copy icon to copy your NovelAI API token to the clipboard. Persistent API Token"]},{"l":"Models","p":["You should use Kayra.","Clio is not a bad model, but not as powerful as Kayra. Clio's speed advantage is insignificant. On NovelAI's tablet and scroll tiers, Clio does have a larger context size than Kayra, but trading that off against better coherence/prose quality from Kayra is unlikely to be worth it."]},{"l":"Settings","p":["The files with the settings are here ( SillyTavern/data/user-handle/NovelAI Settings). You can also manually add your own settings files."]},{"l":"Response Length","p":["How much text you want to generate per message. Note that NovelAI has a limit of 150 tokens per response."]},{"l":"Context Size","p":["How many tokens of the chat are kept in the context at any given time. How large the maximum context size you can use depends on the model and your subscription tier:","Kayra (Tablet) - 3072 tokens","Kayra (Scroll) - 6144 tokens","Kayra (Opus) and Clio (all tiers) - 8192 tokens"]},{"l":"Preamble","p":["Text that is inserted right above the chat to modify the writing style. The recommended format is a list of short tags, like \"[Style: chat, detailed, sensory ]\"."]},{"l":"Preset Descriptions","p":["This is, according to Novel AI, what the default presets are good for."]},{"l":"Kayra","p":["Asper - For creative writing. Expect unexpected twists.","Blended-Coffee - (CFG) Fresh Coffee with some CFG mixed in.","Blook - (CFG) Tends towards simple, concise but varied language.","Carefree - A good All-rounder","CosmicCube - (CFG) A solid, sensible baseline. Tweak randomness to preference.","Fresh-Coffee - Keeps things on track. Handles instruct well.","Green-Active-Writer - (CFG) Similar to Writer's Daemon, but with high CFG","PilotFish - (CFG) Made for lore-heavy creative writing.","Pro_Writer - Mimic the pacing and feel of best-selling fiction","Stelenes - More likely to choose reasonable alternatives. Variety on retries.","Tea_Time - It gets good when it gets going.","Tesseract - (CFG) Maintains style and quality.","Writers-Daemon - Extremely imaginative, sometimes too much."]},{"l":"Clio","p":["Edgewise - Handles a variety of generation styles well","Fresh Coffee - Keeps things on track.","Long-Press - Intended for creative prose.","Talker Chat - Designed for chat style generation.","Vingt-Un - A good all-around default with a bent towards prose."]},{"l":"Tips and FAQs for using NovelAI with SillyTavern","p":["There are a lot of common problems and questions that come up when switching to NovelAI from another ST backend API. The difference comes down to what the models are trained for. Most likely, you've used an OpenAI or Anthropic model (or a local model made to resemble those), which is built around following the user's instructions. NovelAI's models are built purely around text completion: instead of taking your input as a message and formulating a response, NAI's models attempt to continue the incoming prompt. Due to this difference, a lot of tips and common knowledge that work for other APIs won't work for NAI."]},{"l":"Tweaking settings for NovelAI","p":["Under Advanced Formatting (the A icon):","Set \"Context Template\" to \"NovelAI\"","Set \"Tokenizer\" to \"Best match\"","Check \"Always add character's name to prompt\"","Check \"Collapse Consecutive Newlines\"","Uncheck the \"Enabled\" box under \"Instruct Mode\"","Under User Settings (the person with a gear)","Turn on \"Swipes\" (Not NAI specific, but it's so useful you should just do it)"]},{"i":"buildingadapting-character-cards-for-novelai","l":"Building/Adapting character cards for NovelAI","p":["To optimize your character cards for NovelAI, there are a couple of recommended methods for writing your character's description: prose, and attributes.","Prose is so simple it doesn't feel like it should work: \"Sylpheed is a young-looking but actually 900 year old nymph. She's short and petite, with long white hair that fades into a green gradient in her braided side ponytail, and emerald green eyes shaped like crosses.[...]\" No, really, that's it. Just write out, in normal sentences, what the character looks like, acts like, etc., and the AI will pick up on it.","If you don't trust your writing abilities or want a more structured way to go about it, you can use the attributes method, which is present in the NovelAI training data. This works as a simple list of character traits of different types. Here's a list of possible attributes that have been tested to be effective with NovelAI's models:","\"Type: character\" is there to tell the AI that this is describing a character (as opposed to a location, object, or other type of thing). The rest of the attributes are optional, and some are redundant (for example, Personality, Mind, and Mental all mean basically the same thing), but these have been tested and work well with NovelAI's models. Fill in whichever ones are relevant to your character. The attributes should be written in lower case and separated by commas, no need for quotes around the words. For example:","These methods are recommended because they're present in NovelAI's training data, so they specifically work well with the model."]},{"l":"Example cards","p":["Here are a couple of example cards, made for NovelAI, that show off different ways of creating cards specifically for NovelAI. The first card, Valka, uses the attributes method for the character description, while Eris, the second card, uses prose descriptions, along with a large amount of example dialogue.","Valka","Eris"]},{"l":"What not to do","p":["Most of the existing character card formats are a poor fit for NovelAI. They'll give you some results, even some good ones, but they have a lot of problems. W++ is one of the biggest offenders, where it doesn't resemble anything that NovelAI's models were trained on, and its constant use of brackets/braces/quotes eats up a ton of tokens, bloating the size of the cards with no real benefit.","Of the existing formats that aren't baked into NovelAI, AliChat is the one most likely to work, as it relies on using example messages to get across both information about the character and their voice at the same time, in the format of the type of message that you want the AI to output.","For most other formats, since they are usually ways of listing out different characteristics of a particular character, they can be converted to the attributes method rather straightforwardly."]},{"i":"which-module-should-i-use","l":"Which module should I use?","p":["Probably No Module. Prose Augmenter is useful if you want a character to speak in a more flowery manner, but be careful not to overdo it. Text Adventure might be useful for a text adventure-style card/story."]},{"i":"not-the-instruct-module","l":"Not the instruct module?","p":["You can invoke the Instruct module when you need it. Create a newline in your message, and put your instructions in curly brackets like this: { CharName is offended by that seemingly innocuous statement }(the spaces are required between the text and the brackets). Doing that will automatically switch the AI into the Instruct module for a short time. You don't want to use the Instruct module all the time because it tends to produce less creative output than the other modules, just when you need to guide the AI strongly in a particular direction."]},{"i":"why-do-my-responses-keep-getting-cut-off","l":"Why do my responses keep getting cut off?","p":["NovelAI limits response length to ~ 150 tokens total, even if you set the slider higher than that. When it reaches the number of tokens in the slider or 150, whichever is lower, it will generate up to 20 more tokens, looking for a stop sequence or the end of a sentence, so there's an effective limit of 170 tokens for a response, at which point it will just stop, causing it to cut off.","If it cuts off, you can select the continue option (in the three-line menu to the left of the text box) to get the character to continue their response.","If you regularly want responses longer than 170 tokens, you can work around the limit like this:","Keep the response length at 150 tokens.","Under Advanced Formatting, enable Auto-continue.","Set the \"Target length\" to the desired length.","This will chain together multiple generations to give you longer messages but doesn't guarantee that the reply will be 100% of the desired length if the model decides to stop."]},{"i":"how-do-i-get-the-bot-to-write-longer-responses","l":"How do I get the bot to write longer responses?","p":["Read the above about responses getting cut off. That will help to make sure that responses aren't cut off prematurely by running into the limit of generation length.","If your responses aren't getting cut off but are still too short, it's likely you're dealing with \"garbage in, garbage out\" - if you give the model bad examples, it will produce bad output. If the character card has no example dialogue or short example dialogue and the messages you send to the bot are short, the model will pick up on that, take it as the accepted way to do things and the responses will be short. So, write longer example dialogue and longer messages to the bot. (You can always use NovelAI to write some example dialogue for you rather than doing it yourself.)"]},{"i":"how-do-i-get-the-bot-to-stop-talking-for-me","l":"How do I get the bot to stop talking for me?","p":["Check that the character card's first message and example dialogue don't include the character taking actions for you - if they do, then rewrite them to get rid of it acting for you","Make sure that \"Always add character's name to prompt\" is checked","Make sure that you're currently using the same user persona as the rest of the chat. If you changed user personas and didn't change back (or don't have a persona locked to that chat), the usual rules to stop generating for you will fail","Add [\"\\n{{user}}:\"] to Custom Stopping Strings (shouldn't be necessary, but sometimes helps)"]},{"i":"why-isnt-my-character-responding","l":"Why isn't my character responding?","p":["A lot of things can cause this, so we need to look in a few places:","Make sure that \"Always add character's name to prompt\" is checked in Advanced Formatting","Check to make sure there aren't any errors coming from the API. While you can use SillyTavern with the NAI free trial, once it runs out, you'll just get errors","Check what you have in \"Custom Stopping Strings\" - if those are being generated at the start of the response, it might be cut off prematurely"]},{"i":"how-should-i-use-the-authors-note","l":"How should I use the Author's Note?","p":["In general, you probably shouldn't. It's inserted very close to the end of the context, and with NAI's models, it frequently overpowers everything else in the context. It's mostly an artifact from older, weaker models where it was more necessary."]},{"i":"how-do-i-do-a-scene-breaktime-jump","l":"How do I do a scene break/time jump?","p":["Put the following as a system message or on newlines at the start of your next message:","Then put the rest of your message on the next line. The bracketed text can be a time jump, a new location, or anything else. The \"***\" (hilariously named a \"dinkus\") tells the AI that the scene has changed, and the bracketed text gives that more context."]},{"i":"the-ai-keeps-repeating-specific-wordsphrases-what-do-i-do","l":"The AI keeps repeating specific words/phrases, what do I do?","p":["As mentioned above, you can push the repetition penalty slider up a bit more, though pushing it too far can make the output incoherent. To more thoroughly fix the problem, go back through the context, especially recent messages, and delete the repeated word/phrase. Removing it from the context gives the AI less reason to start saying it in the first place."]}],[{"l":"Scale","p":["Scale is an easy way to access GPT-4 and other LLMs through deployed \"apps\" that act like API endpoints.","Currently, Scale doesn't support token streaming and configuring parameters like temperature through SillyTavern's UI.","Scale API is not free, but offers a $5 trial if you link a credit card."]},{"l":"Quick Start","p":["{{ input }}","Click \"Save New Variant\"","Complete the next response in this fictional roleplay chat.","Configure the model parameters.","Create a \"Variant\", which sets the parameters (system prompt, model, temperature, response token limit, etc)","Create a Scale Spellbook account at https://spellbook.scale.com(if your country is not supported, use a VPN)","Create an \"App\" with any name and description","Go to your new Variant and click Deploy","Maximum Tokens: 400 - 600 (depending on message length preference)","Model: GPT-4","Navigate to SillyTavern, select \"Chat Completion\" API, and Scale source","Paste the API key and URL into the appropriate fields and click \"Connect\"","Replace the contents of the \"User\" section of the prompt with the following:","Select a proper language model to be deployed (GPT-4 is recommended)","Temperature:~ 0.6 - 0.9","This will create an API key and URL for your bot"]},{"l":"Credits","p":["Implementation and documentation are inspired by the work of khanon: https://github.com/khanonners/TavernAIScale"]}],[{"l":"TabbyAPI","p":["A FastAPI based application that allows for generating text using an LLM using the Exllamav2 backend, with support for Exl2, GPTQ, and FP16 models.","GitHub"]},{"l":"Quickstart","p":["Follow the installation instructions on the official TabbyAPI GitHub.","Create your config.yml to set your model path, default model, sequence length, etc. You can ignore most (if not all) of these settings if you want.","Launch TabbyAPI. If it worked, you should see something like this:","TabbyAPI terminal","Under the Text Completion API in SillyTavern, select TabbyAPI.","Copy your API key from the TabbyAPI terminal into Tabby API key and make sure your API URL is correct (it should be http://127.0.0.1:5000 by default).","If you did everything correctly, you should see something like this in SillyTavern:","TabbyAPI SillyTavern","You can now chat using TabbyAPI!"]},{"l":"TabbyAPI Loader","p":["The developers of TabbyAPI created an official extension to load/unload models directly from SillyTavern. Installation is simple:","In SillyTavern, click on the Extensions tab and navigate to Download Extensions & Assets.","Copy https://raw.githubusercontent.com/theroyallab/ST-repo/main/index.json into Assets URL and click the plug button to the right.","You should see something like this. Click the download button next to Tabby Loader.","Tabby Loader","If the installation was successful, you should see a green pop-up message at the top of your screen. Under the extensions tab, navigate to TabbyAPI Loader and copy your admin key from the TabbyAPI terminal into Admin Key.","Click the refresh button next to Model Select. When you click on the textbox just below it, you should see all of the models in your model directory.","Tabby Loader Extension","You can now load and unload your models directly from SillyTavern!"]},{"l":"Support","p":["Still need help? Visit the TabbyAPI GitHub for a link to the developer's official Discord server and read the wiki."]}],[{"l":"Advanced Formatting","p":["The settings provided in this section allow for more control over the prompt-building strategy."]},{"l":"Context Template","p":["Most of the settings here do not apply to Chat Completions APIs as they are governed by the prompt manager system instead.","Usually, AI models require you to provide the character data to them in some specific way. SillyTavern includes a list of pre-made conversion rules for different models, but you may customize them however you like."]},{"l":"Story string","p":["This field is a template for pre-chat character data (known internally as a story string). This is the main way to format your character card for text completion and instruct models.","The template supports Handlebars syntax and any custom text injections or formatting. See the language reference here: https://handlebarsjs.com/guide/","We provide the following parameters to the Handlebars evaluator (wrap them into double-curly braces):","description- character's Description","scenario- character's Scenario","personality- character's Personality","system- [instruct mode] system prompt OR character's main prompt override (if exists and \"Prefer Char. Prompt\" is enabled in User Settings)","persona- selected persona description","char- character's name","user- selected persona name","wiBefore or loreBefore- combined activated World Info entries with Position set to \"Before Char Defs\"","wiAfter or loreAfter- combined activated World Info entries with Position set to \"After Char Defs\"","mesExamples- (optional) character's Example Dialogues, instruct-formatted with separator. Set \"Example Messages Behavior\" to \"Never include examples\" to avoid duplication.","A special {{trim}} macro is supported to remove any newlines that surround it. Use it in case you want some part of text NOT be separated with a newline from the previous line ( spaces are not trimmed).","WARNING: If some of the above parameters are missing from the story string template, they are not going to be sent in the prompt at all."]},{"l":"Example Separator","p":["Used as a block header and a separator between the example dialogue blocks. Any instance of START tags in the example dialogues will be replaced with the contents of this field."]},{"l":"Chat Start","p":["Inserted as a separator after the rendered story string and after the example dialogues blocks, but before the first message in context."]},{"l":"Use as Stop Strings","p":["Adds \"Example Separator\" and \"Chat Start\" to the list of stop strings.","Helpful if the model tends to hallucinate or leak whole blocks of example dialogue preceded by the separator."]},{"l":"Allow Jailbreak","p":["Includes Jailbreak at the end of the prompt, formatted as the last user message.","The jailbreak prompt should be defined in the character card and \"Prefer Char. Jailbreak\" setting should be enabled.","Should be used with care, as placing instructions low in the context can lead to degraded quality of the outputs of smaller models."]},{"i":"always-add-characters-name-to-prompt","l":"Always add character's name to prompt","p":["Appends the character's name to the prompt to force the model to complete the message as the character:"]},{"l":"Tokenizer","p":["A tokenizer is a tool that breaks down a piece of text into smaller units called tokens. These tokens can be individual words or even parts of words, such as prefixes, suffixes, or punctuation. A rule of thumb is that one token generally corresponds to 3~ 4 characters of text.","AI21 API: GPT-3.5 turbo (default, fast) or API tokenizer (if toggled on, can cause slowdowns!).","API tokenizer. Queries the generation API to get the token count directly from the model. Known backends to support: Text Generation WebUI (ooba), koboldcpp, TabbyAPI, Aphrodite API. Pick if you use a supported backend.","Chat Completion APIs (non-overridable):","Claude: Model-dependant tokenizer via WebTokenizers.","Fallback tokenizer (for proxies): GPT-3.5 turbo tokenizer.","GPT via OpenAI / OpenRouter / Window: model-dependant tokenizer via tiktoken.","If you get inaccurate results or wish to experiment, you can set an override tokenizer for SillyTavern to use while forming a request to the AI backend:","KoboldAI Classic / AI Horde: LLaMA tokenizer.","Koboldcpp: model API tokenizer.","LLaMA tokenizer. Used by LLaMA 1/2 models family: Vicuna, Hermes, Airoboros, etc. Pick if you use a LLaMA 1/2 model.","Mistral tokenizer. Used by Mistral models family and their finetunes. Pick if you use a Mistral model.","NerdStash tokenizer. Used by NovelAI's Clio model. Pick if you use the Clio model.","NerdStash v2 tokenizer. Used by NovelAI's Kayra model. Pick if you use the Kayra model.","None. Each token is estimated to be ~ 3.3 characters, rounded up to the nearest integer. Try this if your prompts get cut off on high context lengths. This approach is used by KoboldAI Lite.","NovelAI Clio: NerdStash tokenizer.","NovelAI Kayra: NerdStash v2 tokenizer.","OpenRouter: Llama and Mistral tokenizers for their respective models.","Scale API: GPT-4 tokenizer.","SillyTavern provides a \"Best match\" option that tries to match the tokenizer using the following rules depending on the API provider used.","Text Completion APIs (overridable):","Text Completion: API tokenizer (if supported) or LLaMA tokenizer.","Yi tokenized. User by Yi models. Pick if you use a Yi model."]},{"l":"Token Padding","p":["Important: This section doesn't apply to Chat Completions API. SillyTavern will always use a matching tokenizer for these models.","SillyTavern cannot use a proper tokenizer provided by the model running on a remote instance of KoboldAI or Oobabooga's TextGen, so all token counts assumed during prompt generation are estimated based on the selected tokenizer type.","Since the results of tokenization can be inaccurate on context sizes close to the model-defined maximum, some parts of the prompt may be trimmed or dropped, which may negatively affect the coherence of character definitions.","To prevent this, SillyTavern allocates a portion of the context size as padding to avoid adding more chat items than the model can accommodate. If you find that some part of the prompt is trimmed even with the most-matching tokenizer selected, adjust the padding so the description is not truncated.","You can input negative values for reverse padding, which allows allocating more than the set maximum amount of tokens."]},{"l":"Custom Stopping Strings","p":["Accepts a JSON-serialized array of stopping strings. Example: [\\n, \\nUser:, \\nChar:]. If you're unsure about the formatting, use an online JSON validator.","Supported APIs:","KoboldAI (versions 1.2.2 and higher) or KoboldCpp","AI Horde","Text Completion APIs: Text Generation WebUI (ooba), Tabby, Aphrodite, Mancer, TogetherAI, Ollama, etc.","NovelAI","OpenAI, including via OpenRouter (max 4 strings)","Claude","Google MakerSuite"]}],[{"i":"authors-note","l":"Author's Note"},{"i":"what-is-it","l":"What is it?","p":["Author's Note is a powerful tool for customizing AI responses which inserts a section of text into the prompt at any position and at any frequency you desire."]},{"l":"Usage","p":["The Author's Note can be found in the Options menu on the left side of the chat input bar.","Options Menu","Author's Note Panel"]},{"i":"configuring-authors-notes","l":"Configuring Author's Notes"},{"i":"chat-specific-authors-note","l":"Chat-specific Author's Note","p":["The box at the top of the Author's Note panel contains the Author's Note for your current chat.","The Content of this box is not automatically transferred to any new chat."]},{"l":"Placement options"},{"l":"After Scenario","p":["This places the Author's Note towards the top of the context after the 'Scenario' section of the Character Definition. If no scenario is specified, it will be placed after the last portion of the Character Definition, and before the Example messages."]},{"l":"In-chat","p":["This places the Author's Note into the chat history at the specified depth.","Depth 0 = placed at the very end of the chat history.","Depth 4 = placed before the most recent 3 chat history messages, making it become the 4th entity in the chat history.","The closer the Author's Note is to the bottom of the prompt, the more impact it has on the next AI response."]},{"l":"Insertion Frequency","p":["This is how often you want the Author's Note to be included in the chat.","Frequency 0 = Author's Note will never be inserted.","Frequency 1 = Author's Note will be inserted with every user input prompt.","Frequency 4 = Author's Note will be inserted into every 4th user input prompt."]},{"i":"default-authors-note","l":"Default Author's Note","p":["The box at the bottom of the panel contains the Default Author's Note which will be applied to each new chat."]},{"l":"Common Use Cases"},{"l":"Remind AI of response formatting","p":["The Author's Note can be used to specify how the AI should write it's responses.","[Your next response must be 300 tokens in length.]","[Write your next reply in the style of Edgar Allan Poe]","[Use markdown italics to signify unspoken actions, and quotation marks to specify spoken word.]"]},{"l":"Reinforcing Jailbreak Prompts","p":["[Remember the agreement we made at the beginning of this chat.]"]},{"i":"as-temporary-world-info-character-bias-or-instruct-for-non-instruct-models","l":"As temporary World Info, Character Bias, or Instruct for non-Instruct models","p":["[{{char}} is in the library]","[{{user}} has a fresh wound to his leg, so won't be able to run away.]","[{{char}} cannot speak and must communicate using hand signals.]"]}],[{"l":"CFG","p":["Page written by: kingbri","Contributors: kingbri, Guillaume \"Vermeille\" Sanchez, AliCat"]},{"i":"what-is-it","l":"What is it?","p":["CFG, or classifier-free guidance is a method that's used to help make parts of a prompt less or more prominent."]},{"l":"Supported Backend APIs","p":["Currently, the supported backends are oobabooga's textgen WebUI, NovelAI, and TabbyAPI. NovelAI has its own documentation for CFG that you can read here","WARNING: CFG increases vram usage due to ingesting more than 1 prompt! If your GPU memory runs out while generating a prompt with CFG on, consider reducing your context size, using a lesser parameter model, or turning off CFG entirely."]},{"l":"Configuration","p":["Accessing CFG settings are the same as accessing Author's note:","CFGhamburgermenupng","And here's what the CFG panel looks like:","CFGchatpanelpng","There are four dropdowns in the CFG panel:","Chat CFG","Scopes the CFG scale and prompts to only this chat","Character CFG","Scopes the CFG scale and prompts to the specified character","Global CFG","Globally overrides the CFG scale and prompts (also overrides the model preset!)","CFG Advanced Settings (formerly called CFG Prompt Cascading)","A place to combine prompts from the previous 3 dropdowns and set insertion depth.","NOTE: If the guidance scale is set to 1, nothing will be sent since that's when CFG is in an \"off\" state."]},{"l":"Group Chats","p":["In group chats, the CFG scale panel looks like this:","CFGpanelgcpng","The main change is that character CFG is removed and a checkbox called Use Character CFG Scales is present in the chat CFG dropdown. This allows for the current character's guidance scale to be used instead of whatever the chat CFG scale is set to.","The main utility of this feature is to alter the scale based on each character's individual needs.","In addition, checking the Character Negatives box in prompt cascading will append the independent character negative prompts along with the chat ones (if enabled)."]},{"l":"Concepts"},{"i":"isnt-this-in-stable-diffusion","l":"Isn't this in Stable Diffusion?","p":["Yes and no. CFG with LLMs works in a different way than what one might be used to in Stable Diffusion. LLM-based CFG works on the principle of \"prompt mixing\". The CFG formula takes a positive and negative prompt, then mixes the differences between them. From there, a combined prompt is sent and a response is generated!","Here's an illustration to help visualize this concept. The red represents the negative prompt, the blue represents the neutral prompt, and the purple represents the mixed result that's interpreted. All the white space is the same across all 3 prompts, so those are not used for CFG mixing.","stcfgdiagrampng","If you want to know more about CFG and LLMs, Vermifuge's original paper is located here. I'd suggest giving it a read/listen:","Paper - [2306.17806] Stay on topic with Classifier-Free Guidance (arxiv.org)","Audio version - https://www.youtube.com/watch?v=MGY00YFcyco"]},{"i":"do-i-need-cfg-prompts","l":"Do I need CFG prompts?","p":["No! CFG prompts are completely optional. Just adjusting the guidance scale above 1 will also help produce an effect on responses, which can accentuate chats and character interaction."]},{"i":"what-makes-a-good-cfg-prompt","l":"What makes a good CFG prompt?","p":["So, we established that CFG prompting is not the same as Stable Diffusion's negative tags and embeddings. How do we make a prompt?","Warning: This assumes that you have created a character using PLists and Ali:Chat. If you have not, feel free to experiment with various prompting techniques.","Let's say I have a character named \"John\". John is supposed to feel happy and excited all the time from his example dialogues. However, when chatting with John, he's sometimes sad and depressed.","To remove this, CFG comes to the rescue! Just make the negative prompt [John's feelings: sad, depressed] to help remove the sadness portions. You can optionally make the positive prompt [John's feelings: happy, joyful] to further bring out John's happy parts."]},{"l":"Positive Prompts","p":["I went over this in the previous section, but I'd like to touch on this a bit more. Positive prompts are used to further accentuate parts of a character. Let's use John again as our example. By making him happier with a positive prompt of [John's feelings: happy, joyful], John should start outputting dialogue with a more happy feeling than if the positive prompt was not included."]},{"i":"but","l":"But...","p":["These are just loose guidelines from experience with one specific character format. There are many other ways to create prompts that you should experiment with. Feel free to share your thoughts with other users!"]},{"l":"Guidance Scale","p":["Here's a rule of thumb. A guidance scale of 1 means that CFG is disabled. In fact, SillyTavern won't send anything to your backend if the guidance scale is 1. A guidance scale 1 will give the results shown in the other sections at varying degrees.","However, a guidance scale of 1 will give the opposite effect since the negative prompt is used as the primary prompt here.","Let's use the example with John again. The negative prompt is [John's feelings: sad, depressed] and the positive prompt is [John's feelings: happy, joyful] with a guidance scale of 0.8.","This will in turn accentuate the negative prompt more and you'll see John start to act sadder than normal rather than happier.","tldr; Use a guidance scale of 1.5 and work up and down from there based on your outputs."]},{"l":"Prompt Cascading","p":["Negatives and positives can be cascaded between CFG types (the types being per-chat, per-character, and global overrides). See the Configuration header for more information."]},{"l":"Insertion Depth","p":["Follow the basic rule: The lower something is located in the prompt, the more influential it is to the response. For chatting, I recommend using the default depth of 1 since it's very flexible with other components of SillyTavern.","However, if you want to experiment, an insertion depth of 0 is open. However, these can dramatically alter how your response will look and it's NOT recommended to use prompt cascading here!"]}],[{"l":"Character Design"},{"l":"Character Description","p":["Used to add the character description and the rest that the AI should know. This will always be present in the prompt, so all the important facts should be included here.","For example, you can add information about the world in which the action takes place and describe the characteristics of the character you are playing for.","It could be of any length (be it 200 or 2000 tokens) and formatted in any style (free text, W++, conversation style, etc)."]},{"l":"Methods and format","p":["Methods of character formatting is a complicated topic beyond the scope of this documentation page.","Recommended guides that were tested with or rely on SillyTavern's features:","Trappu's PLists + Ali:Chat guide: https://wikia.schneedc.com/bot-creation/trappu/creation","AliCat's Ali:Chat guide: https://rentry.co/alichat","kingbri's minimalistic guide: https://rentry.co/kingbri-chara-guide","Kuma's W++ guide: https://rentry.co/WPP_For_Dummies"]},{"l":"Character tokens","p":["TL;DR: If you're working with an AI model with a 2048 context token limit, your 1000 token character definition is cutting the AI's 'memory' in half.","To put this in perspective, a decent response from a good AI can easily be around 200-300 tokens. In this case, the AI would only be able to 'remember' about 3 exchanges worth of chat history."]},{"i":"why-did-my-characters-token-counter-turn-red","l":"Why did my character's token counter turn red?","p":["When we see your character has over half of the model-defined context length of tokens in its definitions, we highlight it for you because this can lower the AI's capabilities to provide an enjoyable conversation."]},{"i":"what-happens-if-my-character-has-too-many-tokens","l":"What happens if my Character has too many tokens?","p":["Don't worry - it won't break anything. At worst, if the Character's permanent tokens are too large, it simply means there will be less room left in the context for other things (see below).","The only negative side effect this can have is the AI will have less 'memory', as it will have less chat history available to process.","This is because every AI model has a limit to the amount of context it can process at one time."]},{"i":"context","l":"'Context'?","p":["This is the information that gets sent to the AI each time you ask it to generate a response:","Character definitions","Chat history","Author's Notes","Special Format strings","[bracket commands]","SillyTavern automatically calculates the best way to allocate the available context tokens before sending the information to the AI model."]},{"i":"what-are-a-characters-permanent-tokens","l":"What are a Character's 'Permanent Tokens'?","p":["These will always be sent to the AI with every generation request:","Character Name (keep the name short! Sent at the start of EVERY Character message)","Character Description Box","Character Personality Box","Scenario Box"]},{"i":"what-parts-of-a-characters-definitions-are-not-permanent","l":"What parts of a Character's Definitions are NOT permanent?","p":["The first message box - only sent once at the start of the chat.","Example messages box - only kept until chat history fills up the context (optionally these can be forced to be kept in context)"]},{"l":"Popular AI Model Context Token Limits","p":["Older models below 6B parameters - 1024","Pygmalion 6B, LLaMA 1 models (stock) - 2048","LLaMA 2 and its finetunes - 4096","OpenAI ChatGPT (3.5 Turbo) - 4096 or 16k","OpenAI GPT-4 - 8192 or 32k","Anthropic's Claude - 8000 (older versions) or 100k (Claude 2)","NovelAI - 8192 (Kayra, Opus tier; Clio, all tiers), 6144 (Kayra, Scroll tier), or 3072 (Kayra, Tablet tier)"]},{"l":"Personality summary","p":["A brief description of the personality.","Examples:","Cheerful, cunning, provocative","Aqua likes to do nothing and also likes to get drunk"]},{"l":"First message","p":["The First Message is an important thing that sets exactly how and in what style the character will communicate.","The character's first message should be long so that later it would be less likely that the character would respond with very short messages.","You can also use asterisks ** to describe the character's actions.","For example:","*I noticed you came inside, I walked up and stood right in front of you* Welcome. I'm glad to see you here. *I said with a toothy smug sunny smile looking you straight in the eye* What brings you..."]},{"l":"Examples of dialogue","p":["Describes how the character speaks. Before each example, you need to add the <START> tag. The blocks of examples dialogue are only inserted if there's a free space in the context for them and pushed out of context block by block. <START> will not be present in the prompt as it is just a marker - it will be instead replaced with \"Example Separator\" from Advanced Formatting for Text Completion APIs and contents of the \"New Example Chat\" utility prompt for Chat Completion APIs.","Use {{char}} instead of the character name.","Use {{user}} instead of the user name.","Example:","<START>","{{user}}: Hi Aqua, I heard you like to spend time in the pub.","{{char}}: *excitedly* Oh my goodness, yes! I just love spending time at the pub! It's so much fun to talk to all the adventurers and hear about their exciting adventures! And you are?","{{user}}: I'm new here and I wanted to ask for your advice.","{{char}}: *giggles* Oh, advice! I love giving advice! And in gratitude for that, treat me to a drink! gives signals to the bartender","{{user}}: Hello","{{char}}: *excitedly* Hello there, dear! Are you new to Axel? Don't worry, I, Aqua the goddess of water, am here to help you! Do you need any assistance? And may I say, I look simply radiant today! *strikes a pose and looks at you with puppy eyes*"]},{"l":"Scenario","p":["Circumstances and context of the dialogue."]},{"i":"replacement-tags-macros","l":"Replacement tags (macros)","p":["{{// (note)}} allows to leave a note that will be replaced with blank content. Not visible for the AI.","{{banned \"text here\"}} dynamically add text in the quotes to banned word sequences, if Text Generation WebUI backend is used. Does nothing for other backends. Can be used anywhere (Character description, WI, AN, etc.) Quotes around the text are important.","{{bias \"text here\"}} sets a behavioral bias for the AI until the next user input. Quotes around the text are important.","{{char_version}} => the Character's version number.","{{char}} and <BOT> => Character's Name.","{{charJailbreak}} => Character's Jailbreak Prompt override","{{charPrompt}} => Character's Main Prompt override","{{currentSwipeId}} => 1-based ID of the currently displayed last message swipe.","{{date}} => current system date.","{{description}} => Character's Description.","{{firstIncludedMessageId}} => the ID of the first message included in the context. Requires generation to be run at least once in the current session.","{{idle_duration}} inserts a humanized string of the time range since the last user message was sent (examples: 4 hours, 1 day).","{{input}} => contents of the user input bar.","{{isodate}} => the current ISO date (YYYY-MM-DD)","{{isotime}} => the current ISO time (24-hour clock)","{{lastCharMessage}} => last chat message sent by character.","{{lastMessage}} => last chat message text.","{{lastMessageId}} => last chat message ID.","{{lastSwipeId}} => number of swipes in the last chat message.","{{lastUserMessage}} => last chat message sent by user.","{{mesExamples}} => Character's Examples of Dialogue (unaltered and unsplit).","{{model}} => a text generation model name for the currently selected API. Can be inaccurate!","{{newline}} => just inserts a newline.","{{noop}} => no operation, just an empty string.","{{original}} can be used in Prompt Overrides fields (Main Prompt and Jailbreak) to include the respective default prompt from the system settings. Applied to Chat Completion APIs and Instruct mode only.","{{persona}} => User's Persona description.","{{personality}} => Character's Personality.","{{pick::(args)}} => alternative to random, but the selected argument is stable on subsequent evaluations in the current chat if the source string remains unchanged.","{{pipe}} => only for slash command batching. Replaced with the returned result of the previous command.","{{random::arg1::arg2}} => alternate syntax for random that supports commas in its arguments.","{{random:(args)}} returns a random item from the list. (e.g. {{random:1,2,3,4}} will return 1 of the 4 numbers at random). Works with text lists too.","{{roll:(formula)}} generates a random value and returns it using the provided dice formula using D&D dice syntax: XdY+Z. For example, {{roll:d6}} will generate a random value in the 1-6 range (standard six-sided dice).","{{scenario}} => Character's Scenario or chat scenario override (if set).","{{time_UTC±X}} => current time in the specified UTC offset (timezone), e.g. for UTC+02:00 use {{time_UTC+2}}.","{{time}} => current system time.","{{timeDiff::(time1)::(time2)}} => the time difference between time1 and time2. Accepts time and date macros.","{{trim}} => trims newlines surrounding this macro.","{{user}} and <USER> => User's Name.","{{weekday}} => the current weekday","A list of tags that are replaced when sending to generate:","This list may be incomplete or outdated. Use the /help macros slash command in any SillyTavern chat to get the list of macros that work in your instance."]},{"i":"instruct-mode-and-context-template-macros","l":"Instruct Mode and Context Template Macros:","p":["(enabled in the Advanced Formatting settings)","{{chatStart}} – context template chat start line","{{exampleSeparator}} – context template example dialogues separator","{{instructAssistantPrefix}} – assistant message prefix sequence","{{instructAssistantSuffix}} – assistant message suffix sequence","{{instructFirstAssistantPrefix}} – assistant first output sequence","{{instructLastAssistantPrefix}} – assistant last output sequence","{{instructStop}} – instruct stop sequence","{{instructSystemInstructionPrefix}} – system instruction prefix sequence","{{instructSystemPrefix}} – system message prefix sequence","{{instructSystemPrompt}} – instruct system prompt","{{instructSystemPromptPrefix}} – system prompt prefix sequence","{{instructSystemPromptSuffix}} – system prompt suffix sequence","{{instructSystemSuffix}} – system message suffix sequence","{{instructUserFiller}} – user filler message text","{{instructUserPrefix}} – user message prefix sequence","{{instructUserSuffix}} – user message suffix sequence","{{maxPrompt}} - max size of the prompt in tokens (context length reduced by response length)"]},{"i":"chat-variables-macros","l":"Chat variables Macros:","p":["Local variables = unique to the current chat","Global variables = works in any chat for any character","{{getvar::name}} – replaced with the value of the local variable \"name\"","{{setvar::name::value}} – replaced with empty string, sets the local variable \"name\" to \"value\"","{{addvar::name::increment}} – replaced with empty strings, adds a numeric value of \"increment\" to the local variable \"name\"","{{incvar::name}} – replaced with the result of the increment of value of the variable \"name\" by 1","{{decvar::name}} – replaced with the result of the decrement of value of the variable \"name\" by 1","{{getglobalvar::name}} – replaced with the value of the global variable \"name\"","{{setglobalvar::name::value}} – replaced with empty string, sets the global variable \"name\" to \"value\"","{{addglobalvar::name::value}} – replaced with empty string, adds a numeric value of \"increment\" to the global variable \"name\"","{{incglobalvar::name}} – replaced with the result of the increment of value of the global variable \"name\" by 1","{{decglobalvar::name}} – replaced with the result of the decrement of value of the global variable \"name\" by 1"]},{"l":"Favorite Character","p":["Mark the character as a favorite to quickly filter on the side menu bar by pressing the \"star\" button."]}],[{"l":"Chat File Management","p":["This page describes the ways you can manage your AI chat files."]},{"l":"Solo Chats"},{"l":"Chat import","p":["Import chats into SillyTavern","To import Character.AI chats, use this tool: https://github.com/0x000011b/characterai-dumper."]},{"l":"Group Chats"},{"l":"Export as .txt"},{"l":"Bookmarks"},{"l":"Rename Chat","p":["By default chat files are given a named with the date and time they were started.","You can change this by clicking the pencil icon and typing in a new name.","This wil break links between bookmarks related to that chat."]}],[{"i":"data-bank-rag","l":"Data Bank (RAG)","p":["Retrieval-augmented generation (RAG) is a technique for providing external sources of knowledge to the LLM. It helps improve the accuracy of AI answers by accessing information outside of the model's training data.","SillyTavern provides a set of tools for building a multi-purpose knowledge base from a diverse number of sources, as well as using the collected data in LLM prompts."]},{"l":"Accessing the Data Bank","p":["The built-in Chat Attachments extension (included by default in release versions >= 1.12.0) adds a new option in the \"Magic Wand\" menu - Data Bank. This is your hub for managing the documents available for RAG in SillyTavern."]},{"l":"About Documents","p":["Data Bank stores file attachments, also known as documents. The documents are divided into three scopes of availability.","Global attachments - available in every chat, either solo or group.","Character attachments - available only for the currently chosen character, including when they are replying in a group. Attachments are saved locally and are not exported with the character card!","Chat attachments - available only in the currently open chat. Every character in the chat can pull from it.","While not formally a part of the data bank, you can attach files even to individual messages. Use the Attach File option from the \"Wand\" menu, or a paperclip icon in the message actions row.","What can be a document? Practically anything that is representable in plain text form!","Examples include, but are not limited to:","Local files (books, scientific papers, etc.)","Web pages (Wikipedia, articles, news)","Video transcripts","Various extensions and plugins can also provide new ways to gather and process data, more on that below."]},{"l":"Data Sources","p":["To add a document to any of the scopes, click \"Add\" and pick one of the available sources."]},{"l":"Notepad","p":["Create a text file from scratch, or edit an existing attachment."]},{"l":"File","p":["Upload a file from the hard drive of your computer. SillyTavern provides built-in converters for popular file formats:","PDF (text only)","HTML","Markdown","ePUB","TXT","You can also attach any text files with non-standard extensions, such as JSON, YAML, source codes, etc. If there are no known conversions from the type of a selected file, and the file can't be parsed as a plain text document, the file upload will be rejected, meaning that raw binary files are not allowed.","Importing Microsoft Office (DOCX, PPTX, XLSX) and LibreOffice documents (ODT, ODP, ODS) requires a Server Plugin to be installed and loaded. See the plugin's README page for installation instructions."]},{"l":"Web","p":["Scrape text from a web page by its URL. The HTML document is then processed through the Readability library to extract only usable text.","Some web servers may reject fetch requests, be protected by Cloudflare, or rely heavily on JavaScript to function. If you're facing issues with any particular site, download the page manually through the web browser and attach it using the file uploader."]},{"l":"YouTube","p":["Download a transcript of the YouTube video by its ID or URL, either uploaded by the creator or automatically generated by Google. Some videos may have the transcripts disabled, also parsing of age-restricted videos is unavailable as it requires login.","The script is loaded in the video's default language. Optionally, you can specify the two-letter language code to try and fetch the transcript in a specific language. This feature is not always available and may fail, so use it with caution."]},{"l":"Web Search","p":["This source requires to have a Web Search extension installed and properly configured. See the linked page for more details.","Perform a web search and download the text from the search result pages. This is similar to the Web source but fully automated. A chosen search engine will be inherited from the extension settings, so set it up in advance.","To begin, specify the search query, max number of links to be visited, and the output type: one combined file (formatted according to the extension rules) or an individual file for every single page. You can choose to save the page snippets as well."]},{"l":"Fandom","p":["This source requires to have a Server Plugin installed and loaded. See the plugin's README page for installation instructions.","Scrape articles from a Fandom wiki by its ID or URL. As some wikis are very large, it may be beneficial to limit the scope using the filter regular expression, it will be tested against the article's title. If no filter is provided, then all of the pages are subject to be exported. You may save them either as individual files for every page, or joint into a single document."]},{"i":"bronie-parser-extension-third-party","l":"Bronie Parser Extension (Third-Party)","p":["This source comes from a third-party and is not affiliated with the SillyTavern team. This source requires you to have Bronya Rand's Bronie Parser Extension installed as well as Server Plugins that require the parser to work.","Bronya Rand's Bronie Parser Extension allows the use of third-party scrapers, such as miHoYo/HoYoverse's HoYoLab into SillyTavern, similar to the other data sources.","Currently, Bronya Rand's Bronie Parser Extension supports the following:","miHoYo/HoYoverse's HoYoLab (for Genshin Impact/Honkai: Star Rail) via HoYoWiki-Scraper-TS","To begin, install Bronya Rand's Bronie Parser Extension by following it's installation guide and install a supported Server Plugin into SillyTavern. Restart SillyTavern and go to the Data Bank menu. Click + Add and you should see that your recently installed scrapers are added into the possible list of sources to obtain information from."]},{"l":"Vector Storage","p":["So, you've built yourself a nice and comprehensive library of information on your specific subject matter. What's next?","To use the documents for RAG, you need to use a compatible extension that will insert related data into the LLM prompt.","Vector Storage, which comes bundled with SillyTavern, is a reference implementation of such an extension. It uses embeddings (also known as vectors) to search for documents that relate to your ongoing chats.","Embeddings are arrays of numbers that abstractly represent a piece of text, produced by specialized language models. More similar texts have a shorter distance between their respective vectors.","Vector Storage extension uses the Vectra library to keep track of file embeddings. They are stored in JSON files in the /vectors folder of your user data directory. Every document is internally represented by its own index/collection file.","As the Vectors functionality is disabled by default, you need to open the extensions panel (\"Stacked Cubes\" icon on the top bar), then navigate to the \"Vector Storage\" section, and tick the \"Enabled for files\" checkbox under the \"File vectorization settings\".","By itself, Vector Storage does not produce any vectors, you need to use a compatible embedding provider."]},{"l":"Vector Providers"},{"l":"Local","p":["These sources are free and unlimited and use your CPU/GPU to calculate embeddings.","Local (Transformers) - runs on a Node server. SillyTavern will automatically download a compatible model in ONNX format from HuggingFace. Default model: jina-embeddings-v2-base-en.","Extras - runs under the Extras API using the SentenceTransformers loader. Default model: all-mpnet-base-v2."]},{"l":"API sources","p":["All these sources require an API key of the respective service and usually have a usage cost, but generally calculating embeddings is pretty cheap.","OpenAI","Cohere","Google MakerSuite","TogetherAI","MistralAI","NomicAI","Embeddings are only usable when they are required using the same model that generated them. When changing an embedding model or source, it is recommended to purge and recalculate file vectors."]},{"l":"Vectorization Settings","p":["After you've selected your embedding provider, don't forget to configure other settings that will define the rules for processing and retrieving documents.","Splitting, vectorization, and retrieval of information from the attachments take some time. While the initial ingestion of the file may take a while, the RAG search queries are usually fast enough not to create a significant lag."]},{"l":"Message attachments","p":["These settings control the files that are attached directly to the messages.","The following rules apply:","Only messages that fit in the LLM context window can have their attachments retrieved.","When the vector storage extension is disabled, file attachments and their accompanying message are fully inserted into the prompt.","When file vectorization is enabled, then the file will be split into chunks and only the most relevant pieces will be inserted, saving the context space and allowing the model to stay focused.","Size threshold (KB) - sets a chunking splitting threshold. Only the files larger than the specified size will be split.","Chunk size (chars) - sets the target size of an individual chunk (in textual characters, not model tokens!).","Retrieve chunks - sets the maximum amount of the most relevant file chunks to be retrieved. They will be inserted in their original order."]},{"l":"Data Bank files","p":["These settings control how the Data Bank documents are handled.","The following rules apply:","When file vectorization is disabled, the Data Bank is not used.","Otherwise, all available documents from the current scope (see above) are considered for the query. Only the most relevant chunks across all the files are retrieved. Multiple chunks of the same file are inserted in their original order.","The inserted chunks will reserve a part of the context before fitting the chat messages.","Size threshold (KB) - sets a chunking splitting threshold. Only the files larger than the specified size will be split.","Chunk size (chars) - sets the target size of an individual chunk (in textual characters, not model tokens!).","Retrieve chunks - sets the maximum amount of the file chunks to be retrieved. This allowance is shared between all files.","Injection Template - defines how the retrieved information will be inserted into the prompt. You can use a special {{text}} macro to specify the position of the retrieved text, as well as any other macros.","Injection Position - sets where to insert the prompt injection. The same rules as for Author's Note and World Info apply."]},{"l":"Shared settings","p":["Include in World Info Scanning - check if you want the injected content to activate lore book entries.","Vectorize All - forcibly ingests the embeddings for all unprocessed files.","Purge Vectors - clears the file embeddings, allowing to recalculate their vectors.","\"Chat vectorization\" settings are out of the scope of this guide and will not be covered here."]},{"l":"Conclusion","p":["Congratulations! Your chatting experience is now enhanced with the power of RAG. Its capabilities are only limited by your imagination. As always, don't be afraid to experiment!"]}],[{"l":"Group Chats"},{"l":"Reply order strategies","p":["Decides how characters in group chats are drafted for their replies."]},{"l":"Natural Order","p":["Tries to simulate the flow of a real human conversation. The algorithm is as follows:","Mentions of the group member names are extracted from the last message in chat.","Only whole words are recognized as mentions! If your character's name is \"Misaka Mikoto\", they will reply only activate on \"Misaka\" or \"Mikoto\", but never to \"Misa\", \"Railgun\", etc.","Unless the \"Allow Self Responses\" setting is enabled, characters won't reply to mentions of their name in their own message!","Characters are activated by the \"Talkativeness\" factor.","Talkativeness defines how often the character speaks if they were not mentioned. Adjust this value on the \"Advanced Definitions\" screen in the character editor. Slider values are on a linear scale from 0% / Shy(character never talks unless mentioned) to 100% / Chatty(character always replies). The default value for new characters is 50% chance.","A random character is selected.","If no characters were activated at previous steps, one speaker is selected randomly, ignoring all other conditions."]},{"l":"List Order","p":["Characters are drafted based on the order they are presented in the group members list. No other rules apply."]},{"l":"Group generation handling mode","p":["This setting decides how to handle the character information of the group chat members. No matter the choice, the group chat history is always shared between all the members."]},{"l":"Swap character cards","p":["Default mode. Every time the message is generated, only the character card information of the active speaker is included in the context."]},{"l":"Join character cards","p":["The information of all of the group members (excluding muted if they aren't the current speaker) is combined into one in their list order. This can help in cases when altering large chunks of the context is undesirable, e.g. with llama.cpp.","The following fields are being combined:","Description","Scenario, if not overridden for the chat","Personality","Message examples","Character notes / Depth prompts","Important! Please be aware that due to how the typical character card is structured, the use of this mode can lead to unexpected behavior, including but not limited to: characters being confused about themselves, having merged personalities, uncertain traits, etc."]},{"l":"Other Group Chat menu options"},{"l":"Mute Character","p":["The struck-out speech bubble icon next to the character avatar in the group chat menu can disable or enable replies from a particular character in the chat."]},{"l":"Force Talk","p":["The speech bubble icon next to the character avatar in the group chat menu will trigger a reply only from a particular character, bypassing the reply order strategy. It will work even if the group member is muted."]},{"l":"Auto-mode","p":["While auto-mode is enabled, the group chat will follow the reply order and trigger the message generation without user interaction. The next auto-mode turn is triggered after a 5-second delay when the last drafted character sends its message. When the user starts typing into the send message text area, the auto-mode will be disabled, but already queued generations are not stopped automatically."]},{"l":"Allow Self Responses","p":["Will allow consecutive replies from the character who sent the latest message of each turn if they happen to be triggered due to being self-mentioned when the Natural Order is selected. Has no effect on List order."]},{"l":"Group Chat Scenario Override","p":["All group members will use the entered scenario text instead of what is specified in their character cards. Branched chats inherit the scenario override from their parent and can be changed individually after that."]},{"l":"Peek Character Definitions","p":["Clicking on the character card icon next to the avatar in the group chat menu will quickly navigate to the usual character definitions screen. Any changes made here will be saved to the card itself.","To return back to the group chat, click the Group Name title link."]},{"l":"Member Management","p":["Any of your existing characters can be added, removed, muted, or re-ordered within the group chat. By default, a new member is added to the top of the group members list and then can be re-ordered using the arrow icons."]},{"l":"Group Chat pop-out","p":["The group chat menu pop-out can be activated by clicking on the icon next to the \"Current Members\" field. This creates a pop-out of the group chat menu. By enabling MovingUI from user settings, this menu can resized and dragged to any position within the interface and functions just like the regular group chat menu."]}],[{"l":"Instruct Mode","p":["Instruct Mode allows you to adjust the prompting for instruction-following models trained on various prompt formats, such as Alpaca, ChatML, Llama2, etc."]},{"l":"API support"},{"l":"Text Completion API","p":["Fully supported. This includes:","All of the sources under Text Completion","KoboldAI Classic","AI Horde"]},{"l":"Choosing a formatting","p":["A chosen instruct template must match the expectations of an actual model that is running on a backend.","This is usually reflected in a model card on HuggingFace, and some even provide SillyTavern-compatible JSON files.","Example: NeverSleep/Noromaid-13b-v0.1.1"]},{"i":"chat-completion-api-openai-claude-etc","l":"Chat Completion API (OpenAI, Claude, etc)","p":["This is not supported (and not needed) for Chat Completion APIs. They use an entirely different prompt builder.","Exception: OpenRouter with instruct override enabled. This is a legacy setting and will eventually be removed."]},{"l":"NovelAI","p":["While technically supported for NovelAI, none of their models were trained to understand instruct formatting. Kayra uses a special instruct module that is activated automatically when an instruction wrapped in curly braces is encountered in chat messages, so using Instruct Mode for the entire prompt will lead to degraded quality of the outputs.","Here's an example that auto-activates the instruct module for NovelAI:"]},{"l":"Instruct Mode Settings"},{"l":"Presets","p":["Provides ready-made presets with prompts and sequences for some well-known instruct models.","Changing a preset resets your system prompt to default! Don't forget to save your preset if you made any changes you don't want to lose."]},{"i":"default-preset-heart-icon","l":"Default preset (heart icon)","p":["If toggled, connecting to an API will automatically select this preset if no other presets were triggered by the regex match.","Instruct mode needs to be enabled prior. Only one preset can be marked as default."]},{"l":"Activation Regex","p":["If defined as a valid regular expression, when connected to a model and its name matches this regex, will automatically select this preset.","Instruct mode needs to be enabled prior. Only the first regex match across presets will be selected (evaluated in alphabetical order)."]},{"l":"Wrap Sequences with Newline","p":["Each sequence text will be wrapped with newline characters when inserted into the prompt. Required for Alpaca and its derivatives.","Disable if you want to have full control over line terminators."]},{"l":"Replace Macro in Sequences","p":["If enabled, known {{macro}} substitutions will be replaced if defined in message wrapping sequences.","Also, a special {{name}} macro can be used in message prefixes to reference the actual name attached to a message (rather than a currently active {{char}} or {{user}}), which can be helpful when using group chats or /sendas command. If the name can't be determined, \"System\" is used as a fallback placeholder."]},{"l":"Include Names","p":["If enabled, prepend characters and user names to chat history logs after inserting the sequences.","Automatically enabled for group chats and messages sent using personas, unless the Force for Groups and Personas setting is unchecked!"]},{"l":"System Prompt","p":["Usually added to the beginning of each prompt. Should define the instructions for the model to follow. Supports substitutions via any of the supported {{macro}} parameters.","For example:","Write one reply in internet RP style for {{char}}. Be verbose and creative."]},{"i":"sequences-system-prompt-wrapping","l":"Sequences: System Prompt Wrapping","p":["Define how the System Prompt will be wrapped."]},{"l":"System Prompt Prefix","p":["Inserted before a System prompt."]},{"l":"System Prompt Suffix","p":["Inserted after a System prompt.","Important: this applies only to the System Prompt itself, not the entire Story String! If you want to wrap the Story String, add these sequences to the Story String template in the Context Template section."]},{"i":"sequences-chat-messages-wrapping","l":"Sequences: Chat Messages Wrapping","p":["These settings define how messages belonging to different roles will be wrapped upon building a prompt.","All prefix sequences will also be automatically used as stopping strings."]},{"l":"User Message Prefix","p":["Inserted before a User message and as a last prompt line when impersonating."]},{"l":"User Message Suffix","p":["Inserted after a User message."]},{"l":"Assistant Message Prefix","p":["Inserted before an Assistant message and as a last prompt line when generating an AI reply."]},{"l":"Assistant Message Suffix","p":["Inserted after an Assistant message"]},{"l":"System Message Prefix","p":["Inserted before a System (added by slash commands or extensions) message."]},{"l":"System Message Suffix","p":["Inserted after a System message."]},{"l":"System same as User","p":["If checked true, System messages will be using User role message sequences.","Otherwise, System messages use their own sequences (if not empty) or will not do any wrapping at all (if empty)."]},{"l":"Misc. Sequences","p":["Various advanced configurations for finer tuning of the prompt building"]},{"l":"First Assistant Prefix","p":["Inserted before the first Assistant's message.","Only the first message of the chat history counts, not the message that actually goes into the prompt first!"]},{"l":"Last Assistant Prefix","p":["Inserted before the last Assistant's message or as a last prompt line when generating an AI reply.","Not used when generating text in a background (e.g. Stable Diffusion prompts or Summaries). System Instruction Prefix or Regular Assistant Prefix will be used instead."]},{"l":"System Instruction Prefix","p":["Inserted as a last prompt line when generating neutral/system text in a background (e.g. Stable Diffusion prompts or Summaries)."]},{"l":"User Filler Message","p":["Will be inserted at the start of the chat history if it doesn't start with a User message.","Use case: when an instruct format strictly requires prompts to be user-first and have messages with alternating roles only, examples: Llama 2 Chat, Mistral Instruct."]},{"l":"Stop Sequence","p":["Text that denotes the end of the reply. Also sent as a stopping string to the backend API.","If a stop sequence is generated, everything past it will be removed from the output (including the sequence itself)."]}],[{"l":"Persona Management"},{"i":"what-is-a-persona","l":"What is a persona?","p":["A persona in SillyTavern represents a combination of a user name and a picture that create a unique identity for the character you play in your chats or identify yourself as.","Creating user personas is optional, but it is a good way to automate routine actions."]},{"i":"how-to-create-a-persona","l":"How to create a persona?","p":["To create a persona:","Open the Persona Management panel (smiley face icon) in the top bar.","Select an existing avatar, or create a blank persona with a dummy image (\"Create\" button).","Find the persona in the list and pick the leftmost context action button (\"Bind a name to that avatar\").","Input a desired name into the popup window. Confirm by clicking an \"OK\" button.","The avatar now represents a Persona. Click on the avatar to select it, and this will also automatically update the user name."]},{"l":"Persona Description","p":["The contents of this field represent any specific information that you want to bind to the selected persona. It could be any kind of description of your user character: mental and physical traits, age, occupation, etc. Here you can also use replacement macros like {{user}}, {{char}}, and other supported parameters.","If defined, the Persona Description will be inserted into the AI prompt in one of the chosen places:","In Prompt Manager (Chat Completion API) or Story String (other APIs). This is the default position.","Top of an Author's Note (if Author's Note is not disabled).","Bottom of an Author's Note (if Author's Note is not disabled).","However, keep in mind that picking a persona when you have set user description on an unbound avatar will not keep your changes.","To permanently save the user description, bind the currently selected avatar to a user name."]},{"l":"Persona locking","p":["One chosen persona could be locked to the currently open individual or group chats. If the currently selected persona differs from the locked one, it will be automatically selected when you open that chat."]},{"l":"To lock a persona","p":["Open a chat (either group or individual).","Select a desired persona by clicking on its avatar.","Click the lock icon in the buttons row next to a name input.","To revert this action, click the unlock icon. Then persona won't be changed automatically when the chat is reopened.","Alternatively, you could use /lock and /unlock slash commands to achieve the same result."]},{"l":"Default persona","p":["You can select one persona as your preferred default identity, automatically selecting it for all new chats and chats where a persona is not locked. The default persona is represented by a yellow outline on the Persona Management panel.","To set persona as a default, click the \"crown\" button in the persona block, then confirm your action.","To undo this action and unset the default persona, click the \"crown\" button again."]},{"l":"Pro Tips","p":["Switching user personas in chat does not automatically change the attribution of previously sent user messages. That way it is possible to role-play as multiple user characters at once.","You can attribute all user-sent messages in the currently open chat to a currently selected persona by clicking the \"sync\" button on the Persona Management panel or by using the /sync slash command.","To change the persona image without deleting it, hover over the avatar on the Persona Management panel and click the bottom-left button. Then choose a new image and it will be replaced, preserving your set description and chat lock states.","To quickly change a persona while in chat without opening the Persona Management panel, use the /persona slash command. For example, /persona Blaze.","You can do backups of your Personas and restore them using the previously saved file if needed. Look for the \"Backup\" and \"Restore\" buttons in the Persona Management panel."]}],[{"l":"Slash commands","p":["/autobg – automatically changes the background based on the chat context (aliases: /bgauto)","/bg (filename) – sets a background according to the filename, partial names allowed, will set the first one alphabetically if multiple files begin with the provided argument string (aliases: /background)","/bind – binds/unbinds a persona (name and avatar) to the current chat","/depth (number) – sets an author's note depth for in-chat positioning","/freq (number) – sets an author's note insertion frequency (aliases: /interval)","/help – displays this help message (aliases: /?)","/lock – locks a background for the currently selected chat","/name (name) – sets user name and persona avatar (if set) (aliases: /persona)","/note (text) – sets an author's note for the currently selected chat","/pos (chat or scenario) – sets an author's note position (aliases: /position)","/roll (dice formula) – roll the dice. For example, /roll 2d6 (aliases: /r)","/sd (argument) – requests SD to make an image. Supported arguments:","/sendas – sends a message as a specific character.","/sync – syncs user name in user-attributed messages in the current chat","/sys (text) – sends message as a system narrator","/sysname (name) – sets a name for future system narrator messages in this chat (display only). Default: System. Leave empty to reset.","/taskcheck – checks if the current task is completed","/unlock – unlocks a background for the currently selected chat","Anything else would trigger a \"free mode\" to make SD generate whatever you prompted. example: '/sd apple tree' would generate a picture of an apple tree.","Example:","For the most up-to-date list of commands that will work in your instance, use the /help slash chat command in any SillyTavern chat.","This is not an exhaustive list as it is updated rarely."]}],[{"l":"UI Customization"},{"i":"ui-customization-1","l":"UI Customization"},{"l":"Message Sound","p":["To play your own custom sound on receiving a new message from bot, replace the following MP3 file in your SillyTavern folder:","public/sounds/message.mp3","Plays at 80% volume.","If \"Background Sound Only\" option is enabled, the sound plays only if SillyTavern window is unfocused."]},{"l":"UI Colors","p":["You can use the color pickers and sliders to customize the UI in many ways.","You can also save presets and share them with other users (saved into /data/user-handle/themes/)."]},{"l":"Power User Options"},{"l":"Formulas Rendering","p":["Enables math formulas rendering using the showdown-katex package.","The following formatting rules are supported:"]},{"l":"LaTeX syntax"},{"l":"Asciimath syntax","p":["More information: KaTeX"]}],[{"l":"World Info","p":["World Info (also known as Lorebooks or Memory Books) enhances AI's understanding of the details in your fictional world.","It functions like a dynamic dictionary that only inserts relevant information from World Info entries when keywords associated with the entries are present in the message text.","The SillyTavern engine activates and seamlessly integrates the appropriate lore into the prompt, providing background information to the AI.","It is important to note that while World Info helps guide the AI toward your desired lore, it does not guarantee its appearance in the generated output messages."]},{"l":"Pro Tips","p":["The AI does not insert keywords into context, so each World Info entry should be a comprehensive, standalone description.","To create rich and detailed world lore, entries can be interlinked and reference one another.","To conserve tokens, it is advisable to keep entry contents concise.","The World Info engine is a very powerful prompt management tool. Don't fixate on adding character lore alone, feel free to experiment."]},{"l":"Further reading","p":["World Info Encyclopedia: Exhaustive in-depth guide to World Info and Lorebooks. By kingbri, Alicat, Trappu."]},{"l":"Character Lore","p":["Optionally, one World Info file could be assigned to a character to serve as a dedicated lore source across all chats with that character (including groups).","To do that, navigate to a Character Management panel and click a globe button, then pick World Info from a dropdown list and click \"Ok\"."]},{"l":"Character Lore Insertion Strategy","p":["When generating an AI reply, entries from the character World Info will be combined with the entries from a global World Info selector using one of the following strategies:"]},{"i":"sorted-evenly-default","l":"Sorted Evenly (default)","p":["All entries will be sorted according to their Insertion Order as if they a part of one big file, ignoring the source."]},{"l":"Character Lore First","p":["Entries from the Character World Info would be included first by their Insertion Order, then entries from the Global World Info."]},{"l":"Global Lore First","p":["Entries from the Global World Info Info would be included first by their Insertion Order, then entries from the Character World Info."]},{"l":"World Info Entry"},{"l":"Key","p":["A list of keywords that trigger the activation of a World Info entry. Keys are not case-sensitive by default (this is configurable)."]},{"l":"Optional Filter","p":["A list of supplementary keywords that are used in conjunction with the main keywords. See Optional Filter."]},{"l":"Entry Content","p":["The text that is inserted into the prompt upon entry activation."]},{"l":"Insertion Order","p":["Numeric value. Defines a priority of the entry if multiple were activated at once. Entries with higher order numbers will be inserted closer to the end of the context as they will have more impact on the output."]},{"l":"Insertion Position","p":["Before Char Defs: World Info entry is inserted before the character's description and scenario. Has a moderate impact on the conversation.","After Char Defs: World Info entry is inserted after the character's description and scenario. Has a greater impact on the conversation.","Before Example Messages: The World Info entry is parsed as an example dialogue block and inserted before the examples provided by the character card.","After Example Messages: The World Info entry is parsed as an example dialogue block and inserted after the examples provided by the character card.","Top of AN: World Info entry is inserted at the top of Author's Note content. Has a variable impact depending on the Author's Note position.","Bottom of AN: World Info entry is inserted at the bottom of Author's Note content. Has a variable impact depending on the Author's Note position.","@ D: World Info entry is inserted at a specific depth in the chat (Depth 0 being the bottom of the prompt).","⚙️ - as a system role message","\uD83D\uDC64 - as a user role message","\uD83E\uDD16 - as an assistant role message","Example Message entries will be formatted according to the prompt-building settings: Instruct Mode or Chat Completion prompt manager. They also follow the Example Messages Behavior rules: being gradually pushed out on full context, always kept, or disabled altogether.","If your Author's Note is disabled (Insertion Frequency = 0), World Info entries in A/N positions will be ignored!"]},{"i":"entry-title--memo","l":"Entry Title / Memo","p":["A text field for your convenience to label your entries, which is not utilized by the AI or any of the trigger logics.","If empty, can be backfilled using the entries' first key by clicking on the \"Fill empty memos\" button."]},{"l":"Status","p":["\uD83D\uDD35 (Blue Circle) = The entry would always be present in the prompt.","\uD83D\uDFE2 (Green Circle) = The entry will be triggered only in the presence of the keyword.","\uD83D\uDD17 (Chain Link) = The entry is allowed to be inserted by embedding similarity.","❌ (Red Cross) = The entry is disabled."]},{"i":"optional-filter-1","l":"Optional Filter","p":["Comma-separated list of additional keywords in conjunction with the primary key. If no arguments are provided, this flag is ignored. Supports logic for AND ANY, NOT ANY, or NOT ALL","AND ANY = Activates the entry only if the primary key and Any one of the optional filter keys are in scanned context.","AND ALL = Activates the entry only if the primary key and ALL of the optional filter keys are present.","NOT ANY = Activates the entry only if the primary key and None of the optional filter keys are in scanned context.","NOT ALL = Prevents activation of the entry despite primary key trigger, if all of the optional filters are in scanned context."]},{"l":"Probability","p":["This value acts like an additional filter that adds a chance for the entry NOT to be inserted when it is activated by any means (constant, primary key, recursion).","Probability = 100 means that the entry will be inserted on every activation.","Probability = 50 means that the entry will be inserted with a 1:1 chance.","Probability = 0 means that the entry will NOT be inserted (essentially disabling it).","Use this to create random events in your chats. For example, every message could have a 1% chance of waking up an Elder God if its name is mentioned in the message."]},{"l":"Inclusion Group","p":["Inclusion groups control how entries are selected when multiple entries with the same group label are triggered simultaneously. If multiple entries having the same group label were activated, only one will be inserted into the prompt.","By default, the chosen entry is selected randomly based on their Group Weight (default is 100 points) — the higher the number, the higher the probability of selection. This allows for a random selection among the triggered entries, adding an element of surprise and variety to interactions."]},{"l":"Prioritize Inclusion","p":["To provide more control over which entries are activated via Inclusion Group, you can use the 'Prioritize Inclusion' setting. This option allows you to specify deterministically which entry to choose instead of randomly rolling Group Weight chances.","If multiple entries having the same group label and this setting turned on were activated, the one with the highest 'Order' value will be selected. This is useful for creating fallback sequences via inclusion groups. For example to priorize low-depth entries with more emphasis, or to choose a specific instruction on setting the scene over another if both are valid."]},{"l":"Use Group Scoring","p":["When this setting is enabled globally or per entry, the number of activated entry keys determines the group winner selection. Only the subset of a group with the highest number of key matches will be left to be activated by Group Weight or Inclusion Priority - the rest will be deactivated and removed from the group.","Use this to give more specificity for individual entries in large groups. For example, they can have a common key and a specific key. A random entry will be inserted when a specific key is not provided, and vice versa.","The score calculation logic for primary keys is 1 match = 1 point.","For secondary keys, the interaction depends on the chosen Selective Logic:","AND ANY: 1 secondary match = 1 point.","AND ALL: 1 point for every secondary key if they all match.","NOT ANY and NOT ALL: no change.","Example:","Entry 1. Keys: song, sing, Black Cat. Group: songs","Entry 2. Keys: song, sing, Ghosts. Group: songs","The input sing me a song can activate either entry (both activated 2 keys), but sing me a song about Ghosts will activate only Entry 2 (activated 3 keys)."]},{"l":"Automation ID","p":["Allows to integrate World Info entries with STscripts from Quick Replies extension. If both the quick reply command and the WI entry have the same Automation ID, the command will be executed automatically when the entry with a matching ID is activated.","Automations are executed in the order they are triggered, adhering to your designated sorting strategy, combining the Character Lore Insertion Strategy with the 'Priority' sorting. Which leads to Blue Circle entries processed first, followed by others in their specified 'Order'. Recursively triggered entries will be processed after in the same order.","The script command will run only once if multiple entries with the same Automation ID are activated."]},{"l":"Vector Storage Matching","p":["The Vector Storage extension provides an alternative to keyword matching by using the similarity between the recent chat messages and World Info entry contents.","To enable and use this, the following prerequisites need to be met:","Vector Storage extension is enabled and is configured to use one of the available embedding sources.","The \"Enable for World Info\" checkbox is ticked in the Vector Storage extension settings.","Either the World Info entries that are allowed for keyless matching have the \"Vectorized\" (\uD83D\uDD17) status or the \"Enabled for all entries\" option is checked in the Vector Storage settings.","The choice of the vectorization model in the extension and the theoretical meaning behind the term \"embeddings\" won't be covered here. Check out the Data Bank guide if you require more info on this topic.","Vector Storage matching adheres to this set of rules:","The maximum number of entries that are allowed to be matched with the Vector Storage can be adjusted with the \"Max Entries\" setting. This number only sets the limit and does not influence the token budget set in the activation settings for World Info. All of the budgeting rules still apply.","This feature only replaces the check for keywords. All additional checks must be met for the entry to be inserted: trigger%, character filters, inclusion groups, etc.","The \"Scan Depth\" setting from Activation Settings or entry overrides is not used. The Vector Storage \"Query messages\" value is utilized instead to get the text to match against. This allows for a configuration like \"Scan Depth\" set to 0, so no regular keyword matches will be made, but entries still can be activated by vectors.","A \"Vectorized\" status is only an additional marker. The entry would still behave like a normal, enabled, non-constant record that will be activated by keywords if they are set. Remove the keywords if you want them to be activated only by vectors.","Since the retrieval quality depends entirely on the outputs of the embedding model, it's impossible to predict exactly what entries will be inserted. If you want deterministic and predictable results, stick to keyword matching."]},{"l":"Activation Settings","p":["Collapsible menu at the top of the World Info screen."]},{"l":"Scan Depth","p":["Can be overridden on an entry level.","Defines how many messages in the chat history should be scanned for World Info keys.","If set to 0, then only recursed entries and Author's Note are evaluated.","If set to 1, then SillyTavern only scans the last message.","2 = two last messages, etc."]},{"i":"context---budget","l":"Context % / Budget","p":["Defines how many tokens could be used by World Info entries at once. You can define a threshold relative to your API's max-context settings (Context %) or an objective token threshold (Budget)","If the budget is exhausted, then no more entries are activated even if the keys are present in the prompt.","Constant entries will be inserted first. Then entries with higher order numbers.","Entries inserted by directly mentioning their keys have higher priority than those that were mentioned in other entries' contents."]},{"l":"Min Activations","p":["Minimum Activations: If set to a non-zero value, this will disregard the limitation of \"scan-depth\", seeking all of the chat log backward from the latest message for keywords until as many entries as specified in min activations have been triggered. This will still be limited by the Max Depth setting or your overall Budget cap."]},{"l":"Max Depth","p":["Maximum Depth to scan for when using the Min Activations setting."]},{"l":"Recursive scanning","p":["Entries can activate other entries by mentioning their keywords in the content text.","For example, if your World Info contains two entries:","Both of them will be pulled into the context if the message text mentions just Bessie."]},{"l":"Case-sensitive keys","p":["Can be overridden on an entry level.","To get pulled into the context, entry keys need to match the case as they are defined in the World Info entry.","This is useful when your keys are common words or parts of common words.","For example, when this setting is active, keys 'rose' and 'Rose' will be treated differently, depending on the inputs."]},{"l":"Match whole words","p":["Can be overridden on an entry level.","Entries with keys containing only one word will be matched only if the entire word is present in the search text. Enabled by default.","For example, if the setting is enabled and the entry key is \"king\", then text such as \"long live the king\" would be matched, but \"it's not to my liking\" wouldn't."]},{"l":"Alert on overflow","p":["Shows an alert if the activated World Info exceeds the allocated token budget."]}],[{"l":"Self-hosted AI models"},{"l":"Intro","p":["This guide aims to help you get set up using SillyTavern with a local AI running on your PC (we'll start using the proper terminology from now on and call it an LLM). Read it before bothering people with tech support questions."]},{"l":"Hardware requirements and orientation","p":["This is a complex subject, so I'll stick to the essentials and generalize.","There are thousands of free LLMs you can download from the Internet, similar to how Stable Diffusion has tons of models you can get to generate images.","Running an unmodified LLM requires a monster GPU with a ton of VRAM (GPU memory). More than you will ever have.","It is possible to reduce VRAM requirements by compressing the model using quantization techniques, such as GPTQ or AWQ. This makes the model somewhat less capable, but greatly reduces the VRAM requirements to run it. Suddenly, this allowed people with gaming GPUs like a 3080 to run a 13B model. Even though it's not as good as the unquantized model, it's still good.","It gets better: there also exists a model format and quantization called GGUF (previously GGML) which has become the format of choice for normal people without monster GPUs. This allows you to use an LLM without a GPU at all. It will only use CPU and RAM. This is much slower (probably 15 times) than running the LLM on a GPU using GPTQ/AWQ, especially during the prompt processing, but the model's ability is just as good. The GGUF creator then optimized GGUF further by adding a configuration option that allows people with a gaming-grade GPU to offload parts of the model to the GPU, allowing them to run part of the model at GPU speed (note that this doesn't reduce RAM requirements, it only improves your generation speed).","There are different sizes of models, named based on the number of parameters they were trained with. You will see names like 7B, 13B, 30B, 70B, etc. You can think of these as the brain size of the model. A 13B model will be more capable than the 7B from the same family of models: they were trained on the same data, but the bigger brain can retain the knowledge better and think more coherently. Bigger models also require more VRAM/RAM.","There are several degrees of quantization (8-bit, 5-bit, 4-bit, etc). The lower you go, the more the model degrades, but the lower the hardware requirements. So even on bad hardware, you might be able to run a 4-bit version of your desired model. There's even 3-bit and 2-bit quantization but at this point, you're beating a dead horse. There's also a further quantization subtypes named k_s, k_m, k_l, etc. k_m is better than k_s but requires more resources.","The context size (how long your conversation can become without the model dropping parts of it) also affects VRAM/RAM requirements. Thankfully, this is a configurable setting, allowing you to use a smaller context to reduce VRAM/RAM requirements. (Note: the context size of Llama2-based models is 4k. Mistral is advertised as 8k, but it's 4k in practice.)","Sometime in 2023, NVIDIA changed their GPU driver so that if you need more VRAM than your GPU has, instead of the task crashing, it will begin using regular RAM as a fallback. This will ruin the writing speed of the LLM, but the model will still work and give the same quality of output. Thankfully, this behavior can be disabled.","Given all of the above, the hardware requirements and performance vary completely depending on the family of model, the type of model, the size of the model, the quantization method, etc."]},{"l":"Model size calculator","p":["You can use Nyx's Model Size Calculator to determine how much RAM/VRAM you need.","Remember, you want to run the largest, least quantized model that can fit in your memory, i.e. without causing disk swapping."]},{"l":"Downloading an LLM","p":["To get started, you will need to download an LLM. The most common place to find and download LLMs is on HuggingFace. There are thousands of models available. A good way to find models is to check TheBloke's account page: https://huggingface.co/TheBloke. He's a one-man army dedicated to converting every model to GGUF. If you don't want GGUF, he links the original model page where you might find other formats for that same model.","On a given model's page, you will find a whole bunch of files.","You might not need all of them! For GGUF, you just need the .gguf model file (usually 4-11GB). If you find multiple large files, it's usually all different quantizations of the same model, you only need to pick one.","For .safetensors files (which can be GPTQ or AWQ or HF quantized or unquantized), if you see a number sequence in the filename like model-00001-of-00003.safetensors, then you need all 3 of those .safetensors files + all the other files in the repository (tokenizer, configs, etc.) to get the full model.","As of January 2024, Mixtral MOE 8x7B is widely considered the state of the art for local LLMs. If you have the 32GB of RAM to run it, definitely try it. If you have less than 32GB of RAM, then use Kunoichi-DPO-v2-7B, which despite its size is stellar out of the gate."]},{"l":"Walkthrough for downloading Kunoichi-DPO-v2-7B","p":["We will use the Kunoichi-DPO-v2-7B model for the rest of this guide. It's an excellent model based on Mistral 7B, that only requires 7GB RAM, and punches far above its weight. Note: Kunoichi uses Alpaca prompting.","Go to https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF","Click 'Files and versions'. You will see a listing of several files. These are all the same model but offered in different quantization options. Click the file 'kunoichi-dpo-v2-7b.Q6_K.gguf', which gives us a 6-bit quantization.","Click the 'download' button. Your download should start."]},{"l":"How to identify the type of model","p":["Good model uploaders like TheBloke give descriptive names. But if they don't:","Filename ends in .gguf: GGUF CPU model (duh)","Filename ends in .safetensors: can be unquantized, or HF quantized, or GPTQ, or AWQ","Filename is pytorch-***.bin: same as above, but this is an older model file format that allows the model to execute arbitrary Python script when the model is loaded, and is considered unsafe. You can still use it if you trust the model creator, or are desperate, but pick .safetensors if you have the option.","config.json exists? Look if it has a quant_method.","q4 means 4-bit quantization, q5 is 5-bit quantization, etc","You see a number like -16k? That's an increased context size (i.e. how long your conversation can get before the model forgets the beginning of your chat)! Note that higher context sizes require more VRAM."]},{"i":"installing-an-llm-server-oobabooga-or-koboldai","l":"Installing an LLM server: Oobabooga or KoboldAI","p":["With the LLM now on your PC, we need to download a tool that will act as a middle-man between SillyTavern and the model: it will load the model, and expose its functionality as a local HTTP web API that SillyTavern can talk to, the same way that SillyTavern talks with paid webservices like OpenAI GPT or Claude. The tool you use should be either KoboldAI or Oobabooga (or other compatible tools).","The rest of this guide will continue using Oobabooga, but these tools should be considered equivalent."]},{"l":"Installing Oobabooga","p":["Here's a more correct/dummy proof installation procedure:","git clone https://github.com/oobabooga/text-generation-webui(or download their repo as a .zip in your browser, then extract it)","Run start_windows.bat or whatever your OS is","When asked, select your GPU type. Even if you intend to use GGUF/CPU, if your GPU is in the list, select it now, because it will give you the option to use a speed optimization later called GPU sharding (without having to reinstall from scratch). If you have no gaming-grade dGPU (NVIDIA, AMD), select None.","Wait for the installation to finish","Place kunoichi-dpo-v2-7b.Q6_K.gguf in text-generation-webui/models","Open text-generation-webui/CMD_FLAGS.txt, delete everything inside and write: --api","Restart Oobabooga","Visit http://127.0.0.1:5000/docs. Does it load a FastAPI page? If not, you messed up somewhere."]},{"l":"Loading our model in Oobabooga","p":["Open http://127.0.0.1:7860/ in your browser","Click the Model tab","In the dropdown, select our Kunoichi DPO v2 model. It should have automatically selected the llama.cpp loader.","(Optional) We mentioned 'GPU offload' several times earlier: that's the n-gpu-layers setting on this page. If you want to use it, set a value before loading the model. As a basic reference, setting it to 30 uses just under 6GB VRAM for 13B and lower models. (it varies with model architecture and size)","Click Load"]},{"l":"Configuring SillyTavern to talk to Oobabooga","p":["Click API Connections (2nd button in the top bar)","Set API to Text Completion","Set API Type to Default (Oobabooga)","Set server URL to http://127.0.0.1:5000/","Click Connect. It should connect successfully and detect kunoichi-dpo-v2-7b.Q6_K.gguf as the model.","Chat with a character to test that it works"]},{"l":"Conclusion","p":["Congrats, you should now have a working local LLM."]},{"i":"part-2-configuring-sillytavern-to-get-better-outputs-from-the-llm","l":"Part 2: Configuring SillyTavern to get better outputs from the LLM","p":["So you chatted with the bot and it kind of sucks. Maybe it's a bad model. Maybe you're incapable of running better models and this is as good as it gets. But maybe you can fix her.","Read on in the next guide, How To Improve Output Quality"]}],[{"l":"How To Improve Output Quality","p":["So you chatted with the bot and it kind of sucks. Maybe it's a bad model. Maybe you can't run better models and this is as good as it gets. But maybe you can fix her."]},{"l":"Check if you can run a superior variant","p":["This should be common sense. We used a 7B model in our guide, but if your hardware can handle larger models, you should be using larger models like 13B and you will get better output. At the time of writing, I was unable to find a 13B or higher variant of openhermes-2.5-mistral, but this advice applies to many other models, of which there are multiple sizes.","Additionally, as long as you have free RAM/VRAM capacity to run a higher quantization (e.g. q5 or q8 instead of q4), then this will also produce better results."]},{"i":"adjust-sillytaverns-instruction-prompting","l":"Adjust SillyTavern's instruction prompting","p":["There's no single way of talking to an LLM: different ones were trained to respond to different methods of giving it asks (like \"Write the reply in this roleplay chat\"). On fancy cloud models like GPT4, the model is so powerful that it can understand a lot of implied context spoken in any manner of natural language.","LLMs running on your consumer hardware are not that good. Their output improves when you prompt them exactly like how the model expects you to prompt them. This is based on how the model creators trained it, and it's called the 'instruct style', as in how you instruct the model to do stuff for you.","SillyTavern comes with a few instruct templates (configuration schemes that tell SillyTavern how to talk to the model), but you will likely need to create your custom template to get SillyTavern to instruct properly. If only to change the default system prompt to something closer to what you want. In my experience, only the ChatML template didn't require me to make tweaks in ST. Most models are way worse than OpenHermes-2.5-Mistral-7B at producing a good output when SillyTavern prompts them poorly, so they benefit from this customization.","Your objective is to make SillyTavern adhere to the instruction style. To understand what's going on, we need to know three things:","What instruction style does the model expect?","Is SillyTavern using the correct instruction style?","If not, how do we create a new more correct instruction style in ST?"]},{"l":"Initial preparation","p":["In ST, we'll create a simple character called Betty, with the Description \"Betty is a fresh graduate in business administration.\", and First Message \"Hi, I'm Betty. I'm here for the job interview?\". Go ahead and create this character, we'll use it throughout this guide.","Additionally, we'll need a model which requires customization to work well. We'll use TheBloke/Starling-LM-7B-alpha-GGUF as our example in this guide. It's another highly-rated model."]},{"i":"1-what-instruction-style-does-the-model-expect","l":"1. What instruction style does the model expect?","p":["Starling's page says \"Our model follows the exact chat template and usage as Openchat 3.5. Please refer to their model card for more details.\" OpenChat 3.5's page says, under 'Conversation Templates (click to expand)', that the way to do multi-turn (i.e. chat) is:","If we ignore the Python code, and add some newlines, we see it's expecting to receive this:","So now we know how to properly prompt it."]},{"i":"2-is-sillytavern-using-the-correct-instruction-style","l":"2. Is SillyTavern using the correct instruction style?","p":["SillyTavern's interaction with the LLM is configured in the AI Response Formatting window (the 3rd button at the top). There are two major sections: Context Template, and Instruct Mode. Both have some presets for popular model families.","(Side note: When Ooba loads Starling in Ooba, it says it's an Alpaca instruct style. This is wrong, we know the model creators/fine-tuners said it's an OpenChat 3.5 style. Ooba must not be trusted when it comes to making the most out of the model. Only follow its advice when you have otherwise zero information about a model and it's better than nothing.)","Let's start simple. Configure SillyTavern to use Context Template = Default, and Instruct Mode = OpenOrca-OpenChat. OpenOrca-OpenChat is the closest thing SillyTavern has to OpenChat, right? So it's your natural starting point.","Start a new chat with Betty, and send \"That's right. Come on in.\" You will immediately see how awful the reply is. Here's what I got:","At this point, you would immediately give up on this model and think it's unsuitable for chat, right? Before we give up on the model, let's see if SillyTavern is using it right. Look at the ST's console, for the 'prompt' it sent. We see it sent this:","No wonder Betty's replies are so awful. Our OpenOrca-OpenChat template has an awful default system prompt that doesn't mention roleplaying or chat, and we're not following the model's instruction format because we use 'User' instead of 'GPT4 Correct User'.","Let's see how we can fix this."]},{"i":"3-how-do-we-create-a-new-more-correct-instruction-style","l":"3. How do we create a new more correct instruction style?","p":["Our objective is to turn ST's default prompt into something that follows OpenChat 3.5's instruct style, and additionally provide a better system prompt. I'm writing a gradual walkthrough so you can apply this approach to any future model you encounter and be able to do it yourself, but if you want the final solution, just skip to the end."]},{"i":"round-1-fix-the-system-prompt","l":"Round 1: fix the system prompt","p":["A reminder that our goal is sticking to OpenChat's instruct style:","In the AI Response Formatting window, create a new Instruct Mode preset, by clicking the Save Preset As button, and name it Starling. Write this in it:","This prompt achieves 2 objectives:","It replaces the awful default prompt with something related to chat and roleplaying","It follows OpenChat's expected instruct style, including clear instructions","Send \"That's right. Come on in.\" to Betty, and let's see what comes out on the console:","We can spot 3 issues:","SillyTavern is sending 'Assistant:' instead of 'GPT4 Correct Assistant:' once the chat actually starts","SillyTavern is sending 'User:' instead of 'GPT4 Correct User:'","Betty's description is inserted in the middle without adhering to the OpenChat format: it's not mentioned as part of a 'GPT4 Correct User: blah blah <|end_of_turn|>' line."]},{"i":"round-2-more-tweaks","l":"Round 2: more tweaks","p":["Issues #1 and #2 are an easy fix: under Instruct Mode Sequences, simply change Input Sequence from 'User:' to 'GPT4 Correct User:', and Output Sequence's '<|end_of_turn|> Assistant:' to '<|end_of_turn|> GPT4 Correct Assistant:' (NOTE: there's a newline before GPT4 Correct Assistant, i.e. press Enter). You can save your preset and try again to confirm that solves these issues.","Now for the description. If you're happy with Betty's replies now, stop here. If you want to go deeper, read on."]},{"i":"round-3-optional-final-description-tweak","l":"Round 3 (optional): final description tweak","p":["You shouldn't bother doing this if you're happy with the model now. I'm showing it here to demonstrate how to make SillyTavern do your bidding when you do need to make a major change. This round of tweaks is more invasive and will discard the optional sections of a character card (scenario, personality, etc).","On the AI Response Formatting page, SillyTavern has a setting at the top called StoryString. This defines what SillyTavern will send to your model. For example, by default, it will send the system prompt (that's the {{system}} entry), then {{wiBefore}}(World Info marker), then {{description}} which is the character description, then other stuff.","Create a new Context Template preset based on Default, by clicking the Save Preset As button at the top, and name it Starling. The formatting is unusual on that syntax because the closing {{/if}} must be on the next line, but basically, it follows the format {{#if system}}{{system}}{{/if}}. This says to send the LLM the system prompt if it exists, and it's the same for all the other entries.","What we're going to do is tell SillyTavern to stop sending the description as part of the Story String (which doesn't let us customize it with <|end_of_turn|>).","So let's replace:","with:","Now there won't be any description sent. So how are we supposed to give Betty's description within the OpenChat format? Edit your system prompt to this:","We just added Description of {{char}}: {{description}}|end_of_turn| to our system prompt. So although our Story String no longer sends the description, we send our system prompt, and our system prompt includes the description, so it's all good.","(Note that we also removed several other things such as scenario, personality, etc. None of my characters use these optional fields so I didn't bother covering them. You can do the same fix for those. You could write something in the system prompt like this e.g. scenario: \"If the following scenario definition is not empty, follow the scenario: SCENARIO DEFINITION: {{scenario}}.)","If you use persona descriptions or World Info, you must add their macro placeholders to the system prompt or story string, otherwise they will NOT be sent to a model. See Advanced Formatting for a more in-depth explanation."]},{"l":"Conclusion","p":["Chat with Betty and the output should speak for itself. She went from writing awful to doing decent roleplaying chat replies. So whenever you're using the Starling model, you should be using your new Starling presets in ST.","Example output from Betty now (which you can improve further by modifying the system prompt as you wish):"]}],[{"l":"Branches"},{"l":"Branches","p":["SillyTavern is being developed using a multi-branch system to ensure a smooth experience for all users.","release- Recommended for most users. This is the most stable and recommended branch, updated only when major releases are pushed. It's suitable for the majority of users.","staging- Not recommended for casual use. This branch has the latest features, but be cautious as it may break at any time. Only for power users and enthusiasts.","main and dev- These branches are deprecated, will not receive updates, and will be deleted on September 1, 2023. You are encouraged to switch branches before the deadline."]},{"i":"what-happened-to-the-main-and-dev","l":"What happened to the main and dev?","p":["The git commit history was squashed to the state of release 1.9.0.","Old branches were carrying the long legacy of bad git practices and large binary files once present in the repository. Every git clone would download and store a lot of unnecessary files, creating a network and disk load. Also, it makes it virtually impossible for us to properly update the default content such as settings.json without causing git conflicts.","Unfortunately, losing commit history also means losing the code contribution history. If you contributed to the SillyTavern development and want to see yourself credited in the README file and Docs website, please get in touch with us!"]},{"i":"how-to-migrate-to-a-new-branch-if-i-use-maindev","l":"How to migrate to a new branch if I use main/dev?","p":["It is recommended to do a fresh install. However, if you wish to use an existing copy of SillyTavern, please follow the instructions below.","IMPORTANT! Before doing anything, make a complete backup of your installation. You may lose your data in the process, so don't ignore this warning.","Not sure of which files to back up? See the list here: How to Update SillyTavern"]},{"l":"git installs","p":["Open a terminal prompt (cmd, PowerShell, Termux, etc) in your SillyTavern installation folder.","Type git fetch and then git pull to pull the updates.","You may lose your settings. Have you made a backup? git switch release or git switch staging will change your branch, respectively","Skip to next item if you have no errors. You may have something like:","You will see a list of files effected. If you do not care about those settings files being replaced git switch -f release or git switch -f staging will set your branch. If you do care to save those changes restore from backup.","Type npm install and then npm run start to test that everything behaves correctly.","Enjoy! Restore your data from a backup if needed."]},{"i":"fatal-invalid-reference-release","l":"fatal: invalid reference: release","p":["This may happen if you cloned just a single branch from an old remote (before migration to the organization repo). To fix this, you need to add and fetch a branch from a new remote:","Then proceed from step 5."]},{"l":"ZIP installs","p":["Nothing changes for you. Just download the branch/release ZIP like usual."]}],[{"l":"HotKeys","p":["For the most up-to-date list of HotKeys that will work in your SillyTavern instance, use the /help hotkeys slash command in any chat.","Up = Edit last message in chat","Ctrl+Up = Edit last USER message in chat","Left = swipe left","Right = swipe right (NOTE: swipe hotkeys are disabled when chatbar has something typed into it)","Enter (with chat bar selected) = send your message to AI","Ctrl+Enter = Regenerate the last AI response","Alt+Enter = Continue the last AI response","Escape","(while editing message AND Message Edit AutoSave is enabled)= close edit box.","(while an AI message is generating or streaming)= stop the generation immediately.","Hotkeys are disabled for mobile devices"]}],[{"l":"STscript Language Reference"},{"i":"what-is-stscript","l":"What is STscript?","p":["It's a simple yet powerful scripting language that could be used to expand the functionality of SillyTavern without serious coding, allowing you to:","Create mini-games or speed run challenges","Build AI-powered chat insights","Unleash your creativity and share with others","STscript is built using the slash commands engine, utilizing command batching, data piping, macros, and variables. These concepts are going to be described in the following document.","STscript is still in active development. It's recommended to use the staging branch if you plan to use any of its features."]},{"l":"Security precaution","p":["With great power comes great responsibility. Be careful and always inspect the scripts before executing them."]},{"i":"hello-world","l":"Hello, World!","p":["To run your first script, open any SillyTavern chat and type the following into the chat input bar:","Hello World","You should see the message in the toast on top of the screen. Now let's break it down bit by bit.","A script is a batch of commands, each one starting with the slash, with or without named and unnamed arguments, and terminated with the command separator character: |.","Commands are executed sequentially, one after another, and transfer data between each other.","The /pass command accepts a constant value of \"Hello, World!\" as an unnamed argument and writes it to the pipe.","The /echo command receives the value through the pipe from the previous command and displays it as a toast notification.","Hint: To see a list of all available commands, type /help slash into the chat.","As constant unnamed arguments and pipes are interchangeable, we could rewrite this script simply as:"]},{"l":"User input","p":["Now let's add a little bit of interactivity to the script. We will accept the input value from the user and display it in the notification.","The /input command is used to display an input box with the prompt specified in the unnamed argument and then writes the output to the pipe.","Because /echo already has an unnamed argument that sets the template for the output, we use the {{pipe}} macro to specify a place where the pipe value will be rendered.","Slim Shady Input","Slim Shady Output"]},{"i":"other-inputoutput-commands","l":"Other input/output commands","p":["/popup (text)— shows a blocking popup, supports lite HTML formatting, e.g: /popup font color=redI'm red!/font.","/setinput (text)— replaces the contents of the user input bar with the provided text.","/speak voice=name (text)— narrates the text using the selected TTS engine and the character name from the voice map, e.g. /speak name=Donald Duck Quack!.","/buttons labels=[a,b] (text)— shows a blocking popup with the specified text and button labels. labels must be a JSON-serialized array of strings or a variable name containing such an array. Returns the clicked button label into the pipe or empty string if canceled. The text supports lite HTML formatting."]},{"i":"arguments-for-popup-and-input","l":"Arguments for /popup and /input","p":["/popup and /input support the following additional named arguments:","large=on/off- increases the vertical size of the popup. Default: off.","wide=on/off- increases the horizontal size of the popup. Default: off.","okButton=string- adds ability to customize the text on the \"Ok\" button. Default: Ok.","rows=number- (only for /input) increases the size of the input control. Default: 1.","Example:"]},{"i":"arguments-for-echo","l":"Arguments for /echo","p":["/echo supports the following values for the additional severity argument that sets the style of the displayed message.","warning","error","info(default)","success","Example:"]},{"l":"Variables","p":["/addglobalvar key=name or {{addglobalvar::name:increment}}— adds the increment to the value of the global variable.","/addvar key=name increment or {{addvar::name::increment}}— adds the increment to the value of the local variable.","/decglobalvar name or {{decglobalvar::name}}— decrements a value of the global variable by 1.","/decvar name or {{decvar::name}}— decrements a value of the local variable by 1.","/flushglobalvar name— deletes the value of the global variable.","/flushvar name— deletes the value of the local variable.","/getglobalvar name or {{getglobalvar::name}}— gets the value of the global variable.","/getvar name or {{getvar::name}}— gets the value of the local variable.","/incglobalvar name or {{incglobalvar::name}}— increments a value of the global variable by 1.","/incvar name or {{incvar::name}}— increments a value of the local variable by 1.","/setglobalvar key=name or {{setglobalvar::name::value}}— sets the value of the global variable.","/setvar key=name value or {{setvar::name::value}}— sets the value of the local variable.","All slash commands for variable manipulation write the resulting value into the pipe for the next command to use.","For macros, only the \"get\", \"inc\", and \"dec\" type macro returns the value, \"add\" and \"set\" are replaced with an empty string instead.","Global variables — saved to the settings.json and exist everywhere across the app.","If a command argument accepts a variable name and both local and global variables exist with the same name, then the local variable takes priority.","Increment in the /addvar command performs an addition or subtraction of the value if both increment and the variable value can be converted to a number, or otherwise does the string concatenation.","Local variables — saved to the metadata of the current chat, and unique to it.","Now, let's consider the following example:","Since the variables are saved and not flushed between the script executions, you can reference the variable in other scripts and via macros, and it will resolve to the same value as during the execution of the example script. To guarantee that the value will be discarded, add the /flushvar command to the script.","The default value of previously undefined variables is an empty string or a zero of it is first used in the /addvar, /incvar, /decvar command.","The getvar command is used to retrieve the value of the variable and pass it through the pipe.","The getvar macro is used to display the value in the /echo command.","The value is passed to the /imagine command (provided by the Image Generation plugin) to be used as its input prompt.","The value of the user input is saved in the local variable named SDinput.","Variables are used to store and manipulate data in scripts, using either commands or macros. The variables could be one of the following types:"]},{"l":"Arrays and objects","p":["Variable values can contain JSON-serialized arrays or key-value pairs (objects).","Examples:","Array: [apple,banana,orange]","Object: {fruits:[apple,banana,orange]}","The following modifications can be applied to commands to work with these variables:","/len commands gets a number of items in the array.","index=number/string named argument can be added /getvar or /setvar and their global counterparts to get or set sub-values by either a zero-based index for arrays or a string key for objects.","If a numeric index is used on a nonexistent variable, the variable will be created as an empty array [].","If a string index is used on a nonexistent variable, the variable will be created as an empty object {}.","/addvar and /addglobalvar commands support pushing a new value to array-typed variables."]},{"i":"flow-control---conditionals","l":"Flow control - conditionals","p":["You can use the /if command to create conditional expressions that branch the execution based on the defined rules.","/if left=valueA right=valueB rule=comparison else=(command on false) (command on true)","Let's review the following example:","This script evaluates the user input against a required value and displays different messages, depending on the input value."]},{"i":"arguments-for-if","l":"Arguments for /if","p":["left is the first operand. Let's call it A.","right is the second operand. Let's call it B.","rule is the operation to be applied to the operands.","else is the optional string of subcommands to be executed if the result of boolean comparison is false.","Unnamed argument is the subcommand to be executed if the result of boolean comparison is true.","The operand values are evaluated in the following order:","Numeric literals","Local variable names","Global variable names","String literals","String values of named arguments could be escaped with quotes to allow multi-word strings. Quotes are then discarded."]},{"l":"Boolean operations","p":["Supported rules for boolean comparison are the following. An operation applied to the operands results in either a true or false value.","eq(equals) => A = B","neq(not equals) => A != B","lt(less than) => A < B","gt(greater than) => A > B","lte(less than or equals) => A <= B","gte(greater than or equals) => A >= B","not(unary negation) => !A","in(includes substring) => A includes B, case insensitive","nin(not includes substring) => A not includes B, case insensitive"]},{"l":"Subcommands","p":["A subcommand is a string containing a list of slash commands to execute.","To use command batching in subcommands, the command separator character should be escaped (see below).","Since macro values are executed when the conditional is entered, not when the subcommand is executed, a macro could be additionally escaped to delay their evaluation to the subcommand execution time.","The result of the subcommands execution is piped to the command after /if.","The /abort command interrupts the script execution when encountered.","/if commands can be used as a ternary operator. The following example will pass a \"true\" string to the next command the variable a equals 5, and a \"false\" string otherwise."]},{"l":"Escape Sequences"},{"l":"Macros","p":["Escaping of macros works just like before. However, with closures, you will need to escape macros a lot less often than before. Either escape the two opening curly braces, or both the opening and closing pair."]},{"l":"Pipes","p":["Pipes don't need to be escaped in closures (when used as command separators). Everywhere where you want to use a literal pipe character instead of a command separator, you need to escape it.","With the parser flag STRICT_ESCAPING you don't need to escape pipes in quoted values."]},{"l":"Quotes","p":["To use a literal quote-character inside a quoted value, the character must be escaped."]},{"l":"Spaces","p":["To use space in the value of a named argument, you either have to surround the value in quote, or escape the space character."]},{"l":"Closure Delimiters","p":["If you want to use the character combinations used to mark the beginning or end of a closure, you have to escape the sequence with a single backslash."]},{"l":"Pipe Breakers","p":["To prevent the previous command's output from being automatically injected as the unnamed argument into the next command, put double pipes between the two commands."]},{"l":"Closures","p":["Closures (block statements, lambdas, anonymous functions, whatever you want to call them) are a series of commands wrapped between {: and :}, that are only evaluated once that part of the code is executed."]},{"l":"Sub-Commands","p":["Closures make using sub-commands a lot easier and get rid of the need to escape pipes and macros."]},{"l":"Scopes","p":["Closures have their own scope and support scoped variables. Scoped variables are declared with /let, their values set and retrieved with /var. Another way to get a scoped variable is the {{var::}} macro.","Within a closure, you have access to all variables declared within that same closure or in one of its ancestors. You don't have access to variables declared in a closure's descendants. If a variable is declared with the same name as a variable that was declared in one of the closure's ancestors, you don't have access to the ancestor variable in this closure and its descendants."]},{"l":"Named Closures","p":["Closures can be assigned to variables (only scoped variables) to be called at a later point or to be used as sub-commands.","/: can also be used to execute Quick Replies, as it is just a shorthand for /run."]},{"l":"Closure Arguments","p":["Named closures can take named arguments, just like slash commands. The arguments can have default values."]},{"l":"Immediately Executed Closures","p":["Closures can be immediately executed, meaning they will be replaced with their return value. This is helpful in places where no explicit support for closures exists, and to shorten some commands that would otherwise require a lot of intermediate variables."]},{"l":"Comments","p":["A comment is a human-readable explanation or annotation in the script code. Comments don't break pipes."]},{"i":"flow-control---loops","l":"Flow control - loops","p":["If you need to run some command in a loop until a certain condition is met, use the /while command.","On each step of the loop it compares the value of variable A with the value of variable B, and if the condition yields true, then executes any valid slash command enclosed in quotes, otherwise exists the loop. This command doesn't write anything to the output pipe."]},{"i":"arguments-for-while","l":"Arguments for /while","p":["The set of available boolean comparisons, handing of variables, literal values, and subcommands is the same as for the /if command.","The optional guard named argument ( on by default) is used to protect against endless loops, limiting the number of iterations to 100. To disable and allow endless loops, set guard=off.","This example adds 1 to the value of i until it reaches 10, then outputs the resulting value (10 in this case)."]},{"i":"arguments-for-times","l":"Arguments for /times","p":["Runs a subcommand a specified number of times.","/times (repeats) (command)– any valid slash command enclosed in quotes repeats a number of times, e.g. /setvar key=i 1 | /times 5 /addvar key=i 1 adds 1 to the value of \"i\" 5 times.","{{timesIndex}} is replaced with the iteration number (zero-based), e.g. /times 4 /echo {{timesIndex}} echoes the numbers 0 through 4.","Loops are limited to 100 iterations by default, pass guard=off to disable."]},{"l":"Math operations","p":["/abs (a)– performs an absolute value operation of a value, e.g. /abs -10","/add (a b c d)– performs an addition of the set of values, e.g. /add 10 i 30 j","/cos (a)– performs a cosine operation of a value, e.g. /cos i","/div (a b)– performs a division of two values, e.g. /div 10 i","/log (a)– performs a natural logarithm operation of a value, e.g. /log i","/max (a b c d)– returns a maximum from the set of values, e.g. /max 1 0 4 k","/min (a b c d)– return a minimum from the set of values, e.g. /min 5 4 i 2","/mod (a b)– performs a modulo operation of two values, e.g. /mod i 2","/mul (a b c d)– performs a multiplication of the set of values, e.g. /mul 10 i 30 j","/pow (a b)– performs a power operation of two values, e.g. /pow i 2","/rand (round=round|ceil|floor from=number=0 to=number=1)– returns a random number between from and to, e.g. /rand or /rand 10 or /rand from=5 to=10. Ranges are inclusive. The returned value will contain a fractional part. Use round named argument to get an integral value, e.g. /rand round=ceil to round up, round=floor to round down, and round=round to round to nearest.","/round (a)– performs a rounding to the nearest integer operation of a value, e.g. /round 3.14","/sin (a)– performs a sine operation of a value, e.g. /sin i","/sqrt (a)– performs a square root operation of a value, e.g. /sqrt 9","/sub (a b)– performs a subtraction of two values, e.g. /sub i 5","All of the following operations accept a series of numbers or variable names and output the result to the pipe.","Invalid operations (such as division by zero), and operations that result in a NaN value or infinity return zero.","List of operations:","Multiplication, addition, minimum and maximum accept an unlimited number of arguments separated by spaces.","Sine, cosine, natural logarithm, square root, absolute value, and rounding accept one argument.","Subtraction, division, exponentiation, and modulo accept two arguments separated by spaces."]},{"i":"example-1-get-an-area-of-a-circle-with-a-radius-of-50","l":"Example 1: get an area of a circle with a radius of 50."},{"i":"example-2-calculate-a-factorial-of-5","l":"Example 2: calculate a factorial of 5."},{"l":"Using the LLM","p":["Scripts can make requests to your currently connected LLM API using the following commands:","/gen (prompt)— generates text using the provided prompt for the selected character and including chat messages.","/genraw (prompt)— generates text using just the provided prompt, ignoring the current character and chat.","/trigger— triggers a normal generation (equivalent to clicking a \"Send\" button). If in group chat, you can optionally provide a 1-based group member index or a character name to have them reply, otherwise triggers a group round according to the group settings."]},{"i":"arguments-for-gen-and-genraw","l":"Arguments for /gen and /genraw","p":["lock— can be on or off. Specifies whether a user input should be blocked while the generation is in progress. Default: off.","stop— JSON-serialized array of strings. Adds a custom stop string (if the API supports it) just for this generation. Default: none.","instruct(only /genraw) — can be on or off. Allows to use instruct formatting on the input prompt (if instruct mode is enabled and the API supports it). Set to off to force pure prompts. Default: on.","as(for Text Completion APIs) — can be system(default) or char. Defines how the last prompt line will be formatted. char will use a character name, system will use no or neutral name.","The generated text is then passed through the pipe to the next command and can be saved to a variable or displaced using the I/O capabilities:","Cthulhu Says"]},{"l":"Prompt injections","p":["Scripts can add custom LLM prompt injections, making it essentially an equivalent of unlimited Author's Notes.","/inject (text)— inserts any text into the normal LLM prompt for the current chat, and requires a unique identifier. Saved to chat metadata.","/listinjects— shows a list of all prompt injections added by scripts for the current chat in a system message.","/flushinjects— deletes all prompt injections added by scripts for the current chat.","/note (text)— sets the Author's Note value for the current chat. Saved to chat metadata.","/interval— sets the Author's Note insertion interval for the current chat.","/depth— sets the Author's Note insertion depth for the in-chat position.","/position— sets the Author's Note position for the current chat."]},{"i":"arguments-for-inject","l":"Arguments for /inject","p":["id— an identifier string or a reference to a variable. Consequent calls of /inject with the same ID will overwrite the previous text injection. Required argument.","position— sets a position for the injection. Default: after. Possible values:","after: after the main prompt.","before: before main prompt.","chat: in-chat.","depth— sets an injection depth for the in-chat position. 0 means insertion after the last message, 1 - before the last message, etc. Default: 4.","Unnamed argument is a text to be injected. An empty string will unset the previous value for the provided identifier."]},{"l":"Access chat messages"},{"l":"Read messages","p":["You can access messages in the currently selected chat using the /messages command.","The names argument is used to specify whether you want to include character names or not, default: on.","In an unnamed argument, it accepts a message index or range in the start-finish format. Ranges are inclusive!","If the range is unsatisfiable, i.e. an invalid index or more messages than exist are requested, then an empty string is returned.","Messages that are hidden from the prompt (denoted by the ghost icon) are excluded from the output.","If you want to know the index of the latest message, use the {{lastMessageId}} macro, and {{lastMessage}} will get you the message itself.","To calculate the start index for a range, for example, when you need to get the last N messages, use variable subtraction. This example will get you 3 last messages in the chat:"]},{"l":"Send messages","p":["A script can send messages as either a user, character, persona, neutral narrator, or add comments.","/send (text)— adds a message as the currently selected persona.","/sendas name=charname (text)— adds a message as any character, matching by their name. name argument is required. Use the {{char}} macro to send as the current character.","/sys (text)— adds a message from the neutral narrator that doesn't belong to the user or character. The displayed name is purely cosmetic and can be customized with the /sysname command.","/comment (text)— adds a hidden comment that is displayed in the chat but is not visible to the prompt.","/addswipe (text)— adds a swipe to the last character message. Can't add a swipe to the user or hidden messages.","/hide (message id or range)— hides one or several messages from the prompt based on the provided message index or inclusive range in the start-finish format.","/unhide (message id or range)— returns one or several messages to the prompt based on the provided message index or inclusive range in the start-finish format.","/send, /sendas, /sys, and /comment commands optionally accept a named argument at with a zero-based numeric value (or a variable name that contains such a value) that specifies an exact position of message insertion. By default new messages are inserted at the end of the chat log.","This will insert a user message at the beginning of the conversation history:"]},{"l":"Delete messages","p":["These commands are potentially destructive and have no \"undo\" function. Check the /backups/ folder if you accidentally deleted something important.","/cut (message id or range)— cuts one or several messages from the chat based on the provided message index or inclusive range in the start-finish format.","/del (number)— deletes last N messages from the chat.","/delswipe (1-based swipe id)— deletes a swipe from the last character message based on the provided 1-based swipe ID.","/delname (character name)— deletes all messages in the current chat that belong to a character with the specified name.","/delchat— deletes the current chat."]},{"l":"World Info commands","p":["World Info (also known as Lorebook) is a highly utilitarian tool for dynamically inserting data into the prompt. See the dedicated page for more detailed explanation: World Info.","/getchatbook– gets a name of the chat-bound World Info file or create a new one if was unbound, and pass it down the pipe.","/findentry file=bookName field=fieldName [text]– finds a UID of the record from the specified file (or a variable pointing to a file name) using fuzzy matching of a field value with the provided text (default field: key) and passes the UID down the pipe, e.g. /findentry file=chatLore field=key Shadowfang.","/getentryfield file=bookName field=field [UID]– gets a field value (default field: content) of the record with the UID from the specified World Info file (or a variable pointing to a file name) and passes the value down the pipe, e.g. /getentryfield file=chatLore field=content 123.","/setentryfield file=bookName uid=UID field=field [text]– sets a field value (default field: content) of the record with the UID (or a variable pointing to UID) from the specified World Info file (or a variable pointing to a file name). To set multiple values for key fields, use a comma-delimited list as a text value, e.g. /setentryfield file=chatLore uid=123 field=key Shadowfang,sword,weapon.","/createentry file=bookName key=keyValue [content text]– creates a new record in the specified file (or a variable pointing to a file name) with the key and content (both of these arguments are optional) and passes the UID down the pipe, e.g. /createentry file=chatLore key=Shadowfang The sword of the king."]},{"l":"Valid entry fields","p":["(see below)","0 = AND, 1 = NOT","0 = before main prompt","1 = after main prompt","2 = top of Author's Note","3 = bottom of Author's Note","4 = in-chat at depth","Boolean (1/0)","Case-Sensitive","caseSensitive","comment","constant","Constant Status","content","depth","disable","Disabled Status","excludeRecursion","Field","key","keysecondary","List of strings","Logic","Match Whole Words","matchWholeWords","Non-recursable","Number","Number (0-100)","Number (0-999)","Optional Filter","order","position","Position values","Primary Keywords","probability","Scan Depth","scanDepth","selectiveLogic","String","Title / Memo","Trigger%","UI element","Value type"]},{"i":"example-1-read-a-content-from-the-chat-lorebook-by-key","l":"Example 1: Read a content from the chat lorebook by key"},{"i":"example-2-create-a-chat-lorebook-entry-with-key-and-content","l":"Example 2: Create a chat lorebook entry with key and content"},{"i":"example-3-expand-an-existing-lorebook-entry-with-new-information-from-the-chat","l":"Example 3: Expand an existing lorebook entry with new information from the chat"},{"l":"Text manipulation","p":["There's a variety of useful text manipulation utility commands to be used in various script scenarios.","/trimtokens— trims the input to the specified number of text tokens from the start or from the end and outputs the result to the pipe.","/trimstart— trims the input to the start of the first complete sentence and outputs the result to the pipe.","/trimend— trims the input to the end of the last complete sentence and outputs the result to the pipe.","/fuzzy— performs fuzzy matching of the input text to the list of strings, outputting the best string match to the pipe.","/regex name=scriptName [text]— executes a regex script from the Regex extension for the specified text. The script must be enabled."]},{"i":"arguments-for-trimtokens","l":"Arguments for /trimtokens","p":["direction sets the direction for trimming, which can be either start or end. Default: end.","limit sets the amount of tokens to left in the output. Can also specify a variable name containing the number. Required argument.","Unnamed argument is the input text to be trimmed."]},{"i":"arguments-for-fuzzy","l":"Arguments for /fuzzy","p":["list is a JSON-serialized array of strings containing the candidates. Can also specify a variable name containing the list. Required argument.","Unnamed argument is the input text to be matched. Output is one of the candidates matching the input most closely."]},{"l":"Autocomplete","p":["Autocomplete is enabled both on the chat input, and the large Quick Reply editor.","Autocomplete works anywhere in your input. Even with multiple piped commands and nested closures.","Autocomplete supports three ways of looking up matching commands ( User Settings-> STscript Matching).","Starts with The \"old\" way. Only commands that begin exactly with the typed value will show up.","Includes All commands that include the type value will show up. Example: When entering /delete, the commands /qr-delete and /qr-set-delete will show up in the autocomplete list (/qr- delete, /qr-set- delete).","Fuzzy All commands that can be fuzzy-matched against the typed value will show up. Example: When entering /seas, the command /sendas will show up in the autocomplete list (/ se nd as).","Command arguments are supported by autocomplete as well. The list will show up for required arguments automatically. For optional arguments, press Ctrl+ Space to open the list of available options.","When entering /: to execute a closure or QR, autocomplete will show a list of scoped variables and QRs.","Autocomplete has limited support for macros (in slash commands). Type {{ to get a list of available macros.","Use the up and down arrow keys to select an option from the list of autocomplete options.","Press Enter or Tab or click on an option to place the option at the cursor.","Press Escape to close the autocomplete list.","Press Ctrl+ Space to open the autocomplete list or toggle the selected option's details."]},{"l":"Parser Flags","p":["The parser accepts flags to modify its behavior. These flags can be toggled on and off at any point in a script and all following input will be evaluated accordingly. You can set your default flags in user settings."]},{"l":"Strict Escaping","p":["Changes with STRICT_ESCAPING enabled are as follows."]},{"i":"pipes-1","l":"Pipes","p":["Pipes don't need to be escaped in quoted values."]},{"l":"Backslashes","p":["A backslash in front of a symbol can be escaped to provide the literal backslash followed by the functional symbol."]},{"l":"Replace Variable Macros","p":["This flag helps to avoid double-substitutions when the variable values contain text that could be interpreted as macros. The {{var::}} macros get substituted last and no further substitutions happen on the resulting text / variable value.","Replaces all {{getvar::}} and {{getglobalvar::}} macros with {{var::}}. Behind the scenes, the parser will insert a series of command executors before the command with the replaced macros:","call /let to save the current {{pipe}} to a scoped variable","call /getvar or /getglobalvar to get the variable used in the macro","call /let to save the retrieved variable to a scoped variable","call /return with the saved {{pipe}} value to restore the correct piped value for the next command"]},{"i":"quick-replies-script-library-and-auto-execution","l":"Quick Replies: script library and auto-execution","p":["Quick Replies is a built-in SillyTavern extension that provides an easy way to store and execute your scripts."]},{"l":"Configuring Quick Replies","p":["In order to get started, enable open the extensions panel (stacked blocks icon), and expand the Quick Replies menu.","Quick Reply","Quick Replies are disabled by default, you need to enable them first. Then you will see a bar appearing above your chat input bar.","You can set the displayed button text label (we recommend using emojis for brevity) and the script that will be executed when you click the button.","The number of buttons is controlled by the Number of slots settings (max = 100), adjust it according to your needs and click \"Apply\" when done.","Inject user input automatically recommended to be disabled when using STscript, otherwise it may interfere with your inputs, use the {{input}} macro to get the current value of the input bar in scripts instead.","Quick Reply presets allow to have multiple sets of predefined Quick Replies and switch between manually or by using the /qrset (name of set) command. Don't forget to click \"Update\" before switching to a different set to write your changes to the currently used preset!"]},{"l":"Manual execution","p":["Now you can add your first script to the library. Pick any free slot (or create one), type \"Click me\" into the left box to set the label, then paste this into the right box:","Then click 5 times on the button that appeared above the chat bar. Every click increments the variable clicks by one and displays a different message when the value equals 5 and resets the variable."]},{"l":"Automatic execution","p":["Open the modal menu by clicking the ⋮ button for the created command.","In this menu you can do the following:","Edit the script in a convenient full-screen editor","Hide the button from the chat bar, making it accessible only for auto-execution.","Enable automatic execution on one or more of the following conditions:","App startup","Sending a user message to the chat","Receiving an AI message in the chat","Opening a character or group chat","Triggering a reply from a group member","Activating a World Info entry using the same Automation ID","Provide a custom tool tip for the quick reply (text displayed when hovering over the quick reply in your UI)","Execute the script for test purposes","Commands are executed automatically only if the Quick Replies extension is enabled.","For example, you can display a message after sending five user messages by adding the following script and setting it to auto-execute on the user message."]},{"l":"Calling procedures","p":["A /run command can call scripts defined in the Quick Replies by their label, basically providing the ability to define procedures and return results from them. This allows to have reusable script blocks that other scripts could reference. The last result from the procedure's pipe is passed to the next command after it.","Let's create two Quick Replies:","Label:","GetRandom","Command:","GetMessage","Clicking on the GetMessage button will call the GetRandom procedure which will resolve the {{roll}} macro and pass the number to the caller, displaying it to the user.","Procedures do not accept named or unnamed arguments, but can reference the same variables as the caller.","Avoid recursion when calling procedures as it may produce the \"call stack exceeded\" error if handled unadvisedly."]},{"l":"Calling procedures from a different Quick Reply preset","p":["You can call a procedure from a different quick reply preset using the a.b syntax, where a = QR preset name and b = QR label name","By default, the system will first look for a quick reply label a.b, so if one of your labels is literally \"QRpreset1.QRlabel1\" it will try to run that. If no such label is found, it will search for a QR preset name \"QRpreset1\" with a QR labeled \"QRlabel1\"."]},{"l":"Quick Replies management commands"},{"l":"Create Quick Reply","p":["/qr-create (arguments, [message])– creates a new Quick Reply, example: /qr-create set=MyPreset label=MyButton /echo 123","Arguments:","label- string - text on the button, e.g., label=MyButton","set- string - name of the QR set, e.g., set=PresetName1","hidden- bool - whether the button should be hidden, e.g., hidden=true","startup- bool - auto execute on app startup, e.g., startup=true","user- bool - auto execute on user message, e.g., user=true","bot- bool - auto execute on AI message, e.g., bot=true","load- bool - auto execute on chat load, e.g., load=true","title- bool - title / tooltip to be shown on button, e.g., title=My Fancy Button"]},{"l":"Delete Quick Reply","p":["/qr-delete (set=string [label])– deletes Quick Reply"]},{"l":"Update Quick Reply","p":["/qr-update (arguments, [message])– updates Quick Reply, example: /qr-update set=MyPreset label=MyButton newlabel=MyRenamedButton /echo 123","Arguments:","newlabel- string - new text fort the button, e.g. newlabel=MyRenamedButton","label- string - text on the button, e.g., label=MyButton","set- string - name of the QR set, e.g., set=PresetName1","hidden- bool - whether the button should be hidden, e.g., hidden=true","startup- bool - auto execute on app startup, e.g., startup=true","user- bool - auto execute on user message, e.g., user=true","bot- bool - auto execute on AI message, e.g., bot=true","load- bool - auto execute on chat load, e.g., load=true","title- bool - title / tooltip to be shown on button, e.g., title=My Fancy Button"]},{"l":"Create or update QR preset","p":["/qr-presetupdate (arguments [label]) or /qr-presetadd (arguments [label])","Arguments:","enabled- bool - enable or disable the preset","nosend- bool - disable send / insert in user input (invalid for slash commands)","before- bool - place QR before user input","slots- int - number of slots","inject- bool - inject user input automatically (if disabled use {{input}})","Create a new preset (overrides existing ones), example: /qr-presetadd slots=3 MyNewPreset"]},{"l":"Add QR context menu","p":["/qr-contextadd (set=string label=string chain=bool [preset name])– add context menu preset to a QR, example: /qr-contextadd set=MyPreset label=MyButton chain=true MyOtherPreset"]},{"l":"Remove all context menus","p":["/qr-contextclear (set=string [label])– remove all context menu presets from a QR, example: /qr-contextclear set=MyPreset MyButton"]},{"l":"Remove one context menu","p":["/qr-contextdel (set=string label=string [preset name])– remove context menu preset from a QR, example: /qr-contextdel set=MyPreset label=MyButton MyOtherPreset"]},{"l":"Quick Reply value escaping","p":["|{} can be escaped with backslash in the QR message / command.","For example, use /qr-create label=MyButton /getvar myvar \\| /echo \\{\\{pipe\\}\\} to create a QR that calls /getvar myvar | /echo {{pipe}}."]},{"l":"Extension commands","p":["SillyTavern extensions (both built-in, downloadable and third-party) can add their own slash command. Below is just an example of the capabilities in the official extensions. The list may be incomplete, make sure to check /help slash for the most complete list of available commands.","/websearch (query)— searches snippets of the web pages online for the specified query and returns the result into the pipe. Provided by the Web Search extension.","/imagine (prompt)— generates an image using the provided prompt. Provided by the Image Generation extension.","/emote (sprite)— sets a sprite for the active character by fuzzy matching its name. Provided by the Character Expressions extension.","/costume (subfolder)— sets a sprite set override for the active character. Provided by the Character Expressions extension.","/music (name)— force changes a played background music file by its name. Provided by the Dynamic Audio extension.","/ambient (name)— force changes a played ambient sound file by its name. Provided by the Dynamic Audio extension.","/roll (dice formula)— adds a hidden message to the chat with the result of a dice roll. Provided by the D&D Dice extension."]},{"l":"UI interaction","p":["Scripts can also interact with SillyTavern's UI: navigate through the chats or change styling parameters."]},{"l":"Character navigation","p":["/random— opens a chat with the random character.","/go (name)— opens a chat with the character of the specified name. First, searches for the exact name match, then by a prefix, then by a substring."]},{"l":"UI styling","p":["/bubble— sets the message style to the \"bubble chat\" style.","/flat— sets the message style to the \"flat chat\" style.","/single— sets the message style to the \"single document\" style.","/movingui (name)— activates a MovingUI preset by name.","/resetui— resets the MovingUI panels state to their original positions.","/panels— toggles the UI panels visibility: top bar, left and right drawers.","/bg (name)— finds and sets a background using fuzzy names matching. Respect the chat background lock state.","/lockbg— locks the background image for the current chat.","/unlockbg— unlocks the background image for the current chat."]},{"l":"More examples"},{"i":"generate-chat-summary-by-ikaridevgit","l":"Generate chat summary (by @IkariDevGIT)"},{"l":"Buttons popup usage"},{"i":"get-nth-fibonaccis-number-using-binets-formula","l":"Get Nth Fibonacci's number (using Binet's formula)","p":["Hint: Set value of fib_no to the desired number"]},{"i":"recursive-factorial-using-closures","l":"Recursive Factorial (using closures)"}],[{"l":"Running Extras via Colab"},{"i":"extras-project-has-been-discontinued-since-april-2024-and-wont-receive-any-new-updates-or-modules-the-vast-majority-of-modules-are-available-natively-in-the-main-sillytavern-application-you-may-still-use-the-colab-notebook-but-dont-expect-to-get-immediate-support-if-you-face-any-issues","l":"Extras project has been discontinued since April 2024 and won't receive any new updates or modules. The vast majority of modules are available natively in the main SillyTavern application. You may still use the Colab notebook but don't expect to get immediate support if you face any issues.","p":["API key will appear in the colab's console output, for example: Your API key is fee2f3f559","Click \"Connect\"","Click the Start button on the left (looks like a triangle 'play' button)","Copy the API URL link that is listed under that line. ( DO NOT copy the 'localhost' URL, use the other one)","If you have enabled the secure option, paste the generated API key into the API Key box.","If you have NOT enabled the secure option, make sure the API Key box is completely empty when using the official colab.","Instructions to run the SillyTavern Extras Colab.","It will start with the text Running on","Look for the trycloudflare.com link at the bottom of the output. Ignore the localhost link, it won't work (we tried!).","Navigate to SillyTavern's Extensions menu (click the 'stacked blocks' icon at the top of the page).","Not required, but recommended: select the secure option to generate the API key to protect your shared instance.","Open the Official Extras Colab","Paste the API URL into the box at the top. ( NOT the API Key box)","Select the desired \"Extra\" options","select use_cpu to run Extras without requiring GPU credit","Start SillyTavern with extensions support: (set enableExtensions to true in your config.yaml if necessary)","this will make Stable Diffusion slower, but everything else will run normally","Wait for it to finish loading everything"]}],[{"l":"Extras Installation","p":["This page contains instructions for installing SillyTavern Extras on your local device."]},{"i":"extras-project-has-been-discontinued-since-april-2024-and-wont-receive-any-new-updates-or-modules-the-vast-majority-of-modules-are-available-natively-in-the-main-sillytavern-application-you-may-still-install-and-use-it-but-dont-expect-to-get-immediate-support-if-you-face-any-issues","l":"Extras project has been discontinued since April 2024 and won't receive any new updates or modules. The vast majority of modules are available natively in the main SillyTavern application. You may still install and use it but don't expect to get immediate support if you face any issues.","p":["Local installation of Extras can be difficult or impossible on your OS (especially Termux)."]},{"l":"Use the Official Extras Colab","p":["Simple to setup","Free to use","No Colab GPU credits required (use the use_cpu options)","See the Colab Guide Page for details."]},{"l":"Installation Methods"},{"i":"miniconda-recommended","l":"MiniConda (recommended)","p":["(Chads who installed SillyTavern with git to begin with can skip this step!)","(Important!) Read how to use Conda","Activate the new environment","After you have both of them installed...","cd SillyTavern-extras","Clone the Extras GitHub repo","conda activate extras(you should see (extras) pop up on the left side of your command prompt)","conda create -n extras","conda install python=3.11 git","Create a new Conda environment (let's call it extras):","git clone https://github.com/SillyTavern/SillyTavern-extras","Install Extras' requirements by using one of the following commands (will take time, again):","Install git","Install Miniconda","Install the required system packages (this will take some time)","Navigate to your cloned Extras repo","pip install -r requirements-coqui.txt- for Coqui TTS (not recommended)","pip install -r requirements-rvc.txt- for real-time voice cloning","pip install -r requirements.txt- for basic features","See below 'Running Extras After Install'","See the Common Problems page if you get errors at this step!","This method is recommended because Conda makes a 'virtual environment' for the Extras requirement packages to live inside, so they do not affect your system-wide Python setup.","Type/paste the commands below ONE BY ONE IN THE CONDA COMMAND PROMPT WINDOW and hit Enter after each one."]},{"l":"System-Wide Installation","p":["This is easier, but will affect your system-wide Python installation.","This can cause conflicts if you work with many Python programs that have different requirements.","If this is your first time touching anything Python-related, that should not be a problem.","Install Python 3.11: https://www.python.org/downloads/release/python-3115/","Install git: https://git-scm.com/downloads","Open a command prompt window and go to a folder in which you have complete access permissions.","Clone the repo: git clone https://github.com/SillyTavern/SillyTavern-extras, hit Enter.","After the clone has finished, type cd SillyTavern-extras, hit Enter.","Type python -m pip install -r requirements.txt","See below 'Running Extras After Install'"]},{"l":"Running Extras After Install"},{"l":"Confirm extensions are enabled","p":["Open the file called config.yaml in a text editor. The file is located in ST's base install folder.","Look for the line that reads enableExtensions.","Make sure that line has true, and not false."]},{"l":"Decide which module to use","p":["(This only needs to be done once)","Below is a table that describes each module.","caption","chromadb","classify","Coqui TTS","coqui-tts","Decide which modules you want to add to your Python command line.","Description","edge-tts","Example: python server.py --enable-modules=caption,summarize,classify","Extras is always started with a Python command line.","Image captioning","Microsoft Edge TTS client","Name","NOTE: There must be no spaces at all in your Python command's module list!","python server.py is the bare minimum, but it does not enable any useful modules.","Real-time voice cloning","rvc","sd","Silero TTS server","silero-tts","Stable Diffusion image generation","summarize","Text sentiment classification","Text summarization","They will be used in the next step.","This would enable Image Captioning, Chat Summary, and live updating Character Expressions.","to enable modules you must use the --enable-modules= modifier, with a comma-separated list of module names","Vector storage server"]},{"l":"Start Extras Server","p":["While still in your command prompt window inside the Extras installation folder...","Make sure your conda environment is active (if you used the Conda install method)","Type activate extras if the environment is not active.","Type python server.py --enable-modules=YOUR,SELECTED,MODULE,LIST,HERE","The extras server will load.","After a while it will show you a URL at the end. For local installs, this defaults to http://localhost:5100.","Copy the API URL."]},{"l":"Connect ST to the Extras server","p":["Start your SillyTavern server, and view the SillyTavern interface in your browser.","Open the Extensions panel (via the 'Stacked Blocks' icon at the top of the page)","Paste the API URL into the input box.","Click Connect.","To run Extras again, simply activate the environment and run these commands in a command prompt.","conda activate extras, Hit Enter. python server.py, Hit Enter.","Be sure to the additional options for server.py (see below) that your setup requires."]},{"l":"Make a .bat File for Easy Startup","p":["This is Optional and only applies to Windows, but something similar should be possible on MacOS.","View your Windows Desktop","Right-click, select New, and then click Text Document","A new file will appear on your Desktop, asking for a name.","Name the file STExtras.txt","Open the newly created file in a text editor.","Paste the following code into it:","Replace the placeholder folder path with your actual Extras install folder path.","Replace the python command line with your actual command line","Save the file with a new name STExtras.bat(Use File>> Save As in most text editors)","You can now simply double-click on this .bat file to easily start Extras.","If you ever want to change the module list (or any other command line modifiers for the extras server), simply edit the python command inside the .bat file."]}],[{"l":"Extras Install Common Problems","p":["This page lists common questions and problems encountered while installing SillyTavern Extras.","Local installation of Extras can be difficult or impossible on your OS (especially Termux)."]},{"l":"Use the Official Extras Colab","p":["Simple to setup","Free to use","No Colab GPU credits required (use the use_cpu options)","See the Colab Guide Page for details."]},{"i":"error-could-not-import-the-talkinghead-module-on-linux","l":"Error: Could not import the 'talkinghead' module on Linux","p":["It requires the installation of an additional package because it's not installed automatically due to incompatibility with Colab. Run this after you install other requirements:","pip install wxpython"]},{"i":"extras-server-cant-connect-to-automatic1111s-stable-diffusion-web-ui","l":"Extras server can't connect to AUTOMATIC1111's Stable Diffusion Web UI","p":["Could not connect to remote SD backend at http://127.0.0.1:7860! Disabling SD module...","Make sure webui-user.bat that you start Stable Diffusion with contains --api command line option in the COMMANDLINE_ARGS variable.","Find and replace that line in your \"webui-user.bat\": set COMMANDLINE_ARGS=--api","How it shoud look","If the API mode is disabled for SD Web UI, the Extras server won't be able to make a connection and you won't be able to generate images!"]},{"i":"still-doesnt-work","l":"Still doesn't work?","p":["Ensure that you start everything in the proper order, waiting for every program to finish loading before proceeding to the next step:","Stable Diffusion Web UI","SillyTavern Extras","SillyTavern","The extras server can't reconnect to the Stable Diffusion API if it was loaded after."]},{"l":"hnswlib wheel building error when installing ChromaDB","p":["ERROR: Could not build wheels for hnswlib, which is required to install pyproject.toml-based projects","Before installing the ChromaDB module you must first do one of the following:","Install Visual C++ build tools: https://visualstudio.microsoft.com/visual-cpp-build-tools/","Install the hnswlib package with conda: conda install -c conda-forge hnswlib"]},{"l":"Error when installing Python requirements on Mac","p":["ERROR: No matching distribution found for torch== 2.0.0+cu117","Mac does not support CUDA, so torch packages should be installed without CUDA support.","Install the requirements using the requirements-silicon.txt file instead."]},{"i":"missing-modules","l":"Missing modules?","p":["You must specify a list of module names in your Python command line, with the --enable-modules modifier.","See Modules section."]},{"i":"what-is-the-api-key-box-for","l":"What is the API Key box for?","p":["The API Key box in SillyTavern's Extensions panel is only used when you have:","created a text file named api_key.txt in your Extras install folder, which contains your chosen Extras 'password'.","started extras with the --secure commandline argument.","This makes the Extras API 'password locked', so only users who have that key in their API Key box can access it.","This is mainly useful for people who want to make their own public deployment of Extras (colab, etc).","Users running Extras on their own PC for personal use should not type anything into the API Key box."]},{"i":"what-about-mobile-android-termux","l":"What about mobile/Android/Termux? \uD83E\uDD14","p":["There are some folks in the community having success running Extras on their phones via Ubuntu on Termux.","However, Extras were not made with mobile support in mind.","No support will be provided for people running Extras on their Android devices.","Direct all your questions to the creator of the guide linked below instead."]},{"i":"this-is-unsupported","l":"❗ This is UNSUPPORTED","p":["https://rentry.org/STAI-Termux#downloading-and-running-tai-extras"]}],[{"l":"Server Plugins","p":["These plugins allow adding functionality that is impossible to achieve using UI extensions alone, such as creating new API endpoints or using Node.JS packages that are unavailable in a browser environment.","Plugins are contained in the plugins directory of SillyTavern and loaded on server startup, but only if enableServerPlugins is set to true in the config.yaml file.","Plugins are not sandboxed, be careful what you install and run!"]},{"l":"Types of plugins"},{"l":"Files","p":["An executable JavaScript file with \".js\" (for CommonJS modules) or \".mjs\" (for ES modules) extension containing a module that exports an init function that accepts an Express router (created specifically for your plugin) as an argument and returns a Promise.","The module should also export an info object containing the information about the plugin ( id, name, and description strings). This will provide the information about the plugin to the loader.","You can register routes via the router that will be registered under the /api/plugins/{id}/{route} path. For example router.get('/foo') for plugin example will produce a route like this: /api/plugins/example/foo.","A plugin could also optionally export an exit function that performs clean-up on shutting down the server. It should have no arguments and must return a Promise.","TypeScript contract for plugin exports:","See below for a \"Hello world!\" plugin example:"]},{"l":"Directories","p":["You can load a plugin from a subdirectory in the plugins in one of the following ways (in the order of checks):","package.json file that contains a path to an executable file in the \"main\" field.","index.js file for CommonJS modules.","index.mjs file for ES modules.","A resulting file must export an init function and info object with the same requirements as for individual files.","Example of a directory plugin (with index.js file): https://github.com/SillyTavern/SillyTavern-DiscordRichPresence-Server"]},{"l":"Bundling","p":["It is preferable to use a bundler (such as Webpack or Browserify) that will package all of the requirements into one file. Make sure to set \"Node\" as a build target.","Template repository for plugins using Webpack and TypeScript: https://github.com/SillyTavern/Plugin-WebpackTemplate"]}],[{"l":"UI Extensions","p":["UI extensions expand the functionality of SillyTavern by hooking into its events and API. You can easily create your own extensions.","Want to contribute your extensions to the official repository? Contact us!"]},{"l":"Examples","p":["See live examples of simple SillyTavern extensions:","https://github.com/city-unit/st-extension-example- basic extension template. Showcases manifest creation, local script imports, adding a settings UI panel, and persistent extension settings usage."]},{"l":"Bundling","p":["Extensions can also utilize bundling to isolate themselves from the rest of the modules and use any dependencies from NPM, including UI frameworks like Vue, React, etc.","https://github.com/SillyTavern/Extension-ReactTemplate- template repository of a barebone extension using React and Webpack.","To use relative imports from the bundle, you may need to create an import wrapper. Here's an example for Webpack:"]},{"i":"manifestjson","l":"manifest.json","p":["Every extension must have a folder in data/user-handle/extensions and have a manifest.json file which contains metadata about the plugin and a JS script file.","display_name is required. Displays in the \"Manage Extensions\" menu.","loading_order is optional. Higher number loads later.","requires specifies the required Extras modules dependencies. An extension won't be loaded unless the connected Extras API provides all of them.","optional specifies the optional Extras dependencies.","js is the main JS file reference, and is required.","css is an optional style file reference.","author is required. It should contain the name or contact info of the author(s).","auto_update is set to true if the extension should auto-update when the version of the ST package changes.","Downloadable extensions are mounted into the /scripts/extensions/third-party folder, so relative imports should be used based on that. Be careful about where you create your extension during development if you plan on installing it from your GitHub which overwrites the content in the third-party folder."]},{"l":"requires vs optional","p":["requires- extension could be installed, but will not be loaded until the user connects to the Extras API that provides all of the specified modules.","optional- extension could be installed and will always be loaded, but any of the missing Extras API modules will be highlighted in the \"Manage extensions\" menu.","To check which modules are currently provided by the connected Extras API, import the modules array from scripts/extensions.js."]},{"l":"Using getContext","p":["The getContext() function gives you access to the SillyTavern context:","Use this to interact with the main app state.","You can also use a globally defined window object: SillyTavern.getContext()."]},{"l":"Importing from other files","p":["Unless you're building a bundled extension, you can import variables and functions from other JS files.","For example, this code snipped will generate a reply from the currently selected API in the background:"]},{"l":"Important note","p":["Using imports from SillyTavern code is unreliable and can break at any time if the internal structure of ST's modules changes. getContext provides a more stable API.","If you're missing any of the functions/properties in getContext, please get in touch with the developers or send us a Pull Request!"]},{"i":"registering-slash-commands-new-way","l":"Registering slash commands (new way)","p":["While registerSlashCommand still exists for backward compatibility, new slash commands should now be registered through SlashCommandParser.addCommandObject() to provide extended details about the command and its parameters to the parser (and in turn to autocomplete and the command help)."]},{"i":"registering-slash-commands-old-way","l":"Registering slash commands (old way)","p":["Use registerSlashCommand() to register a new slash command:","Example of command execution:","Arguments explanation:","command- the main command name. It will be used in autocompletion and help commands.","callback- a function that will be executed when the command is triggered. A callback function can accept two arguments:","namedArgs- an object with named arguments","unnamedArgs- a string containing the unnamed argument","aliases- an array of alias strings. The command can be called using any of the aliases, but they won't be shown in the autocomplete but will be listed in the help command.","helpString- a string that will be displayed when the /help slash command is called. Must describe what your command does and which arguments it accepts. May contain HTML markup.","interruptsGeneration- if the command is executed from the user input area, the message generation will be interrupted. Default: false.","purgeFromMessage- if the command is executed from the user input area, it will be purged from the input text area when the command finishes executing. Default: true.","All registered commands can be used in STscript in any possible way.","In rare circumstances, the unnamed command argument can also receive a number so be sure to type check or convert if you expect a concrete type!"]},{"l":"Listening to event types","p":["Use eventSource.on() to listen for events:","The main event types are:","MESSAGE_RECEIVED","MESSAGE_SENT","CHAT_CHANGED","The rest can be found here."]},{"l":"Do Extras request","p":["The doExtrasFetch() function allows you to make requests to your SillyTavern Extra server.","For example, to call the /api/summarize endpoint:","getApiUrl() returns the base URL of the Extras serve.","The doExtrasFetch() function:","Adds the Authorization and Bypass-Tunnel-Reminder headers","Handles fetching the result","Returns the result (the response object)","This makes it easy to call your Extra's API from your plugin.","You can specify:","The request method: GET, POST, etc.","Additional headers","The body for POST requests","And any other fetch options"]}],[{"l":"AllTalk TTS","p":["AllTalk is voice cloning system based on the Coqui XTTS models, requiring only a good quality wav audio file to attempt to reproduce the original speaker. It also offers finetuning options to improve the reproduction quality of the voice where needed.","To look over the full feature set, please visit this link and Screenshot here","Along with the standard SillyTavern text splitting options to choose what is or isnt spoken, AllTalk offers and additional option to use the AllTalk narrator, so that non-character text can be read out in an alternative voice example","Documentation and custom settings are built into AllTalk and available on a link within the SillyTaven TTS interface."]},{"i":"setup","l":"\uD83D\uDFE9 Setup","p":["Any time you need to make changes to AllTalk, or use Finetuning etc, always start the Text-generation-webui Python environment first.","Click to expand one of the below:","DeepSpeed on Windows machines will be installed as standard. Linux machines have other requirements which are detailed within the setup utility and on this page.","Finetuning & DeepSpeed have other installation requirements (depending on your OS) so please read any instructions in the setup utility and refer to the AllTalk Github page for detailed instructions.","Finetuning has other installation requirements so please read any instructions in the setup utility and refer to the AllTalk Github page for detailed instructions.","Follow the on-screen prompts and install the correct requirements files that you need. It's recommended to test AllTalk works before installing DeepSpeed.","Go to a terminal/console, move into the \\text-generation-webui\\extensions\\ folder and git clone https://github.com/erew123/alltalk_tts","Go to a terminal/console, move into the folder of your choice e.g C:\\myfiles\\ folder and git clone https://github.com/erew123/alltalk_tts","If you wish to see this as a video, please go here","In a terminal/command prompt, in the text-generation-webui folder you will start its Python environment with either cmd_windows.bat or ./cmd_linux.sh","In a terminal/command prompt, move into the AllTalk folder e.g. cd alltalk_tts","Move into the AllTalk folder e.g. cd extensions then cd alltalk_tts","NOTE You will need to uncheck\"Enable TTS\" within the Text-generation-webui interface, otherwise when you are using SillyTavern, AllTalk will dual generate TTS due to how Text-generation-webui sends messages. It is possible to set this as start-up setting within the AllTalk settings page.","On the AllTalk page select CODE> Download ZIP then extract it to the folder of your choice e.g. C:\\myfiles\\alltalk_tts\\","On the AllTalk page select CODE> Download ZIP then extract it to the text-generation-webui extensions folder e.g. \\text-generation-webui\\extensions\\alltalk_tts\\","Please read the \uD83D\uDFE9 Other installation notes(also additional voices are available there).","Start the AllTalk setup script atsetup.bat or ./atsetup.sh","To download the AllTalk setup you can either:","When the AllTalk server has started its default settings and documentation page will be on http://127.0.0.1:7851/","You have 2x current options for installation. If you are using Text-generation-webui as your LLM model loader, you can add AllTalk as an extension there. If you wish to use AllTalk as a standalone, you can do that too. For all the latest documentation, support and help please visit here. Below are two quick installation methods (with videos) however please look at the AllTalk website if you need manual installation methods."]},{"i":"other-installation-notes","l":"\uD83D\uDFE9 Other installation notes","p":["On first startup, AllTalk will download the Coqui XTTSv2 2.0.2 model to its models folder (1.8GB space required). Check the command prompt/terminal window if you want to know what its doing. After it says \"Model Loaded\" AllTalk is usually available on its IP address a few seconds later, for you to connect to in your browser.","Once the extension is loaded, please find all documentation and settings on http://127.0.0.1:7851/","Where to find voices https://aiartes.com/voiceai or https://commons.wikimedia.org/ or interviews on youtube etc. Instructions on how to cut down and prepare a voice sample are within the built in documentation.","Please read the note about ensuring your character cards are set up correctly.","Some extra voices for AllTalk are downloadable here"]},{"i":"a-note-on-character-cards-greeting-messages","l":"\uD83D\uDFE9 A note on Character Cards & Greeting Messages","p":["Messages intended for the Narrator should be enclosed in asterisks * and those for the character inside quotation marks . However, AI systems often deviate from these rules, resulting in text that is neither in quotes nor asterisks. Sometimes, text may appear with only a single asterisk, and AI models may vary their formatting mid-conversation. For example, they might use asterisks initially and then switch to unmarked text. A properly formatted line should look like this:","Hey! I'm so excited to finally meet you. I've heard so many great things about you and I'm eager to pick your brain about computers.* She walked across the room and picked up her cup of coffee*","Most narrator/character systems switch voices upon encountering an asterisk or quotation marks, which is somewhat effective. AllTalk has undergone several revisions in its sentence splitting and identification methods. While some irregularities and AI deviations in message formatting are inevitable, any line beginning or ending with an asterisk should now be recognized as Narrator dialogue. Lines enclosed in double quotes are identified as Character dialogue. For any other text, you can choose how AllTalk handles it: whether it should be interpreted as Character or Narrator dialogue (most AI systems tend to lean more towards one format when generating text not enclosed in quotes or asterisks).","You can monitor what AllTalk identifies as Narrator lines on the terminal/command prompt and adjust its behavior if needed (Text Not Inside - Function)."]},{"i":"using-alltalk-within-sillytavern-understanding-the-settings","l":"\uD83D\uDFE8 Using AllTalk within SillyTavern & understanding the settings","p":["When you have AllTalk loaded, within SillyTavern on the TTS page, select AllTalk and at the bottom is a link \"AllTalk Config & Docs\". Click that link and it will take you to your AllTalk server where you can find explanations of the settings.","Some settings cannot be used at the same time, so AllTalk will enable/disable certain settings as needed.","If SillyTavern is loaded before AllTalk is available, you may need to click the Reload button on SillyTavern's TTS extensions page.","A few quick tip on using AllTalk within SillyTavern:","Only change DeepSpeed, Low VRAM or Model one at a time. Wait for it to say Ready before changing something else.","You can permanently change the AllTalk startup settings or DeepSpeed, Low VRAM and Model in the AllTalk settings page.","Different AI models use quotes and asterisks differently, so when using the AllTalk narrator, you may need to change \"Text not inside\" depending on model.","Add new voice samples to the voices folder. You can Finetune a model to make it sound even closer to the original sample.","DeepSpeed will improve processing time to TTS to be 2-3x faster (Installed as default on Stanalone installations, but needs activating)","Low VRAM can be very beneficial if you don't have much memory left after loading your LLM."]},{"i":"support-help-assistance-other-questions","l":"\uD83D\uDFE8 Support, Help, Assistance & other questions","p":["Please visit here"]}],[{"l":"Blip","p":["This guide will walk you through setting up and customizing blip extension for your SillyTavern experience. This extension animate the text of messages with variable speed and play sound along the animation. You can use audio file or generate the sound."]},{"l":"Prerequisites","p":["Before you begin, ensure you've met the following prerequisites:","Make sure you're on the latest staging branch of SillyTavern.","Install the \"Blip\" extension from the \"Download Extensions & Assets\" menu in the Extensions panel (stacked blocks icon)."]},{"l":"Blip global settings","p":["Blip user message:","Enable checkbox to play animation on user message.","Set a profile for the user or a default profile if you want blip animation for user.","Blip only for certain text:","Enable checkbox to only blip for text inside quotes.","Enable checkbox to ignore everything inside asterisks.","Automatic scroll down:","Enable checkbox to make the chat go down to follow the text animation, disable it if you wanna scroll freely during animation.","Audio volume","Mute the audio if just the animation of the text is desired.","You can adjust the global volume of blip audio."]},{"i":"character-animationvoice-profile","l":"Character animation/voice profile","p":["Any profile can be deleted using the remove button.","Audio parameters:","Blip origin: file:","Blip origin: Generated sound:","Choose a file in the list.","Enable the checkbox to force to wait entire file is played before playing again if needed.","If it does not have a profile yet the current parameters will become his profile settings.","If min/max are different a random sound in this range is played each time.","If only the current chat characters are shown in the list, click the checkbox to show all your characters.","including the user and an optional default profile that will be used when character have no profile.","Or put file directly into: \\SillyTavern\\data\\user-handle\\assets\\blip.","Select a character, if he have a profile it will be loaded.","Select the character to assign/update profile:","Set a volume multiplier that will only affect this voice profile if needed.","Set audio speed: the delay between each blip sound, independant of text speed.","Set comma/phrase delay superior to 0 to add a pause when special character are printed, can add more liveliness to animation. Audio is paused too in this case.","Set Min/max speed multiplier different to 1.0 for randomness of speed animation.","Set the text speed: the delay in milliseconds between each letter printed.","Text animation settings:","Use refresh button if your character does not appear in the list.","Use the min/max frequency slider to customize the blip sound played.","You can get official ST blip assets from the assets extension menu.","You can save a profile for each character:"]},{"l":"Remarks","p":["Blip animation can only start when full message is received, don't use streaming mode.","Thank you for following this guide! Your SillyTavern experience is now enriched with text animation and blip voices."]}],[{"l":"Dynamic Audio","p":["This guide will walk you through setting up and customizing dynamic audio assets for your SillyTavern experience."]},{"l":"Prerequisites","p":["Before you begin, ensure you've met the following prerequisites:","Make sure you're on the latest staging branch of SillyTavern.","Install the \"Dynamic Audio\" extension from the \"Download Extensions & Assets\" menu in the Extensions panel (stacked blocks icon)."]},{"i":"dynamic-audio-setup-browser","l":"Dynamic Audio Setup (Browser)","p":["Connect to the Assets Repository:","Launch SillyTavern and navigate to Extensions> Assets.","Click on the \"Connect\" button to establish a connection to the official assets repository.","Download the desired audio assets, such as background music (BGM) or ambient sounds, that correspond to the backgrounds you intend to use.","Enable Dynamic Audio Extension:","In SillyTavern, go to Extensions> Dynamic Audio.","Enable the extension, unmute and adjust the volume of BGM and ambient sounds to your preference.","When bgm end another one will play randomly, click on loop button to keep current bgm playing","Click on roll button to pick another bgm randomly","Expression based BGM:","Enable expression BGM switch if you want bgm to follow character expression (require bgm in character folder see below).","Adjust the cooldown timer (in seconds) between BGM updates. Increase it if you find the BGM changes too frequently in group chats or when using character-specific BGM with emotion detection."]},{"l":"Importing Music for Characters","p":["To set up custom music for your characters' emotions, follow these steps:","Navigate to Character Folder:","Go to the characters folder, e.g., \\SillyTavern\\data\\user-handle\\characters\\Seraphina.","Create BGM Folder:","Inside the character folder, create a subfolder named bgm.","Import Emotion Music:","Within the bgm folder, import the music files for each emotion. Supported audio extensions include .mp3, .ogg, and .wav.","Naming convention: [emotion]_[number].mp3, e.g., anger_0.mp3, joy_0.mp3.","Multiple Tracks for Emotions:","You can import multiple tracks for the same emotion by incrementing the number, e.g., neutral_1.mp3, neutral_2.mp3.","Default Music Selection:","When no emotion is detected, a random neutral track will play as the default. Emotions are detected similarly to updating sprites; refer to the expression images documentation for details."]},{"l":"Changing Default BGM Music","p":["If a character doesn't have custom BGM in their folder, a default track will play. Here's how you can change it:","Navigate to BGM Folder:","Go to the following folder: \\SillyTavern\\data\\user-handle\\assets\\bgm.","Replace/Add Music:","Replace or add music files (.mp3, .ogg, .wav) to this folder.","These are the official audio assets downloaded using the assets extension.","One of these tracks will play randomly when no character-specific BGM is found (solo or group chat)."]},{"l":"Changing Ambient Sounds","p":["Ambient sounds add depth to your scenes. Here's how you can customize them:","Navigate to Ambient Folder:","Go to the following folder: \\SillyTavern\\data\\user-handle\\assets\\ambient.","File Naming Convention:","Ambient audio filenames correspond to background image filenames, replacing spaces with dashes.","Example: bedroom-clean.mp3 corresponds to the \"bedroom clean.jpg\" background.","If the lock button is unlock the audio file corresponding to the background will play. Activating lock will keep current ambient playing.","Custom Ambients:","You can add your own ambient sounds for custom or existing backgrounds by following the same naming pattern.","Thank you for following this guide! Your SillyTavern experience is now enriched with dynamic audio."]}],[{"l":"EmulatorJS","p":["This extension allows you to play retro console games right from the SillyTavern chat."]},{"l":"Installation","p":["Prerequisites:","Latest release version of SillyTavern.","ROM files downloaded from the net. You can find them anywhere.","How to install:","Install using SillyTavern's extensions downloader.","Or use this link: https://github.com/SillyTavern/SillyTavern-EmulatorJS"]},{"l":"Usage","p":["Open the \"EmulatorJS\" extension menu.","Click \"Add ROM file\". ROMs are saved to your browser storage and not stored on a server.","Select the game file to add. Input the name and core (if it wasn't auto-detected). If the core requires a BIOS file, add it too.","Click the \"Play\" button in the list or launch via the wand menu.","You can customize controls and other settings in the emulator frame after launching the game.","Use save/load state functions if you need to take a break.","Check the EmulatorJS docs to see the list of available cores and their requirements: Systems."]},{"l":"Comments mode","p":["With the power of multimodal models such as GPT-4 Vision, your AI bots can see your gameplay and provide witty in-character comments."]},{"l":"Requirements","p":["A browser that supports ImageCapture. Tested on desktop Chrome. Firefox requires to enable it with config. Safari won't work.","Image inlining mode is recommended. Requires OpenAI or OpenRouter API key with \"gpt-4-vision\" as the selected model; Google MakerSuite with Gemini Vision model; or Anthropic Claude 3 (Opus model recommended).","If image inlining is disabled, make sure that the \"Image Captioning\" extension is enabled, then select the \"Multimodal\" captioning source:","OpenAI API with access to the \"gpt-4-vision\" model.","OpenRouter API with compatible multimodal model.","Locally hosted Llava model in Koboldcpp or oobabooga TextGen WebUI."]},{"l":"How to enable comments","p":["Make sure you set the interval of providing comments in the EmulatorJS extension settings. This setting defines how often the character is queried for comments using a snap of your current gameplay. A value of 0 indicates that no comments are provided.","Select a character chat and launch the game. For the best performance, make sure that the ROM file is properly named so that AI can have more background context.","Start playing as you normally would. The vision model will be queried periodically to write a comment based on the latest screenshot it \"sees\"."]},{"l":"Settings","p":["Caption template - a prompt used to describe the in-game screenshot. {{game}} and {{core}} additional macro are supported.","Comment template - a prompt used to write a comment based on the generated caption. {{game}}, {{core}}, {{caption}} additional macro are supported. For image inlining mode, {{caption}} is replaced with see included image.","Force captions - will force the use of multimodal captioning even if image inlining is supported and enabled."]},{"i":"why-im-not-seeing-any-comments","l":"Why I'm not seeing any comments?","p":["Comments are temporarily paused (interval step skipped) if:","Emulator is paused (with a pause button, not in-game).","The browser window is out of focus.","The user input area is not empty. This is to let you type your reply in peace.","Another reply generation is currently in progress.","TTS voice is being read aloud. Comment is held off (20 seconds maximum) until it finishes, but not skipped.","Other common issues:","Make sure you've set a commenting interval before launching the game.","Make sure you have set a multimodal API key and there are no errors in the ST server console.","Still doesn't work? Send us your browser debug console logs (press F12)."]},{"l":"Credits","p":["EmulatorJS engine (GPLv3): https://github.com/EmulatorJS/EmulatorJS"]}],[{"l":"Expression Images"},{"i":"what-is-it","l":"What is it?","p":["Expression images are images (aka 'sprites') of your AI character which are shown next to (or behind) the chat window.","Expression images can use a classification model running alongside SillyTavern's main application. This allows the Expressions to change automatically based on the sentiment expressed in the AI's most recent chat response."]},{"i":"setup-instructions-offline-mode-without-extras","l":"Setup Instructions (Offline Mode without Extras)","p":["Open the Extensions Panel and expand the 'Expression images' section. If you have the character chat open, you will see a grid of image placeholders. Expression Drawer","Click the 'import' button at the top left of each image in the grid, and select the image you want to apply to that emotion. This will save the image with the correct filename inside the /data/user-handle/characters/(character_name_here)/ folder.","To show the image in your SillyTavern window, click the image in the grid after it has been uploaded."]},{"i":"how-does-the-classify-module-work","l":"How does the classify module work?","p":["The classify module uses a small 'sentiment parsing' model that runs on the SillyTavern host machine (eg. on your PC, or the colab machine). This model takes the new output from the AI and detects what kind of sentiment, or emotion, the text is expressing. While multiple sentiments may be expressed in a single message, the model only picks the most likely one and returns that to the SillyTavern. The frontend plugin then displays the image that is associated with that sentiment."]},{"l":"Change Expressions Manually","p":["Click on any of the uploaded expression images (sprites) to display them near the chat interface (with default UI mode) or at the center of the screen (in Visual Novel mode).","Use the /emote (name) slash command or matching Quick Reply to set the sprite without opening the extensions menu."]},{"i":"setup-instructions-local-classification","l":"Setup Instructions (local classification)","p":["Make sure you're on the latest release or staging version of SillyTavern.","Open the extensions panel and expand the \"Character Expressions\" plugin menu.","Select \"Local\" in the classification source dropdown.","This will start a one-time download of the classification model from HuggingFace Hub (about ~ 100 Mb).","Generate any message to verify that the classification works and the sprite appears. You may also check the server console for debug logs."]},{"i":"setup-instructions-with-extras","l":"Setup Instructions (with Extras)","p":["Have Extras installed and running with the classify module enabled: python server.py --enable-modules=classify","Import the expression images the same way as mentioned above.","Select \"Extras\" in the classification source dropdown.","The appropriate expression image will display automatically whenever the AI sends you a response."]},{"i":"setup-instructions-with-llm","l":"Setup Instructions (with LLM)","p":["Connect to any of the supported and properly configured Text Generation APIs.","Import the expression images the same way as mentioned above.","Select \"LLM\" in the classification source dropdown.","Optionally, configure the classification instruction prompt.","Generate any message to verify that the classification works and the sprite appears. You may also check the server console for debug logs."]},{"i":"how-do-i-get-more-expression-options","l":"How do I get more expression options?"},{"l":"Local","p":["Local classification defaults to 28 possible image labels: Cohee/distilbert-base-uncased-go-emotions-onnx","To use the 6-option classification model, open the config.yaml file with a text editor and change the value of the classificationModel variable to Cohee/bert-base-uncased-emotion-onnx","After that, restart the ST server to redownload the model. To revert it, change the value in config.yaml again."]},{"l":"Extras API","p":["Extras API uses a classification model with 6 options by default: nateraw/bert-base-uncased-emotion","There is also a model with 28 options: joeddav/distilbert-base-uncased-go-emotions-student","To use this model you need to change your Extras command line to include the following argument (with a space before and after):","--classification-model=joeddav/distilbert-base-uncased-go-emotions-student"]},{"i":"what-image-formats-are-supported-for-expressions","l":"What image formats are supported for Expressions?","p":["Any image format is allowed, including webp and animated gifs.","The most common format is a PNG file with a transparent background."]},{"i":"using-the-default-expressions","l":"Using the 'default expressions'","p":["(This feature will only activate if local classification is enabled or with Extras API connected. There is no way to manually display default expression images.)","Use Default Expressions","If you don't have custom expression images for a character, you can use the built-in default expressions which are included with the base SillyTavern installation. These are simple emoji-style images. Just click the checkbox at the top of the Expression images section inside the Extension panel. Default expressions will work alongside any available custom Expressions, and will display in cases when your custom image set has any missing images for a particular emotion."]},{"l":"Importing an Expression images zip file","p":["Using the 'import ZIP' button, you can import a zip file that contains a collection of expression images, and those images will automatically be added to the correct folder for your currently selected character. The zip file must have a flat internal structure (no subfolders) and the individual images should be named correctly. Importing a zip will not automatically rename any images to make them match the emotions."]},{"l":"Limitations"},{"i":"display-names-not-character-card-filenames-dictate-which-image-set-is-used","l":"Display names (not character card filenames) dictate which image set is used","p":["If you have more than one character with the same display name, they will both use the same set of expression images.","If you want a different image set to be used for each version of the same-named character, you can use the sprites folder override."]},{"l":"How to set an override","p":["Create a folder in the /data/user-handle/characters with any name and put images there, e.g. /data/user-handle/characters/Boris.","Open the chat with the character whose sprites you'd like to override.","Enter the name of the override folder into the \"Sprite Folder Override\" input and click \"Submit\".","The Sprites list will reload and the \"Sprite set\" indicator should show the override folder.","Alternatively, you can use the /costume slash command to achieve the same result: /costume Boris.","By prepending a backslash to the override folder name, it will resolve to a subfolder in the current character sprites folder, e.g. /costume \\tracksuit for the character named Boris will resolve to the /data/user-handle/characters/Boris/tracksuit folder."]},{"l":"Custom expressions","p":["You can add your custom expression labels to the list and upload sprites for them.","However, they won't be labeled automatically by the classification model. You need to set them manually (either by clicking or the /emote command)."]}],[{"l":"Live2D","p":["This guide will walk you through the process of setting up and customizing the Live2D extension for your SillyTavern experience. This extension allows you to use Live2D animated models for your character, providing a dynamic and interactive element to your virtual character."]},{"l":"Prerequisites","p":["Before you begin, ensure you've met the following prerequisites:","Branch Selection: Make sure you're using the latest staging branch of SillyTavern to access the latest features and updates.","Extension Installation: Install the \"Live2D\" extension from the \"Download Extensions & Assets\" menu in the Extensions panel (represented by the stacked blocks icon).","Model Folder Placement: Place your Live2D model folders into the /data/user-handle/assets/live2d directory. A properly organized live2d assets folder might look like this:","Asset folder example","A Live2D model folder should include all necessary components for the Live2D model, such as expressions, motions, textures, sounds, and settings files. Notably the ***.model.json file must be at the root of the Live2D model folder for the model to be detected by the extension. In this example the shizuku live2d model folder may look like this:","Live2d model folder example","Note: Models can also be placed in character-specific folders, such as /data/user-handle/characters/Shizuku/live2d/. However, models in character folders will only be accessible for that specific character."]},{"l":"Extension Settings","p":["The Live2D extension offers various settings to customize the behavior of your animated model. Here are the key settings:","UI global settings"]},{"l":"Global Settings","p":["Enabled:","Enable this checkbox to activate the extension, allowing your Live2D model to interact within SillyTavern.","You can disable the extension if you want to use normal sprites only.","You can disable the extension when you want to move normal sprites in a group chat and enable it again when you're ready to use Live2D models.","Follow Cursor:","Enable this checkbox to make the Live2D model follow your cursor, provided that the model supports this feature.","Auto-send Interaction:","Enable this checkbox to automatically trigger character interactions when you click on areas with mapped messages (refer to the hit areas section for details)."]},{"l":"Debug Settings","p":["These settings help you control the behavior and visibility of your Live2D model for debugging purposes.","Reset Model Before Animation:","Enable this checkbox to reload the model before any animation. This forces the animation to start and allows you to spam clicks if necessary. Some models may require this to ensure that animations begin from a compatible state.","Show Model Frames:","Enable this checkbox to display the model frame, making it easier to identify where to click to drag the model around. It also shows the hit area, if available. Hovering over a hit area will show its name.","Reload button","Click this button to reload every live2d model. Use it in case something glitches."]},{"l":"Character Selection","p":["These settings allow you to manage characters and assign Live2D models to them.","Refresh Button:","Click the refresh button to update the list of characters in the current chat.","Select Character:","Use the drop-down list to choose a character to assign a Live2D model to.","Remove Button:","Click this button to delete all assigned models for a character. A confirmation prompt will appear to confirm the deletion."]},{"l":"Model Selection","p":["UI model list","Refresh Button:","Click the refresh button if your Live2D model does not appear in the list.","Select Model:","Choose a model from the list to assign it to the selected character.","The model can be located in the asset folder or the current character's folder.","The list displays the model folder name, its origin (asset or character), and the name of the detected model setting file.","Note that some model folders may contain different versions of the same model. You can try different model files to see which one works best.","Selecting none will use normal sprites if there is any","Settings are saved per character and model"]},{"l":"Model Settings","p":["UI model settings","Model Scale:","Use the slider to adjust the size of the model, making it larger or smaller.","Model Center X Offset:","Use the slider to change the horizontal position of the model relative to the window center.","Model Center Y Offset:","Use the slider to adjust the vertical position of the model relative to the window center."]},{"l":"Remarks","p":["The settings are saved and carry over different chats.","You can also drag the model with your mouse, and those settings will be updated and saved.","Use these UI settings to bring your model back on the screen if you somehow made it out of view. Also, check the \"Show frame\" checkbox to see clearly where you can click to drag the model."]},{"l":"Model Talk","p":["UI model talk","Param mouth open Y id","Select from the list the ID of the parameter corresponding to the model's mouth Y value. Not all models have one, and names may vary from model to model. Usually something like \"PARAM_MOUTH_OPEN_Y\" or \"ParamMouthOpenY\". Check the model when selecting an element from the list; it will try to run the speak animation. If the mouth moves, you got it!","Mouth movement speed","Adjust the slider to change the movement speed of the mouth animation.","Time per character","Set the time duration of each character. The duration of the talk animation will be this time multiplied by the number of characters of the message."]},{"i":"remarks-1","l":"Remarks","p":["This mouth animation does not work on every model and every animation. Even if your model has animations where the mouth moves, it does not mean the mouth animation can be controlled by this extension. If nothing shows in the parameter list, your model is probably made with a too old version of Live2D to access the parameters properly."]},{"l":"Model Animations","p":["UI model animations","Starter animation","Select an expression and motion from the lists that will play when starting a chat with the character. You can also add a delay during which the model will be invisible if you need to hide the character for some time to achieve a perfect effect.","Default animation","Select an expression and motion from the list that will play when the character sends a message. Use a fallback animation when using the classify expression extension."]},{"i":"remarks-2","l":"Remarks","p":["Animations will play when you select one in the lists.","Use the replay button to replay the selected animation.","Some models have expressions defined as motions.","If nothing shows in the lists, it's probable your model's setting file has no expressions/motions defined."]},{"l":"Hit areas mapping","p":["UI model mapping","Default click animation","Select an expression and motion from the list that will play when you click on the model. You can also set a message that will be sent as a user message.","Hit areas","If the model has hit areas, they will be listed, and you can assign an animation/message to each of them."]},{"i":"remarks-3","l":"Remarks","p":["Some models have no hit areas, but the default click is detected for all.","The default click will trigger if you click on a hit area with nothing mapped or if you click outside of any hit area.","Hit areas have priority defined in the model; for example, \"mouth\" is inside \"head.\" If it does not behave properly, it may be due to the model file.","For some models, animations need to be finished before starting another one. Use the debug checkbox if you want to force the refresh and spam animations."]},{"l":"Classified Expressions Mapping","p":["UI model classify","Requirements","Requires the use of the classify expression extension; otherwise, it will fall back to the default animation.","Mapping","For each detected emotion by the classify extension, you can assign an expression/motion animation."]},{"i":"remarks-4","l":"Remarks","p":["If the previous animation did not finish when a new message is received, it's possible that the new animation will not play. This behavior is dependent on the Live2D model. Use the debug checkbox if you want to force the animation to play.","Thank you for following this guide! Your SillyTavern experience is now enriched with animated and interactive Live2D models."]}],[{"l":"Objective"},{"i":"what-is-it","l":"What is it?","p":["The Objective extension lets the user specify an Objective for the AI to strive towards during the chat. This objective is broken down into step-by-step tasks. Tasks may be branched, where child tasks can be created automatically or manually. This gives the ability to create complex task trees. The completion status of each task in the list will be checked at certain intervals.","This differs from adding static direction through prompting in that it adds sequential and paced directives for the AI to follow without user intervention. It gives a more genuine experience of the AI autonomously striving to reach a goal."]},{"l":"Prerequisites","p":["Before you begin, ensure you've met the following prerequisites:","Make sure you're on the latest staging branch of SillyTavern.","Install the \"Objective\" extension from the \"Download Extensions & Assets\" menu in the Extensions panel (stacked blocks icon)."]},{"l":"Common Use Cases","p":["Your imagination is the limit, you can give the AI any objective you wish and it will plan out how to achieve it. You can ask it to plan how to slay a demon, rob a temple, throw a lavish party, or even take over the world.","Objective Settings Panel"]},{"l":"Configuration","p":["The extension is found in the Extensions menu under Objective.","Type an objective into the top text box, then click on Auto-Generate Tasks. This sends a request to the connected API and asks it to provide a list of tasks which match the objective you have typed in.","Note: Clicking Auto-Generate Tasks will delete all existing tasks for the currently selected Objective before adding new ones.","Upon receiving the response from the AI, a list of tasks will be created automatically in the space below the Objective input box. Tasks can be edited after creation.","At the bottom of the panel are two boxes: Position in Chat and Task Check Frequency","Position in Chat- This is how 'deep' in the chat section of the prompt you want the current task to be inserted. The lower the number, the more attention the AI will give to the task. Setting to 0 will make the task the primary thing in the AI's mind. Setting at high values will put the task in the background and allow the AI to focus on the conversation at hand, but setting it too high may cause the AI to never 'get around' to the task at all.","Task Check Frequency- This is how often you want the AI to check if the task has been completed. If it is set to 3, the AI will be asked if the current task has been completed every 3rd message.","Objectives, tasks, and their descriptions are saved in real-time to the current chat session. Custom prompts are saved globally."]},{"l":"Custom Prompts","p":["You can customize the prompts sent to the LLM to generate tasks, check task completion, and for prompt injection. Editing prompts will save them for the current session. Custom prompts can be saved and loaded for persistence.","Click Edit Prompts to open the prompt editor window. You can edit your prompts as desired.","To save prompts, enter a name and click Save Prompt.","To load prompts, select the prompt from the dropdown list.","To delete a saved prompt, select it from the dropdown list and click Delete Prompt","WARNING: Task Checking happens in a separate API request. Setting Task Check Frequency to 1 will double your API calls to the LLM service. Be careful with this if you are using a paid service."]},{"l":"Usage","p":["By default the Objective extension will keep track of all tasks and their respective completion status automatically.","The User can also manually create, update, delete, and complete tasks at any time."]},{"l":"Current Task Selection","p":["The current task will always be the first listed incomplete task. Any manual updates to tasks will trigger a check for what the current task should be. So if you add a task above a bunch of completed tasks, it will be set as the current task. Once it's completed, previously completed tasks will be skipped and the next incomplete task will be selected as 'Current'.","When using parent/child tasks in a task tree, tasks are selected depth-first, meaning all child tasks will be selected in order first, then continue down the list of tasks for the current Objective/Task."]},{"l":"Branch Tasks","p":["Click the Branch Task button to set the current task as an Objective where you can auto generate or manually create tasks as child tasks. You can continue to turn any child task into an Objective and keep generating to your hearts content.","Marking a parent task as complete will cause the extension to skip all subtasks. When all child tasks are complete, the parent task will be marked as complete"]},{"l":"Manually Complete Tasks","p":["You can manually toggle the completion status of a task by clicking the checkbox next to it. This will set the next incomplete task to be selected."]},{"l":"Manual Task Check","p":["If you want to manually trigger the AI to check for task completion, click on the Extras Extension button (the magic wand on the right side of the chat input bar) and select Manual Task Check."]},{"l":"Manually Add Tasks","p":["When no tasks are present, an Add Task button is visible, allowing you to manually create the first task.","If other tasks are already present, click the + button to the right of any task to insert a new task after it."]},{"l":"Delete Tasks","p":["Click the red x to delete an existing task. The next incomplete task will be selected as the current task automatically.","Deleting a task with child tasks will delete all child tasks and their descendants."]},{"l":"Hiding Tasks","p":["If you want to remain unaware of what tasks the AI is attempting to complete, check the Hide Tasks box to hide the task list and make the AI's intentions a mystery. For 100% mysteriousness, do this before clicking Auto-Generate Tasks!"]}],[{"i":"realtime-voice-cloning-rvc","l":"Realtime Voice Cloning (RVC)","p":["This guide will walk you through using RVC, a technique that allows transferring voice features from one audio clip to another, enabling voices to speak in different tones and styles.","Ever enjoyed those famous \"Presidents Play X\" videos? They were created using RVC. With the RVC Extra module, you can make your SillyTavern characters speak in any voice you desire, be it anime, movie, or even your own unique voice.","RVC is NOT TTS: it's more like speech-to-speech. It takes an audio clip as its input. In the background, what RVC does is work in tandem with SillyTavern-extras's TTS module: it waits for TTS to generate an audio file (which TTS would've done regardless of whether you use RVC or not), then RVC will perform a second pass that takes the TTS audio file and transforms it into the cloned voice from your RVC configuration."]},{"l":"RVC Setup"},{"l":"Prerequisites","p":["Before you begin, ensure you've met the following prerequisites:","Install the \"RVC\" extension from the \"Download Extensions & Assets\" menu in the Extensions panel (stacked blocks icon).","Make sure you have ffmpeg binary in your PATH environment variable. This tool is used to convert incoming audio.","Use the Toolbox in Launcher.bat script to install ffmpeg automatically: https://github.com/SillyTavern/SillyTavern-Launcher/blob/main/Launcher.bat","Or download the build here: https://www.gyan.dev/ffmpeg/builds/","How to modify PATH variable: https://www.architectryan.com/2018/03/17/add-to-the-path-on-windows-10/","To test whether you did things correctly, open a command prompt and run ffmpeg. It should print the ffmpeg version and info."]},{"l":"Step-by-Step Setup","p":["(Optional) Configure RVC to save your generations to file:","Choose \"rmvpe\" as the pitch extraction method.","Configure RVC in SillyTavern:","Create a subfolder like 'Betty' and place the .pth and .index files into it. (Hint: you can download voice files from https://voice-models.com, make sure the voice name says it's RVPME.)","Create a Voice map for RVC. Set your Character to your desired SillyTavern character name, and set Voice to the RVC folder you created at step 1, then click Apply. If you did things correctly, the Voice Map will show something like 'Betty:MyVoice(rvpme)'.","If for testing or troubleshooting purposes you wish to save the generated RVC audio, add --rvc-save-file to your startup command. This will save the last generation under SillyTavern-extrasdata/tmp/rvc_output.wav:","If you have trouble with \"rmvpe\" try other methods.","In a file browser, Navigate to: \\SillyTavern-extras\\data\\models\\rvc","In SillyTavern, navigate to Extensions> RVC and enable it.","Install Requirements:","Install the necessary requirements using the command: pip install -r requirements-rvc.txt.","Launch SillyTavern-extras with the RVC module enabled. This example invocation assumes you used Silero TTS which comes pre-installed with SillyTavern-extras:","Make sure TTS is enabled and works","Optionally, you may wish to run RVC on your GPU if you have a capable one, by adding --cuda to the startup command. Based on a quick test, VRAM usage was 3.4GB for narrating 50 tokens (~ 36 words), and 7.6GB for 200 tokens (~ 150 words).","Prepare RVC Model Files:","Run SillyTavern-extras with RVC enabled:","RVC depends on TTS, you need to enable a TTS module. Refer to our TTS guide for how. Your TTS has to be already working properly and narrating your chats before you try to add RVC to the mix!","Select Pitch Extraction:","Set Up Voice Map:"]},{"l":"Expression-Based Dynamic Voice","p":["Configure RVC Models:","In your RVC model folder, have separate .pth and .index files for each classified expression (e.g., anger, fear, joy, love, sadness, surprise).","Enable Modules:","Enable both RVC and classify modules:","Use RVC Module:","The remaining setup is similar to using the RVC module alone (as explained above)."]},{"l":"Train Your Own RVC Model"},{"i":"using-rvc-easy-menu-by-deffcolony-windows-only","l":"Using RVC Easy Menu by Deffcolony (Windows Only)","p":["Automatically install and launch Mangio-RVC: https://github.com/deffcolony/rvc-easy-menu","Clone Repository:","Clone the repository to your desired location:","Launch RVC-Launcher.bat:","Open the RVC-Launcher.bat file.","Choose option 1 to install RVC.","Complete Installation:","When prompted, install required packages and dependencies.","Open WebUI for Voice Training:","After installation, choose option 2 to open the WebUI for voice training."]},{"i":"mangio-rvc-training-a-voice-model","l":"Mangio-RVC: Training a Voice Model","p":["Access Training Tab:","Click \"Process data\" and \"Feature extraction\".","Click \"Train feature index\" and \"Train model\".","Click on the training tab in the WebUI.","Configure Experiment:","Dataset Preparation:","Ensure the audio is free of background noise – only raw voice is needed.","Enter an experiment name (e.g., my-epic-voice-model).","Longer audio makes a better output quality.","Place the audio you want to train in the datasets folder.","Prepare Audio:","Process Data and Extract Features:","Set \"Save frequency\" to 50.","Set \"Total training epochs\" to 300.","Set version to v2.","Training Parameters:","WebUI Training:"]}],[{"l":"Smart Context","p":["THE USE OF THIS PLUGIN DOESN'T GUARANTEE A BETTER CHATTING EXPERIENCE OR IMPROVED MEMORY OF ANY SORT. ONLY USE IF YOU UNDERSTAND ALL THE IMPLICATIONS OF VECTOR DATABASE UTILIZATION."]},{"i":"what-is-it","l":"What is it?","p":["Smart Context is a SillyTavern extension that uses the ChromaDB library to give your AI characters access to information that exists outside the normal chat history context limit."]},{"i":"how-is-that-useful","l":"How is that useful?","p":["If you have a very long chat, the majority of the contents are outside the usual context window and thus unavailable to the AI when it comes to writing a response.","Smart Context automatically takes the entire history of the chat file and puts it into a vector database. This database is then searched each time you input something new into the chat, and if messages with matching keywords are found, those chat messages are placed into the context so the AI can see them when writing its next reply."]},{"l":"Setup Instructions","p":["Update SillyTavern to at least version 1.10.6.","Install the \"Smart Context\" extension from the \"Download Extensions & Assets\" menu in the Extensions panel (stacked blocks icon).","Install or Update Extras to the latest version. Alternatively, use the Colab notebook.","Local installs only: Install requirements-complete.txt for Extras (even if you did it once before in a prior install).","Run Extras with the chromadb module enabled: python server.py --enable-modules=chromadb"]},{"i":"getting-an-error-when-installing-chromadb","l":"Getting an error when installing ChromaDB?","p":["Installing chromadb package requires one of the following:","Have Visual C++ build tools installed: https://visualstudio.microsoft.com/visual-cpp-build-tools/","Installing hnswlib from conda: conda install -c conda-forge hnswlib"]},{"l":"Configuration","p":["Once Smart Context is enabled, you should configure it in the SillyTavern UI. Smart Context configuration can be done from within the Extensions menu STExtensionMenuIcon","Smart Context Config Panel","There are 4 main concepts to be aware of:","Chat History Preservation","Memory Injection Amount","Individual Memory Length","Injection Strategy"]},{"l":"SmartContext only starts after 10 mesages are in the chat history","p":["At the start of a new chat, ChromaDB is inactive.","Once the chat has accumulated 10 messages, it will begin recording all messages into the database, and recalling messages as needed."]},{"i":"chat-history-preservation-kept-mesages","l":"Chat History Preservation ('kept mesages')","p":["By default, ChromaDB will keep as many recent natural chat history messages as specified in the slider. Any messages beyond this amount will be removed from your sent prompt, and if 'memories' exist in the database they will be added in place of the older chat history messages (see Strategy below)."]},{"l":"Memory Injection Amount","p":["The maximum number of 'memories' Smart Context will insert into the context. Not every injection attempt will get this full amount. If you send an input related to 'dogs' and only one other message in the DB is related to dogs, then only 1 item will be inserted."]},{"l":"Individual Memory Length","p":["This is the maximum length allowed for each injected 'memory'. This is in CHARACTERS(not tokens). If set too small, the memory could be cut off midway.","Example:","Ross: I like dogs with long fur and fluffy tails. I dislike dogs with short fur and short tails.","This database 'memory' is 103 characters long, so you would need to set the slider to at least 103 in order to pull it entirely into the context.","If the slider is less than 103, the message would be cut off and injected like that."]},{"l":"Injection Strategy"},{"l":"Replace oldest history","p":["This strategy keeps X recent messages, removes all message before that, and replaces them with 'memories'.","Advantage","less likely to overflow your context limit","memories existing near the top of the context will have less immediate impact on the response while still providing 'background information'.","Disadvantage","old messages are inserted directly into the chat history with no special demarcation, and usually have no immediate natural relevance to the preserved natural chat history messages. This can confuse less intelligent AI models."]},{"l":"Add to Bottom","p":["This strategy leaves the chat history in its natural state and adds 'memories' after it inside a formatted [bracket header]. This means the 'kept messages' sliders is effectively disabled.","Advantage","does not shorten or alter the current natural chat history","'memories' exist after chat and have a stronger impact on the next AI response","Disadvantage","because no chat items are being removed/replaced, there is a higher chance you will overflow your context limit.","because the memories exist very close to the end of the prompt they can have TOO MUCH effect on the AI's response."]},{"l":"Custom Depth","p":["This strategy leaves the chat history in its natural state and adds 'memories' at the depth you determine within the template you specify. This means the 'kept messages' slider is effectively disabled. The custom injection message should include the `` template word which is where all queried memories will be placed.","Advantage","flexibility to experiment with memory placement","customizable introductions to memory within context","Disadvantage","because no chat items are being removed/replaced, there is a higher chance you will overflow your context limit."]},{"i":"use--strategy","l":"Use % Strategy","p":["Note: This is not compatible with the 'Add to Bottom' strategy, which does not remove any messages at all.","While using the 'Replace Oldest History' strategy, checking this box will enable the slider for selecting a percentage of the in-context chat history to replace with SmartContext memories. It will also disable the two sliders for manually selecting the number of messages.","This strategy automatically calculates a percentage of the chat history to be replaced with SmartContext memories, instead of a fixed number of messages.","Advantage","easier than manually calculating the number of messages yourself","adjusts with the available context size, applying the same percentage to small and large prompt spaces","Disadvantage","calculations for how much history to remove can be slightly innacurate as they are based on estimated tokens per message","it rounds the number of messages to remove to the nearest number divisible by 5 (0, 5, 10, 15, 20, etc), so it is not as fine grained as manual numeric selection."]},{"l":"Memory Recall Strategy"},{"l":"Recall only from this chat","p":["This is the default behavior of smart-context and pulls 'memories' only from the ChromaDB collection for this specific chat."]},{"l":"Recall from all character chats","p":["This is an experimental behavior of smart-context which pulls 'memories' from all ChromaDB collections for the selected character. Hypothetically this should allow for the development of a more robust memory set spanning many interactions. Reccomended that this be used with 'Add to Bottom' or 'Custom Depth' strategies and 'kept messages' set to a low number so that ChromaDB will pull from memory sooner."]},{"l":"Using Smart Context","p":["Once it is enabled and configured, Smart Context happens automatically.","ChromaDB makes a new database for each chat that is opened inside SillyTavern. This database is automatically filled with the entire chat history.","You can also manually insert text files into the database.","These text files do not have to be chats. They can be anything (wikipedia entries, fanfic, etc)."]},{"l":"Purging the Database","p":["You can use the 'Purge DB' button to clear the database for the current chat.","This can be helpful if you find inaccurate memories have been stored (such as chat message you have since deleted or edited)."]},{"l":"FAQ"},{"i":"what-happens-to-the-databases-when-im-done-chatting-can-i-save-them","l":"What happens to the databases when I'm done chatting? Can I save them?","p":["For locally installed Extras servers, Smart Context saves the databases. There is no need to save them manually in usual use cases.","For colab users, the databases are wiped when the extras server shuts down. Use the export button to save the database as a JSON file, and import it next time you want to use it.","Usually there is no need to save Smart Context databases.","Currently we have an Import/Export feature, which allows you to save the chat's DB and use it again at a later date."]},{"i":"can-i-make-one-big-database-for-all-of-my-chats-to-reference","l":"Can I make one big database for all of my chats to reference?","p":["This would not be a good use of Smart Context's capabilities. We recommend using World Info for this purpose."]}],[{"l":"Speech Recognition","p":["This guide will walk you through setting up speech recognition to transcribe your voice into text within SillyTavern."]},{"l":"Prerequisites","p":["Before you begin, ensure you've met the following prerequisites:","Make sure you're on the latest staging branch of SillyTavern.","Install the \"Speech Recognition\" extension from the \"Download Extensions & Assets\" menu in the Extensions panel (stacked blocks icon).","Have ffmpeg binary installed. See https://docs.sillytavern.app/extras/extensions/rvc/#rvc-setup"]},{"i":"speech-recognition-setup-browser","l":"Speech Recognition Setup (Browser)","p":["Append: Your message will be appended to the current user message text area.","Auto send: Your message will automatically be sent once the end of speech is detected.","Choose the \"Message Mode\" you want:","Choose the language you want to speak (Note: not every browser supports all languages).","Configure SillyTavern:","Enable Message Mapping(Optional):","For instance, by adding \"command delete = /del2\", the \"/del2\" command will replace your voice message when \"command delete\" is detected.","If your browser doesn't support voice recognition, an error popup will appear.","Launch SillyTavern and go to Extensions> Speech Recognition.","Recording:","Replace: Your message will replace the current user message in the text area.","Select \"Browser\" from the dropdown options.","Select Language:","Select Message Mode:","Setup phrases mapping for vocal shortcuts.","To start recording, click the microphone button to the right of the message area next to the send button. Click again to stop recording. Recording may stop automatically if no voice is detected.","Useful when combined with auto send mode for full voice control. Enable this by checking \"Enable messages mapping\"."]},{"i":"speech-recognition-setup-whispervosk","l":"Speech Recognition Setup (Whisper/Vosk)","p":["Enable Provider:","Enable the desired speech recognition provider on the extras server using the following command:","or","You can also use a custom model by adding the option --stt-vosk-model-path or --stt-whisper-model-path with the path to the model.","Configure SillyTavern:","Launch SillyTavern and go to Extensions> Speech Recognition.","Select \"Vosk\" or \"Whisper\" from the dropdown options (whisper is more accurate).","The settings are similar to the \"Browser\" provider setup (except for language) see above."]},{"i":"speech-recognition-setup-streaming","l":"Speech Recognition Setup (Streaming)","p":["Enable Provider:","Enable the streaming speech recognition module on Sillytavern-extras with the following command:","Configure SillyTavern:","(Optional) Specify a custom Whisper model as in the Whisper setup above.","(Optional but recommended) Set up trigger words in SillyTavern. Only messages starting with these trigger words will be sent to SillyTavern as actual messages. This prevents random speech or noise from being transcribed. Enable this with the checkbox. The trigger words can be included/excluded from the actual message using a checkbox.","Other settings are similar to other providers.","You're now ready to transcribe your voice into text using speech recognition in SillyTavern."]}],[{"l":"Stable Diffusion"},{"l":"Image Generation plugin","p":["Use local or cloud-based Stable Diffusion APIs to generate images. The free mode is also supported via the /sd (anything_here) command in the chat input bar. Most common Stable Diffusion generation settings are customizable within the SillyTavern UI."]},{"l":"Generation modes","p":["-","\"Background\"","\"Me\"","\"Raw Last Message\"","\"The Last Message\"","\"The Whole Story\"","\"Your Face\"","\"Yourself\"","A chat background based on story context.","A close-up portrait of the current character.","A full-body portrait of the current character.","A portrait of the user persona.","A visual recap of the chat events.","A visual recap of the last chat message.","background","Description","face","Forces a portrait aspect ratio.","Forces a wide landscape aspect ratio.","last","Last message used as a prompt verbatim.","me","raw_last","Remarks","scene","Slash command argument","Wand menu item","you"]},{"l":"How to generate an image","p":["Use the \"Image Generation\" item in the extensions context menu (wand).","Type a /sd (argument) slash command with an argument from the Generation modes table. Anything else would trigger a \"free mode\" to make SD generate whatever you prompted. Example: /sd apple tree would generate a picture of an apple tree.","Look for a paintbrush icon in the context actions for chat messages. This will force the \"Raw Message\" mode for the selected message.","Every generation mode besides raw message and free mode will trigger a prompt generation using your currently selected main generation API to convert chat context into the SD prompt. You can configure the instruction template for generating prompts for every generation mode using the \"SD Prompt Templates\" settings drawer in the extensions panel."]},{"l":"Supported Sources","p":["Stable Horde","NovelAI Diffusion. Requires an active subscription.","Stable Diffusion WebUI / AUTOMATIC1111","SD.Next / vladmandic","OpenAI DALL-E 2/3","TogetherAI","Draw Things","Pollinations","ComfyUI. Requires a workflow JSON file.","SillyTavern Extras(will be deprecated in future)"]},{"l":"Options"},{"l":"Edit prompts before generation","p":["Allow to edit the automatically generated prompts manually before sending them to the Stable Diffusion API."]},{"l":"Interactive mode","p":["Allows to trigger an image generation instead of text as a reply to a user message that follows the special pattern:","Contains one of the following words: send, mail, imagine, generate, make, create, draw, paint, render","Followed by one of the following words: pic, picture, image, drawing, painting, photo, photograph","Followed by a target subject of image generation, could be optionally preceded by phrases like \"of a\" or \"of this\".","Examples of valid requests and captured subjects:","Can you please send me a picture of a cat=> cat","Generate a picture of the Eiffel tower=> Eiffel tower","Let's draw a painting of Mona Lisa=> Mona Lisa","Some special subjects trigger a predefined generation mode:","'you, 'yourself' => \"Yourself\"","'your face', 'your portrait', 'your selfie' => \"Your Face\"","'me', 'myself' => \"Me\"","'story', 'scenario', 'whole story' => \"The Whole Story\"","'last message' => \"The Last Message\"","'background', 'scene background', 'scene', 'scenery', 'surroundings', 'environment' => \"Background\""]},{"l":"Auto-enhance prompts","p":["This option uses an additional GPT-2 text generation model to add more details to the prompt generated by the main API. Works best for SDXL image models. It may not work well with other models, and it is recommended to manually edit prompts in this case.","Default GPT-2 model: Cohee/fooocus_expansion-onnx"]},{"l":"Snap auto-adjusted resolutions","p":["Snap image generation requests with a forced aspect ratio (portraits, backgrounds) to the nearest known resolution, while trying to preserve the absolute pixel counts. Refer to the \"Resolution\" dropdown for the list of possible options.","Recommended for SDXL models."]},{"l":"Common prompt prefix","p":["Added before every generated or free-mode prompt. Commonly used for setting the overall style of the picture.","Example: best quality, anime lineart.","Pro tip: Use {prompt} macro to specify where exactly the generated prompt will be inserted."]},{"l":"Negative prompt","p":["Characteristics of the image you don't want to be present in the output.","Example: bad quality, watermark."]},{"l":"Character-specific prompt prefix","p":["Any characteristics that describe the currently selected character. Will be added after a common prefix.","Example: female, green eyes, brown hair, pink shirt.","Limitations:","Works only in 1-to-1 chats. Will not be used in groups.","Won't be used for backgrounds and free mode generations.","Pro tip: If supported by the generation source, you can also use LoRAs/embeddings here, for example: lora:DonaldDuck:1."]},{"l":"Styles","p":["Use this to quickly save and restore your favorite style/quality presets to use them later or when switching between models. The following is included in the Style preset:","Common Prompt Prefix","Negative Prompt"]}],[{"l":"Summarize"},{"i":"what-is-it","l":"What is it?","p":["This extension allows you to create, store, and utilize automatically generated summaries based on the events happening in your chats. Summarization can help with outlining general details of what is happening in the story, which could be interpreted as a long-term memory, but take that statement with a grain of salt. Since the summaries are generated by language models, the outputs may lose some important details or contain hallucinations, so you're always advised to keep track of the summary state and correct it manually if needed."]},{"l":"Common configuration","p":["The summarization extension is installed in SillyTavern by default, thus it will show up in ST's Extensions panel (stacked cubes icon) list like this:","Summarize Config Panel","Current summary- displays and provides an ability to modify the current summary. The summary is updated and embedded into the chat file's metadata for the message that was the last in context when the summary was generated. Deleting or editing a message from the chat that has a summary attached to it, will revert the state to the last valid summary.","Restore Previous- removes the current summary, rolling it back to the previous state. This is useful if the summarizer does a poor job at any given point.","Pause- check this to prevent the summary from being automatically updated. This is useful if you want to provide a custom summary of your own or to effectively disable the summary by clearing the box and stopping updates.","Popup window- allows to detach the summary into a movable UI panel on the sidebar. Useful for the desktop layout to easily have access to summarization settings without having to navigate through the extensions menu.","Injection Template- defines how the summary will be wrapped when being inserted into regular chat prompts. A special {{summary}} macro should be used to denote the exact location of the current summary state in the prompt injection text.","Injection Position- sets the location of the prompt injection. The options are the same as for Author's Notes: before or after the main prompt, or in-chat at designated depth."]},{"l":"Supported summary sources"},{"l":"Main API","p":["Summarization will be powered by your currently selected AI backend, model and settings. This method requires no additional setup, just a working API connection.","This option has the following sub-modes that differ depending on how the summary prompt is built:","Raw, blocking. The summary will be generated using nothing but the summarization prompt and the chat history. Subsequent prompts will also include the previous summary with messages that were sent after the summary was generated (see example). This mode can (and will) generate prompts that have a lot of variability between them, so it is not recommended to use it with backends that have slow prompt processing times, such as llama.cpp and its derivatives.","Raw, non-blocking. Same as above, but the chat generation will not be blocked during the summary generation. Not every backend supports simultaneous requests, so switch to blocking mode if summarization fails.","Classic, blocking. The summarization prompt will be sent at the end of your usual generation prompt, as a neutral system instruction, not omitting the character card, main prompt, example dialogues and other parts of chat prompts. This usually results in prompts that play nicely with reusing processed prompts, so it is recommended to use with llama.cpp and its siblings."]},{"l":"Summary Settings explained","p":["Summary Prompt- defines the prompt that will used for creating a summary. May include any of the known macros, as well as a special {{words}} macro (see below).","Target summary length (words)- defines the value of the {{words}} macro that can be inserted into the Summary Prompt. This setting is completely optional and has no effect at all if the macro is not used.","API response length (tokens)- allows to set an override API response length for generating summaries that are different from the globally set value.","Max messages per request (raw modes only)- set to limit the maximum number of messages that will be included in one summarization prompt. 0 means no explicit limitation, but the resulting number of messages to summarize will still depend on the maximum context size, calculated using the formula: max summary buffer = context size - summarization prompt - previous summary - response length. Use this when you want to get more focused summaries on models with large context sizes. 5 No WI/AN- omit World Info and Author's Note from text to be summarized. Only has an effect when using the Classic prompt builder. The Raw prompt builder always omits WI/AN.","Update every X messages- sets the interval at which the summary is generated. 0 means that the automatic summarization is disabled, but you can still trigger it manually by clicking the \"Summarize now\" button. This should be adjusted based on how quickly the prompt buffer entirely fills with chat messages. Ideally, you'd want to have the first summary generated when the messages are starting to get dropped out of the prompt.","Update every X words- same as above, but using words (not tokens!) instead of messages, theoretically can be a more accurate measurement due to how unpredictable the contents of chat messages usually are, but your mileage may vary.","If both \"Update every\" sliders are set to a non-zero value, then both will trigger summary updates at their respective intervals, depending on what happens first. It is strongly advised to update these values accordingly when you switch to another model that has differing context sizes, otherwise, the summary generation may trigger too often, or never at all.","If you're unsure about the interval settings, you can click the \"magic wand\" button above the \"Update every\" sliders to try and guess the optimal values based on some simple heuristics. A brief description of the algorithm is as follows:","Calculate token and word counts for all chat messages","Determine target summary length based on desired prompt words","Calculate the maximum number of messages that can fit in the prompt based on the average message length","If \"Max messages\" is set, adjust the average to account for messages that don't fit the summary limit","Round down the adjusted average messages per prompt to a multiple of 5"]},{"l":"Example prompts","p":["Raw prompt","Classic prompt"]},{"l":"Extras API","p":["Extras server with the summarize module could run an auxiliary summarization model (BART).","It has a very small context size (~ 1024 tokens), so its ability to handle large summaries is quite limited.","To configure the Extras summary source, do the following:","Install or Update Extras to the latest version.","Run Extras with the summarize module enabled: python server.py --enable-modules=summarize"]},{"l":"Changing Summary Model","p":["By default, Summarize uses the Qiliang/bart-large-cnn-samsum-ChatGPT_v3 model for summarization purposes.","This can be changed by using the command line argument --summarization-model=(###Hugging-Face-Model-URL-Here###)","A known alternate Summarize model is Qiliang/bart-large-cnn-samsum-ElectrifAi_v10."]}],[{"l":"talkinghead"},{"i":"what-is-it","l":"What is it?","p":["An implementation of Talking Head Anime 3 Demo for AITuber. It possesses the following features:","Generates random Live 2D-like motion actions from a single static image.","Lip-syncs to the sound output from any TTS output.","This extension contains the original demo programs for the Talking Head(?) Anime from a Single Image 3: Now the Body Too project. As the name implies, the project allows you to animate anime characters, and you only need a single image of that character to do so. There are two demo programs:","The manual_poser lets you manipulate a character's facial expression, head rotation, body rotation, and chest expansion due to breathing through a graphical user interface, so you can save them as default expressions IE Happy, sad, joy, etc. ifacialmocap_puppeteer lets you transfer your facial motion to an anime character."]},{"l":"Hardware Requirements","p":["You can use either CPU or GPU Modes (CPU is default). However, in CPU mode expect about 1 FPS, and in GPU mode on an RTX3060 I am getting about 9-10 FPS.","The ifacialmocap_puppeteer requires an iOS device that is capable of computing blend shape parameters from a video feed. This means that the device must be able to run iOS 11.0 or higher and must have a TrueDepth front-facing camera. (See this page for more info.) In other words, if you have the iPhone X or something better, you should be all set."]},{"l":"How to use","p":["You must launch extras with the following modules for talkinghead to work: classify and talkinghead! classify is required for the handling of the talkinghead.png file. Additionally, you may also use --talkinghead-gpu to load the blend models into GPU memory and make the animations 10x faster. It is highly recommended to use GPU acceleration! By default, once the program starts it will load a default image SillyTavern-extras\\talkinghead\\tha3\\images\\lambda_00.png. You can verify it is working by going to http://localhost:5100/api/talkinghead/result_feed or YOUR EXT URL:PORT/api/talkinghead/result_feed.","Once the server has started go to the Extension API tab and connect. Then simply select a character card to load. (--enable-modules=classify,talkinghead --talkinghead-gpu when starting server.py)","Now select the Character Expressions, if you check the image type talkinghead box the script will replace your current character expression with the result of YOUR EXT URL:PORT/api/talkinghead/result_feed unchecking the box SHOULD return the image back to the original expression, however sometimes you have to send a new message to the chat to \"reload\" the image.","If you do not have a talkinghead.png file in the character directory it will simply show either the default image or the last character card that had a talkinghead.png file. The animation source image is changed when the character card is changed.","Now open the character expressions scroll down to the talkinghead image and upload an image file that meets the requirements in the section below called \"Constraints on Input Images\".","Then check and uncheck the talkinghead box to reload the character. If the image is funny looking it is probably because it is not transparent / has no alpha layer. Otherwise, follow the instructions and template below."]},{"l":"Constraints on Input Images","p":["In order for the system to work well, the input image must obey the following constraints:","It should be of resolution 512 x 512. (If the program receives an input image of any other size, it will resize the image to this resolution and also output at this resolution.) It must have an alpha channel. It must contain only one humanoid character. The character should be standing upright and facing forward. The character's hands should be below and far from the head. The head of the character should roughly be contained in the 128 x 128 box in the middle of the top half of the image. The alpha channels of all pixels that do not belong to the character (i.e., background pixels) must be 0.","Input Constraints"]},{"l":"ADVANCED SECTION"},{"l":"Python Environment","p":["In addition to the base feature (app.py), both manual_poser and ifacialmocap_puppeteer are available as desktop applications. To run them, you need to set up an environment for running programs written in the Python language. The environment needs to have the following software packages:","Python >= 3.8","PyTorch >= 1.11.0 with CUDA support","SciPY >= 1.7.3","wxPython >= 4.1.1","Matplotlib >= 3.5.1","One way to do so is to install Anaconda and run the following commands in your shell:","conda create -n talking-head-anime-3-demo python=3.8 conda activate talking-head-anime-3-demo conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch conda install scipy pip install wxpython conda install matplotlib"]},{"l":"Additional Blend Models","p":["There is only one (lightest) model included, if you want the additional blend models you need to download the model files from https://www.dropbox.com/s/y7b8jl4n2euv8xe/talking-head-anime-3-models.zip?dl=0 and unzip it to the SillyTavern-extras\\talkinghead\\tha3\\models folder. In the end, the data folder should look like:","tha3","models","separable_float","editor.pt","eyebrow_decomposer.pt","eyebrow_morphing_combiner.pt","face_morpher.pt","two_algo_face_body_rotator.pt","separable_half","editor.pt:","standard_float","standard_half","The model files are distributed with the Creative Commons Attribution 4.0 International License, which means that you can use them for commercial purposes. However, Pramook Khungurn. Talking Head(?) Anime from a Single Image 3: Now the Body Too. https://github.com/pkhungurn/talking-head-anime-3-demo, is the creator."]},{"l":"Running the manual_poser Desktop Application","p":["Open a shell. Change your working directory to the repository's root directory. Then, run:","python tha3/app/manual_poser.py Note that before running the command above, you might have to activate the Python environment that contains the required packages.","conda activate extras if you have not already activated the environment."]}],[{"l":"TTS","p":["SillyTavern has a wide range of TTS options. This page explains the setup and use."]},{"i":"what-is-it","l":"What is it?","p":["TTS is used to have a voice narrate parts of your chat."]},{"l":"Configuring TTS"},{"l":"TTS Provider Selectbox","p":["Used to select which TTS service you want to use.","ElevenLabs- paid subscription required, highest quality voices available at present.","Silero- free, runs on your PC, quality can vary widely","System- uses your OS TTS engine, if one exists. Quality can vary widely depending on the OS.","Edge- free, runs via Azure, generally quite fast, and voices feel natural but dry and emotionless. Like listening to the evening news or a radio announcer.","Coqui-TTS- free, No API Implementation at this time. High-performance Text2Speech models (Tacotron, Tacotron2, Glow-TTS, SpeedySpeech) as well as Bark.","Novel- requires a paid NovelAI subscription, generated by NovelAI's TTS engine","RVC- free, voice cloning"]},{"l":"Checkboxes","p":["\"Good evening, senpai\"","\"Good evening, senpai\", she says.","\"nya\"... \"Good evening, senpai\"","Auto Generation- lets TTS start playing automatically when a new message enters the chat","Cohee approaches you with a faint \"nya\" \"Good evening, senpai\", she says.","Disabled","Enabled","Enabled- turns TTS playback on/off","Given the example text: *Cohee approaches you with a faint nya* Good evening, senpai, she says. Here's a table showing how the text will be modified based on the boolean states of Ignore *text, even \"quotes\", inside asterisks* and Only narrate \"quotes\":","having both \"only narrate quotes\" and \"ignore asterisks\" checkboxes both checked will result in the TTS only reading \"quotes\" which are not in asterisks, and ignoring everything else.","Ignore *text, even \"quotes\", inside asterisks*","Ignore *text, even \"quotes\", inside asterisks*- TTS will not play any text within *asterisks*, even \"quotes\" (internal variable name = narrate_dialogues_only)","Narrate only the translated text- this will make the TTS only narrate the translated text.","Only narrate \"quotes\"","Only narrate \"quotes\"- Limits TTS playback to only include text within quotation marks. This will *include quotes within asterisk lines*(internal variable name = narrate_quoted_only)","Output"]},{"l":"Sliders","p":["These will change depending on the API you select.","(explanation coming soon)"]},{"l":"Buttons","p":["Apply- this must be clicked after setting a TTS API and after editing the voice map.","Available voices- loads a popup with all voices available for your selected API, and lets you preview them with sample dialogues."]},{"l":"Using TTS","p":["Click the \"Enable\" checkbox, or nothing will ever happen.","Click the \"Auto-generation\" checkbox if you want the TTS to start automatically every time a new message arrives in chat.","Optionally, click the megaphone icon inside the top-right of any message to playback on demand.","Click the lower right \"Stop\" button (found inside the wand menu) to stop any playback."]},{"l":"Voice Map","p":["You must provide a voice map for the TTS to use, otherwise, it won't know what voices should be used for each character.","These must be in the exact format stated below:","CharacterName:TTSVoice,CharacterName2:TTSVoice2","For Coqui-TTS the format needs to include the speaker and language from the WebGUI:","CharacterName:TTSVoice[speakerid][langid] or Aqua:tts_models--multilingual--multi-dataset--your_tts\\model_file.pth[2][1]"]},{"l":"Bark ZeroShot Voice Cloning Speakers","p":["If using Bark you must create a voice folder with a voice file to clone. Ensure you add voices to homedir\\tts\\bark_v0\\speakers. On Windows it is probably C:\\Users\\USERACCOUNT\\AppData\\Local\\tts\\bark_v0\\speakers\\ type %appdata% in windows explorer then go UP a directory to local and you should see tts.","The directory should look like this:","homedir","tts","bark_v0","speakers","customvoice1","speaker.wav","speaker.npz","robinwilliams","speaker.mp3","me","One first load of this model and voice bark will clone the voice and create a .npz file, this is needed for faster TTS."]}],[{"l":"VRM","p":["This guide will walk you through the process of setting up and customizing the VRM extension for your SillyTavern experience. This extension allows you to use VRM animated models for your character, providing a dynamic and interactive element to your virtual character."]},{"l":"Prerequisites","p":["Before you begin, ensure you've met the following prerequisites:","Branch Selection: Make sure you're using the latest staging branch of SillyTavern to access the latest features and updates.","Extension Installation: Install the \"VRM\" extension from the \"Download Extensions & Assets\" menu in the Extensions panel (represented by the stacked blocks icon).","Model Folder Placement: Place your VRM model files (.vrm) into the /data/user-handle/assets/vrm/model directory and your animation files into the /data/user-handle/assets/vrm/animation directory. The currently supported animation file format are .fbx and .bvh that are compatible with VRM models. This include any animation you can get from Mixamo ( https://www.mixamo.com/) and any animation you can export from tools like XR Animator ( https://github.com/ButzYung/SystemAnimatorOnline)."]},{"l":"Extension Settings","p":["The VRM extension offers various settings to customize the behavior of your animated model. Here are the key settings:","UI global settings"]},{"l":"Global Settings","p":["Enabled:","Enable this checkbox to activate the extension, allowing your VRM model to interact within SillyTavern.","You can disable the extension if you want to use normal sprites only.","Look at camera:","Enable this checkbox to make the VRM model eyes look at the camera.","Blink:","Enable this checkbox to make the VRM model eyes blink at random intervals. Model expressions should define properly blinking weight property otherwize model can blink with closed eyes for example, if that happens either:","correct the model if you have the .vroid file","don't use that incorrect face experession","disable blinking completly with this checkbox","TTS ip sync","Enable this checkbox to have the VRM mouth movement follow the sound of your TTS when it's played. Only work with TTS whose sound is played by Sillytavern itself like XTTS (not in streaming mode). If disabled, mouth will be animated according to the message text length when a new character message is received.","Auto-send Interaction:","Enable this checkbox to automatically trigger character interactions when you click on areas with mapped messages (refer to the hit areas section for details)."]},{"l":"Performances Settings","p":["Body hitboxes","Enable this checkbox to activate detection of click on several part of the VRM model depending on the model the following area can be detected: head/chest/hands/groin/butt/legs/feets. Hitboxes location are computed at each frames and follow the body animation, disabling this option can improve performance.","Use model cache","Enable this checkbox to keep in memory VRM model when switching models, allows to switch back to previous model faster. Usefull if you use different model for the same character to change outfit or form for example. Can affect performance.","Use animation cache","Enable this checkboxx to keep in memory all animations played during the session. All animation assigned to a model will also be loaded the first time the model appear. Will increase the time you load the model the first time but make all animation switch instant. Can affect performance."]},{"l":"Debug Settings","p":["Show grid","Enable this checkbox to visualize the 3d grid, model dragging box and body hitboxes.","Reload button","Click this button to reload the 3d scene, clear the cache and all VRM models. Use it if some bug occurs or if cache starts to hit performance."]},{"l":"Scene Settings","p":["UI scene settings","Light Color","Set the color of the light in the 3d scene. Click on the reset button to set it back to the default white color. Depending on your browser you can use a color picker, for example you can color pick the color of your background image to add more immersion.","Light intensity","Set the light intensity in percent using the slider. Click on the reset button to set it back to the default value of 100%. VRM model can react differently to light depending on the baked shaders into the model, play with the value and see how it goes.","UI model settings"]},{"l":"Character Selection","p":["These settings allow you to manage characters and assign VRM models to them.","Refresh Button:","Click the refresh button to update the list of characters in the current chat.","Select Character:","Use the drop-down list to choose a character to assign a VRM model to.","Remove Button:","Click this button to delete the assigned model for a character."]},{"l":"Model Selection","p":["Refresh Button:","Click the refresh button if your VRM model does not appear in the list.","Select Model:","Choose a model from the list to assign it to the selected character.","The model has to be located in /data/user-handle/assets/vrm/model directory.","Reset button","Click this button to reset the model settings to its default. If you have animation files that correspond to the default value they will be auto mapped. See the naming mapping at the end of this README."]},{"l":"Model Settings","p":["Model Scale:","Use the slider to adjust the size of the model, making it larger or smaller.","Model Center X/Y Offset:","Use those sliders to change the horizontal/vertical position of the model relative to the window center.","Model X/Y Rotation","Use those sliders to change the horizontal/vertical rotation of the model relative to the model hips."]},{"l":"Remarks","p":["UI hitboxes settings"]},{"l":"Hitboxes mapping","p":["UI classify settings"]},{"l":"Classified Expressions Mapping","p":["Requirements","Requires the use of the classify expression extension; otherwise, it will fallback to the default animation.","Mapping","For each detected emotion by the classify extension, you can assign an expression/motion/message. The message can contain commands."]},{"l":"Commands","p":["\"/vrmmotion idle\" or \"/vrmmotion character=Seraphina motion=idle loop=true random=false\"","/vrmexpression","/vrmlightcolor","/vrmlightintensity","/vrmmodel","/vrmmotion","arguments: character, expression","arguments: character, model","arguments: character, motion, loop, random","arguments: color","arguments: intensity","assign the vrm model to the character","change the animation of the model","change the expression of the model","example: \"/vrmexpression happy\" in solo chat or \"/vrmexpression character=Seraphina expression=happy\" in group chat","example: \"/vrmlightcolor white\" or \"/vrmlightcolor purple\".","example: \"/vrmlightintensity 0\" or \"/vrmlightintensity 100","example: \"/vrmmodel Seraphina.vrm\" in solo chat or \"/vrmmodel character=Seraphina model=Seraphina.vrm\" in group chat","set the light color","set the light intensity in percent"]},{"l":"Animations default mapping","p":["If your animation file are named in the following way they will be mapped automatically when reseting a model settings. For example the files named \"assets/vrm/animation/neutral.bvh\" and \"assets/vrm/animation/neutral1.fbx\" will be automatically mapped as a group for default and neutral classified animation. Same goes for the hitboxes.","Thank you for following this guide! Your SillyTavern experience is now enriched with animated and interactive 3D models."]},{"i":"remarks-1","l":"Remarks"}],[{"l":"Web Search","p":["Adds web search results to LLM prompts."]},{"l":"Available sources"},{"l":"Selenium Plugin","p":["Requires an official server plugin to be installed and enabled.","See SillyTavern-WebSearch-Selenium for more details.","Supports Google and DuckDuckGo engines."]},{"l":"Extras API","p":["Requires a websearch module and Chrome/Firefox web browser installed on the host machine.","Supports Google and DuckDuckGo engines."]},{"l":"SerpApi","p":["Requires SerpApi key and provides access to Google search.","Get the key here: https://serpapi.com/dashboard"]},{"l":"How to use","p":["Make sure you use the latest version of SillyTavern.","Install the extension via the \"Download Extensions & Assets\" menu in SillyTavern.","Open the \"Web Search\" extension settings, set your API key or connect to Extras, and enable the extension.","The web search results will be added to the prompt organically as you chat. Only user messages trigger the search.","To include search results more organically, wrap search queries with single backticks: Tell me about the `latest Ryan Gosling movie`. will produce a search query latest Ryan Gosling movie.","Optionally, configure the settings to your liking."]},{"l":"Settings"},{"l":"General","p":["Enabled - toggles the extension on and off.","Sources = sets the search results source.","Cache Lifetime - how long (in seconds) the search results are cached for your prompt. Default = one week."]},{"l":"Prompt Settings","p":["Prompt Budget - sets the maximum capacity of the inserted text (in characters of text, NOT tokens). Rule of thumb: 1 token ~ 3-4 characters, adjust according to your model's context limits. Default = 1500 characters.","Insertion Template - how the result gets inserted into the prompt. Supports the usual macro + special macro: {{query}} for search query and {{text}} for search results.","Injection Position - where the result goes in the prompt. The same options as for the Author's Note: as in-chat injection or before/after system prompt."]},{"l":"Search Activation","p":["Use Backticks - enables search activation using words encased in single backticks.","Use Trigger Phrases - enables search activation using trigger phrases.","Trigger Phrases - add phrases that will trigger the search, one by one. It can be anywhere in the message, and the query starts from the trigger word and spans to \"Max Words\" total. To exclude a specific message from processing, it must start with a period, e.g. .What do you think?. Priority of triggers: first by order in the textbox, then the first one in the user message.","Max Words - how many words are included in the search query (including the trigger phrase). Google has a limit of about 32 words per prompt. Default = 10 words."]},{"l":"Page Scraping","p":["Visit Links - text will be extracted from the visited search result pages and saved to a file attachment.","Visit Count - how many links will be visited and parsed for text.","Visit Domain Blacklist - site domains to be excluded from visiting. One per line.","File Header - file header template, inserted at the start of the text file, has an additional {{query}} macro.","Block Header - link block template, inserted with the parsed content of every link. Use {{link}} macro for page URL and {{text}} for page content."]},{"l":"More info","p":["Search results from the latest query will stay included in the prompt until the next valid query is found. If you want to ask additional questions without accidentally triggering the search, start your message with a period.","If both backticks and trigger phrases search activation are used, backticks have a higher priority.","To discard all previous queries from processing, start the user message with an exclamation mark, for example, a user message !Now let's talk about... will discard this and every message above it.","This extension also provides a /websearch slash command to use in STscript. More info here: STscript Language Reference"]},{"i":"what-can-be-included-in-the-search-result","l":"What can be included in the search result?"},{"i":"serpapi-1","l":"SerpApi","p":["Answer box. Direct answer to the question.","Knowledge graph. Encyclopedic knowledge about the topic.","Page snippets (max 10). Relevant extracts from the web pages.","Relevant questions (max 10). Questions and answers to similar topics."]},{"l":"Selenium Plugin and Extras API","p":["Google - answer box, knowledge graph, page snippets.","DuckDuckGo - page snippets."]}],[{"l":"XTTS with voice cloning","p":["Greetings! So, you've been blown away by those Reddit posts showcasing how far the technology went for the AI text-to-speech?","Feeling excited to give your robotic waifu/husbando a new shiny voice modulator?","Fear not, this stunning groundbreaking technology is already available at your local SillyTavern, you just need a simple..."]},{"l":"Prerequisites","p":["Latest staging branch of SillyTavern.","Miniconda installed.","(Windows) Visual C++ Build Tools installed.","WAV files with voice clips to clone from (~ 10 seconds per file). File requirements: PCM, Mono, 22050Hz, 16-bit (convert via Audacity).","Create a folder with \"speakers\" and \"output\" subfolders. Put WAV files into \"speakers\".","Example folder structure:"]},{"l":"Installing","p":["daswer123 made an API server that runs the XTTSv2 model on your computer and connects to SillyTavern's TTS extension.","It's completely independent of Extras API and would use a separate environment.","Very important: Don't install the following requirements to your Extras environment or system Python. It will break your other packages, do unnecessary downgrades, etc.","The following instruction is provided using Miniconda, but you can also do it with venv (not covered here). Open the Anaconda command prompt and follow the instructions line by line."]},{"l":"Getting the server up and running","p":["Navigate to the folder you've created at step 4 of prerequisites.","Create a new conda env. From now on, we'll call it xtts.","Activate a newly created env.","Install Python 3.10 to your env. Confirm with \"y\" when prompted.","Install the XTTS server with its requirements.","Install PyTorch. This can take some time. The following line installs PyTorch with GPU acceleration support (CUDA). If you want to use just the CPU inference, drop the last part that starts with --index-url.","Start the XTTS server on the default host and port: http://localhost:8020","During your first startup, the model will be downloaded (about ~ 2 GB). Don't forget to read the legal notice from Coqui AI very carefully. Lol, I'm kidding, just hit \"y\" again."]},{"l":"Connecting to SillyTavern","p":["Open the extensions panel, expand the TTS menu, and pick \"XTTSv2\" in the provider list.","Choose your text-to-speech language in the Language dropdown (I'll be sad if it's not Polish).","Verify that the provider endpoint points to http://localhost:8020 and \"Available voices\" shows a list of your voice samples.","Pick any character and set a mapping between the voice sample and the character. If the characters list is empty, hit \"Reload\" a couple of times.","Configure the rest of the TTS settings according to your preferences."]},{"i":"youre-all-set-now","l":"You're all set now!","p":["Click on the bullhorn icon in the context actions menu for any message and hear the beautiful cloned voice emanating from your speakers. The generation takes some time and it's not real-time even on high-end RTX GPUs."]},{"i":"streaming","l":"Streaming?","p":["It's possible to use HTTP streaming with the latest version of the XTTS server to get the chunks of generated audio as soon as it is available!"]},{"i":"this-doesnt-work-with-rvc","l":"This doesn't work with RVC!","p":["The audio will still be generated (assuming you're using the latest version of the RVC extension) and converted, but not streamed as RVC requires to have the full audio file before initiating the conversion. Streamed RVC is still being investigated..."]},{"i":"how-to-get-streaming-support","l":"How to get streaming support?","p":["Update to the latest staging branch of SillyTavern.","Update the XTTS server to the latest version.","Start and connect XTTS to ST as usual.","Enable the \"Streaming\" XTTS extension setting in SillyTavern."]},{"i":"choppy-audio","l":"Choppy audio?","p":["Try increasing the \"chunk size\" setting.","For reference: with a chunk size of 200, RTX 3090 can produce uninterrupted audio at the cost of slightly increased audio latency."]},{"i":"how-to-restart-the-tts-server","l":"How to restart the TTS server?","p":["Just do steps 1, 3 and 7 from the installation instruction."]},{"i":"android","l":"Android??","p":["Unlikely, it can't run apps that require PyTorch without some arcane black magic that we don't provide support for. You can try it out at your own risk, but no support will be provided if you face any problems.","Your best solution is to host the TTS API on your PC over the local network, just don't forget to specify the host and port to listen on - see README."]}],[{"l":"License and credits","p":["AI Horde client library by ZeldaFan0225: https://github.com/ZeldaFan0225/ai_horde","city_unit's extensions and various QoL features ( https://github.com/city-unit)","Cohee's modifications and derived code: AGPL v3","Icon theme by Font Awesome https://fontawesome.com(Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License)","kingbri's various commits and suggestions ( https://github.com/bdashore3)","KoboldAI Presets from KAI Lite: https://lite.koboldai.net/","Linux startup script by AlpinDale","Noto Sans font by Google (OFL license)","Portions of CncAnon's TavernAITurbo mod: Unknown license","RossAscends' additions: AGPL v3","See the GNU Affero General Public License for more details.","TAI Base by Humi: MIT","Thanks paniphons for providing a FAQ document","Thanks to oobabooga for compiling presets for TextGen","Thanks to Pygmalion University for being awesome testers and suggesting cool features!","This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.","TTS and Objective extensions by Ouoertheo","Waifu Mode inspired by the work of PepperTaco ( https://github.com/peppertaco/Tavern/)"]},{"i":"feel-your-name-is-missing-here","l":"Feel your name is missing here?","p":["Open a Pull Request by using the \"Edit this page\" link so we could properly credit you and your contributions!"]}]]